dataset: imdb
subset: bg
templates:
  02ff2949-0f45-4d97-941e-6fa4c0afbc2d: !Template
    answer_choices: "\u043E\u0442\u0440\u0438\u0446\u0430\u0442\u0435\u043B\u0435\u043D\
      \ ||| \u043F\u043E\u043B\u043E\u0436\u0438\u0442\u0435\u043B\u0435\u043D"
    id: 02ff2949-0f45-4d97-941e-6fa4c0afbc2d
    jinja: "\u0421\u043B\u0435\u0434\u043D\u043E\u0442\u043E \u0444\u0438\u043B\u043C\
      \u043E\u0432\u043E \u0440\u0435\u0432\u044E \u0438\u0437\u0440\u0430\u0437\u044F\
      \u0432\u0430 \u043A\u0430\u043A\u0432\u0438 \u0447\u0443\u0432\u0441\u0442\u0432\
      \u0430? {{text}} ||| {{ answer_choices [label] }}"
    metadata: !TemplateMetadata
      choices_in_prompt: false
      metrics:
      - Accuracy
      original_task: true
    name: Movie Expressed Sentiment 2
    reference: ''
  2351d12a-e630-4d19-8b41-e199266e38f7: !Template
    answer_choices: "\u043B\u043E\u0448\u043E ||| \u0434\u043E\u0431\u0440\u0435"
    id: 2351d12a-e630-4d19-8b41-e199266e38f7
    jinja: "{{text}} \u0420\u0435\u0446\u0435\u043D\u0437\u0435\u043D\u0442\u044A\u0442\
      \ \u043D\u0430\u043C\u0435\u0440\u0438 \u043B\u0438 \u0442\u043E\u0437\u0438\
      \ \u0444\u0438\u043B\u043C {{\"\u0434\u043E\u0431\u0440\u043E \u0438\u043B\u0438\
      \ \u043B\u043E\u0448\u043E\"}}? ||| {{ answer_choices [label] }}"
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
      - Accuracy
      original_task: true
    name: Reviewer Opinion bad good choices
    reference: ''
  5f372fb1-795a-47b6-8ddf-c4fd1579e76a: !Template
    answer_choices: "\u043E\u0442\u0440\u0438\u0446\u0430\u0442\u0435\u043B\u0435\u043D\
      \ ||| \u043F\u043E\u043B\u043E\u0436\u0438\u0442\u0435\u043B\u0435\u043D"
    id: 5f372fb1-795a-47b6-8ddf-c4fd1579e76a
    jinja: "{{text}} \n\u0422\u043E\u0432\u0430 \u0440\u0435\u0432\u044E {{\"\u043F\
      \u043E\u043B\u043E\u0436\u0438\u0442\u0435\u043B\u0435\u043D \u0438\u043B\u0438\
      \ \u043E\u0442\u0440\u0438\u0446\u0430\u0442\u0435\u043B\u0435\u043D\"}} \u043B\
      \u0438 \u0435? ||| \n{{answer_choices[label] }}"
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
      - Accuracy
      original_task: true
    name: 'Sentiment with choices '
    reference: ''
  866474a5-1498-46b7-bfee-ac0c5160707f: !Template
    answer_choices: "\u043E\u0442\u0440\u0438\u0446\u0430\u0442\u0435\u043B\u0435\u043D\
      \ ||| \u043F\u043E\u043B\u043E\u0436\u0438\u0442\u0435\u043B\u0435\u043D"
    id: 866474a5-1498-46b7-bfee-ac0c5160707f
    jinja: "{{text}} \u041A\u0430\u043A\u0432\u043E \u0435 \u0447\u0443\u0432\u0441\
      \u0442\u0432\u043E\u0442\u043E \u043D\u0430 \u0437\u0440\u0438\u0442\u0435\u043B\
      \u044F \u0437\u0430 \u0444\u0438\u043B\u043C\u0430? ||| {{ answer_choices [label]\
      \ }}"
    metadata: !TemplateMetadata
      choices_in_prompt: false
      metrics:
      - Accuracy
      original_task: true
    name: Reviewer Sentiment Feeling
    reference: ''
  96538f30-f2c1-430e-8fc6-936a16966d9c: !Template
    answer_choices: "\u043E\u0442\u0440\u0438\u0446\u0430\u0442\u0435\u043B\u0435\u043D\
      \ ||| \u043F\u043E\u043B\u043E\u0436\u0438\u0442\u0435\u043B\u0435\u043D"
    id: 96538f30-f2c1-430e-8fc6-936a16966d9c
    jinja: "{{text}} \u041A\u0430\u043A\u0432\u0438 \u0447\u0443\u0432\u0441\u0442\
      \u0432\u0430 \u0438\u0437\u0440\u0430\u0437\u044F\u0432\u0430 \u043F\u0438\u0441\
      \u0430\u0442\u0435\u043B\u044F\u0442 \u043A\u044A\u043C \u0444\u0438\u043B\u043C\
      \u0430? ||| {{ answer_choices [label] }}"
    metadata: !TemplateMetadata
      choices_in_prompt: false
      metrics:
      - Accuracy
      original_task: true
    name: Writer Expressed Sentiment
    reference: ''
  af51297c-38a3-4d6c-a8b5-04b1243d7443: !Template
    answer_choices: "\u043E\u0442\u0440\u0438\u0446\u0430\u0442\u0435\u043B\u0435\u043D\
      \ ||| \u043F\u043E\u043B\u043E\u0436\u0438\u0442\u0435\u043B\u0435\u043D"
    id: af51297c-38a3-4d6c-a8b5-04b1243d7443
    jinja: "{{text}} \u0418\u0437\u0440\u0430\u0437\u0435\u043D\u043E\u0442\u043E\
      \ \u0447\u0443\u0432\u0441\u0442\u0432\u043E \u0437\u0430 \u0444\u0438\u043B\
      \u043C\u0430 \u0435 ||| {{ answer_choices [label] }}"
    metadata: !TemplateMetadata
      choices_in_prompt: false
      metrics:
      - Accuracy
      original_task: true
    name: Movie Expressed Sentiment
    reference: ''
  b93b74ac-fe95-40b4-9610-318b46ab820f: !Template
    answer_choices: "\u043E\u0442\u0440\u0438\u0446\u0430\u0442\u0435\u043B\u0435\u043D\
      \ ||| \u043F\u043E\u043B\u043E\u0436\u0438\u0442\u0435\u043B\u0435\u043D"
    id: b93b74ac-fe95-40b4-9610-318b46ab820f
    jinja: "{{text}} \u041A\u0430\u043A\u0432\u043E \u0435 \u0447\u0443\u0432\u0441\
      \u0442\u0432\u043E\u0442\u043E, \u0438\u0437\u0440\u0430\u0437\u0435\u043D\u043E\
      \ \u0432 \u0442\u043E\u0437\u0438 \u0442\u0435\u043A\u0441\u0442? ||| {{ answer_choices\
      \ [label] }}"
    metadata: !TemplateMetadata
      choices_in_prompt: false
      metrics:
      - Accuracy
      original_task: true
    name: Text Expressed Sentiment
    reference: ''
  b9b5d79d-f0b3-4bec-a724-f585db3e93ff: !Template
    answer_choices: "\u043E\u0442\u0440\u0438\u0446\u0430\u0442\u0435\u043B\u0435\u043D\
      \ ||| \u043F\u043E\u043B\u043E\u0436\u0438\u0442\u0435\u043B\u0435\u043D"
    id: b9b5d79d-f0b3-4bec-a724-f585db3e93ff
    jinja: "{{text}} \u0422\u043E\u0432\u0430 \u043E\u043F\u0440\u0435\u0434\u0435\
      \u043B\u0435\u043D\u043E \u043D\u0435 \u0435 \u043F\u0440\u0435\u0433\u043B\u0435\
      \u0434 \u043D\u0430 ||| {{ answer_choices [1-label]}}."
    metadata: !TemplateMetadata
      choices_in_prompt: false
      metrics:
      - Accuracy
      original_task: false
    name: Negation template for positive and negative
    reference: ''
  bd82ba0f-01d4-4fa1-bf8d-07e392c00cd9: !Template
    answer_choices: "\u041D\u0435 ||| \u0434\u0430"
    id: bd82ba0f-01d4-4fa1-bf8d-07e392c00cd9
    jinja: "{{text}} \u0420\u0435\u0446\u0435\u043D\u0437\u0435\u043D\u0442\u044A\u0442\
      \ \u0445\u0430\u0440\u0435\u0441\u0430 \u043B\u0438 \u0444\u0438\u043B\u043C\
      \u0430? ||| {{ answer_choices [label] }}"
    metadata: !TemplateMetadata
      choices_in_prompt: false
      metrics:
      - Accuracy
      original_task: true
    name: Reviewer Enjoyment Yes No
    reference: ''
  c70d1687-2421-49a2-9553-91b8bac4cfbe: !Template
    answer_choices: "\u043E\u0442\u0440\u0438\u0446\u0430\u0442\u0435\u043B\u0435\u043D\
      \ ||| \u043F\u043E\u043B\u043E\u0436\u0438\u0442\u0435\u043B\u0435\u043D"
    id: c70d1687-2421-49a2-9553-91b8bac4cfbe
    jinja: "{{text}} \u041A\u0430\u043A\u0432\u043E \u0435 \u043C\u043D\u0435\u043D\
      \u0438\u0435\u0442\u043E \u043D\u0430 \u0440\u0435\u0446\u0435\u043D\u0437\u0435\
      \u043D\u0442\u0430 \u0437\u0430 \u0444\u0438\u043B\u043C\u0430? ||| {{ answer_choices\
      \ [label] }}"
    metadata: !TemplateMetadata
      choices_in_prompt: false
      metrics:
      - Accuracy
      original_task: true
    name: Reviewer Expressed Sentiment
    reference: ''
  e01970ab-42c0-4e6e-a08f-4940d889ef37: !Template
    answer_choices: "\u041D\u0435 \u0438\u043C \u0445\u0430\u0440\u0435\u0441\u0430\
      ! ||| \u0422\u0435 \u0433\u043E \u043E\u0431\u0438\u0447\u0430\u0445\u0430"
    id: e01970ab-42c0-4e6e-a08f-4940d889ef37
    jinja: "{{text}} \u041A\u0430\u043A\u0432\u043E \u0435 \u043C\u043D\u0435\u043D\
      \u0438\u0435\u0442\u043E \u043D\u0430 \u0440\u0435\u0446\u0435\u043D\u0437\u0435\
      \u043D\u0442\u0430 \u0437\u0430 \u0444\u0438\u043B\u043C\u0430? ||| {{ answer_choices\
      \ [label] }}"
    metadata: !TemplateMetadata
      choices_in_prompt: false
      metrics:
      - Accuracy
      original_task: true
    name: Reviewer Enjoyment
    reference: ''
