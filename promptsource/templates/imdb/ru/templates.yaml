dataset: imdb
subset: ru
templates:
  02ff2949-0f45-4d97-941e-6fa4c0afbc2d: !Template
    answer_choices: "\u043E\u0442\u0440\u0438\u0446\u0430\u0442\u0435\u043B\u044C\u043D\
      \u044B\u0439 ||| \u043F\u043E\u043B\u043E\u0436\u0438\u0442\u0435\u043B\u044C\
      \u043D\u044B\u0439"
    id: 02ff2949-0f45-4d97-941e-6fa4c0afbc2d
    jinja: "\u041A\u0430\u043A\u0438\u0435 \u0447\u0443\u0432\u0441\u0442\u0432\u0430\
      \ \u0432\u044B\u0440\u0430\u0436\u0430\u0435\u0442 \u0441\u043B\u0435\u0434\u0443\
      \u044E\u0449\u0430\u044F \u0440\u0435\u0446\u0435\u043D\u0437\u0438\u044F \u043D\
      \u0430 \u0444\u0438\u043B\u044C\u043C? {{text}} ||| {{ answer_choices [label]\
      \ }}"
    metadata: !TemplateMetadata
      choices_in_prompt: false
      metrics:
      - Accuracy
      original_task: true
    name: Movie Expressed Sentiment 2
    reference: ''
  2351d12a-e630-4d19-8b41-e199266e38f7: !Template
    answer_choices: "\u041F\u043B\u043E\u0445\u043E ||| \u0445\u043E\u0440\u043E\u0448\
      \u0438\u0439"
    id: 2351d12a-e630-4d19-8b41-e199266e38f7
    jinja: "{{text}} \u0420\u0435\u0446\u0435\u043D\u0437\u0435\u043D\u0442 \u043D\
      \u0430\u0448\u0435\u043B \u044D\u0442\u043E\u0442 \u0444\u0438\u043B\u044C\u043C\
      \ {{\"\u0445\u043E\u0440\u043E\u0448\u043E \u0438\u043B\u0438 \u043F\u043B\u043E\
      \u0445\u043E\"}}? ||| {{ answer_choices [label] }}"
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
      - Accuracy
      original_task: true
    name: Reviewer Opinion bad good choices
    reference: ''
  5f372fb1-795a-47b6-8ddf-c4fd1579e76a: !Template
    answer_choices: "\u043E\u0442\u0440\u0438\u0446\u0430\u0442\u0435\u043B\u044C\u043D\
      \u044B\u0439 ||| \u043F\u043E\u043B\u043E\u0436\u0438\u0442\u0435\u043B\u044C\
      \u043D\u044B\u0439"
    id: 5f372fb1-795a-47b6-8ddf-c4fd1579e76a
    jinja: "{{text}} \n\u042D\u0442\u043E\u0442 \u043E\u0431\u0437\u043E\u0440 {{\"\
      \u043F\u043E\u043B\u043E\u0436\u0438\u0442\u0435\u043B\u044C\u043D\u044B\u0439\
      \ \u0438\u043B\u0438 \u043E\u0442\u0440\u0438\u0446\u0430\u0442\u0435\u043B\u044C\
      \u043D\u044B\u0439\"}}? ||| \n{{answer_choices[label] }}"
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
      - Accuracy
      original_task: true
    name: 'Sentiment with choices '
    reference: ''
  866474a5-1498-46b7-bfee-ac0c5160707f: !Template
    answer_choices: "\u043E\u0442\u0440\u0438\u0446\u0430\u0442\u0435\u043B\u044C\u043D\
      \u044B\u0439 ||| \u043F\u043E\u043B\u043E\u0436\u0438\u0442\u0435\u043B\u044C\
      \u043D\u044B\u0439"
    id: 866474a5-1498-46b7-bfee-ac0c5160707f
    jinja: "{{text}} \u041A\u0430\u043A \u0437\u0440\u0438\u0442\u0435\u043B\u044C\
      \ \u043E\u0442\u043D\u043E\u0441\u0438\u0442\u0441\u044F \u043A \u0444\u0438\
      \u043B\u044C\u043C\u0443? ||| {{ answer_choices [label] }}"
    metadata: !TemplateMetadata
      choices_in_prompt: false
      metrics:
      - Accuracy
      original_task: true
    name: Reviewer Sentiment Feeling
    reference: ''
  96538f30-f2c1-430e-8fc6-936a16966d9c: !Template
    answer_choices: "\u043E\u0442\u0440\u0438\u0446\u0430\u0442\u0435\u043B\u044C\u043D\
      \u044B\u0439 ||| \u043F\u043E\u043B\u043E\u0436\u0438\u0442\u0435\u043B\u044C\
      \u043D\u044B\u0439"
    id: 96538f30-f2c1-430e-8fc6-936a16966d9c
    jinja: "{{text}} \u041A\u0430\u043A\u043E\u0435 \u043E\u0442\u043D\u043E\u0448\
      \u0435\u043D\u0438\u0435 \u043A \u0444\u0438\u043B\u044C\u043C\u0443 \u0432\u044B\
      \u0440\u0430\u0436\u0430\u0435\u0442 \u043F\u0438\u0441\u0430\u0442\u0435\u043B\
      \u044C? ||| {{ answer_choices [label] }}"
    metadata: !TemplateMetadata
      choices_in_prompt: false
      metrics:
      - Accuracy
      original_task: true
    name: Writer Expressed Sentiment
    reference: ''
  af51297c-38a3-4d6c-a8b5-04b1243d7443: !Template
    answer_choices: "\u043E\u0442\u0440\u0438\u0446\u0430\u0442\u0435\u043B\u044C\u043D\
      \u044B\u0439 ||| \u043F\u043E\u043B\u043E\u0436\u0438\u0442\u0435\u043B\u044C\
      \u043D\u044B\u0439"
    id: af51297c-38a3-4d6c-a8b5-04b1243d7443
    jinja: "{{text}} \u041D\u0430\u0441\u0442\u0440\u043E\u0435\u043D\u0438\u0435\
      , \u0432\u044B\u0440\u0430\u0436\u0435\u043D\u043D\u043E\u0435 \u0432 \u0444\
      \u0438\u043B\u044C\u043C\u0435, ||| {{ answer_choices [label] }}"
    metadata: !TemplateMetadata
      choices_in_prompt: false
      metrics:
      - Accuracy
      original_task: true
    name: Movie Expressed Sentiment
    reference: ''
  b93b74ac-fe95-40b4-9610-318b46ab820f: !Template
    answer_choices: "\u043E\u0442\u0440\u0438\u0446\u0430\u0442\u0435\u043B\u044C\u043D\
      \u044B\u0439 ||| \u043F\u043E\u043B\u043E\u0436\u0438\u0442\u0435\u043B\u044C\
      \u043D\u044B\u0439"
    id: b93b74ac-fe95-40b4-9610-318b46ab820f
    jinja: "{{text}} \u041A\u0430\u043A\u043E\u0435 \u043D\u0430\u0441\u0442\u0440\
      \u043E\u0435\u043D\u0438\u0435 \u0432\u044B\u0440\u0430\u0436\u0435\u043D\u043E\
      \ \u0432 \u044D\u0442\u043E\u043C \u0442\u0435\u043A\u0441\u0442\u0435? |||\
      \ {{ answer_choices [label] }}"
    metadata: !TemplateMetadata
      choices_in_prompt: false
      metrics:
      - Accuracy
      original_task: true
    name: Text Expressed Sentiment
    reference: ''
  b9b5d79d-f0b3-4bec-a724-f585db3e93ff: !Template
    answer_choices: "\u043E\u0442\u0440\u0438\u0446\u0430\u0442\u0435\u043B\u044C\u043D\
      \u044B\u0439 ||| \u043F\u043E\u043B\u043E\u0436\u0438\u0442\u0435\u043B\u044C\
      \u043D\u044B\u0439"
    id: b9b5d79d-f0b3-4bec-a724-f585db3e93ff
    jinja: "{{text}} \u042D\u0442\u043E \u043E\u043F\u0440\u0435\u0434\u0435\u043B\
      \u0435\u043D\u043D\u043E \u043D\u0435 \u043E\u0431\u0437\u043E\u0440 ||| {{\
      \ answer_choices [1-label]}}."
    metadata: !TemplateMetadata
      choices_in_prompt: false
      metrics:
      - Accuracy
      original_task: false
    name: Negation template for positive and negative
    reference: ''
  bd82ba0f-01d4-4fa1-bf8d-07e392c00cd9: !Template
    answer_choices: "\u041D\u0435\u0442 ||| \u0414\u0430"
    id: bd82ba0f-01d4-4fa1-bf8d-07e392c00cd9
    jinja: "{{text}} \u041F\u043E\u043D\u0440\u0430\u0432\u0438\u043B\u0441\u044F\
      \ \u043B\u0438 \u0440\u0435\u0446\u0435\u043D\u0437\u0435\u043D\u0442\u0443\
      \ \u0444\u0438\u043B\u044C\u043C? ||| {{ answer_choices [label] }}"
    metadata: !TemplateMetadata
      choices_in_prompt: false
      metrics:
      - Accuracy
      original_task: true
    name: Reviewer Enjoyment Yes No
    reference: ''
  c70d1687-2421-49a2-9553-91b8bac4cfbe: !Template
    answer_choices: "\u043E\u0442\u0440\u0438\u0446\u0430\u0442\u0435\u043B\u044C\u043D\
      \u044B\u0439 ||| \u043F\u043E\u043B\u043E\u0436\u0438\u0442\u0435\u043B\u044C\
      \u043D\u044B\u0439"
    id: c70d1687-2421-49a2-9553-91b8bac4cfbe
    jinja: "{{text}} \u041A\u0430\u043A\u043E\u0435 \u043E\u0442\u043D\u043E\u0448\
      \u0435\u043D\u0438\u0435 \u043A \u0444\u0438\u043B\u044C\u043C\u0443 \u0432\u044B\
      \u0440\u0430\u0437\u0438\u043B \u0440\u0435\u0446\u0435\u043D\u0437\u0435\u043D\
      \u0442? ||| {{ answer_choices [label] }}"
    metadata: !TemplateMetadata
      choices_in_prompt: false
      metrics:
      - Accuracy
      original_task: true
    name: Reviewer Expressed Sentiment
    reference: ''
  e01970ab-42c0-4e6e-a08f-4940d889ef37: !Template
    answer_choices: "\u0418\u043C \u044D\u0442\u043E \u043D\u0435 \u043F\u043E\u043D\
      \u0440\u0430\u0432\u0438\u043B\u043E\u0441\u044C! ||| \u0418\u043C \u044D\u0442\
      \u043E \u043F\u043E\u043D\u0440\u0430\u0432\u0438\u043B\u043E\u0441\u044C"
    id: e01970ab-42c0-4e6e-a08f-4940d889ef37
    jinja: "{{text}} \u041A\u0430\u043A \u0440\u0435\u0446\u0435\u043D\u0437\u0435\
      \u043D\u0442 \u043E\u0442\u043D\u043E\u0441\u0438\u0442\u0441\u044F \u043A \u0444\
      \u0438\u043B\u044C\u043C\u0443? ||| {{ answer_choices [label] }}"
    metadata: !TemplateMetadata
      choices_in_prompt: false
      metrics:
      - Accuracy
      original_task: true
    name: Reviewer Enjoyment
    reference: ''
