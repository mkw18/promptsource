dataset: yelp_review_full
subset: bg
templates:
  135fcd11-9fcc-4b55-bf1b-9b76290d0f6b: !Template
    answer_choices: "1 \u0437\u0432\u0435\u0437\u0434\u0430 ||| 2 \u0437\u0432\u0435\
      \u0437\u0434\u0438 ||| 3 \u0437\u0432\u0435\u0437\u0434\u0438 ||| 4 \u0437\u0432\
      \u0435\u0437\u0434\u0438 ||| 5 \u0437\u0432\u0435\u0437\u0434\u0438"
    id: 135fcd11-9fcc-4b55-bf1b-9b76290d0f6b
    jinja: "{{ text }}\n\u0422\u0430\u043A\u0430 \u0447\u0435 \u0431\u0438\u0445 \u0438\
      \u0441\u043A\u0430\u043B \u0434\u0430 \u0433\u043E \u0434\u0430\u043C ||| {{\
      \ answer_choices[label] }}"
    metadata: !TemplateMetadata
      choices_in_prompt: false
      metrics:
      - Accuracy
      original_task: true
    name: so_i_would
    reference: ''
  27b6bc81-bb1c-467b-91c0-22a4d6a19f44: !Template
    answer_choices: "1 \u0437\u0432\u0435\u0437\u0434\u0430 ||| 2 \u0437\u0432\u0435\
      \u0437\u0434\u0438 ||| 3 \u0437\u0432\u0435\u0437\u0434\u0438 ||| 4 \u0437\u0432\
      \u0435\u0437\u0434\u0438 ||| 5 \u0437\u0432\u0435\u0437\u0434\u0438"
    id: 27b6bc81-bb1c-467b-91c0-22a4d6a19f44
    jinja: "{{ text }}\n===\n\u0412\u044A\u0437 \u043E\u0441\u043D\u043E\u0432\u0430\
      \ \u043D\u0430 \u0442\u043E\u0432\u0430 \u043E\u0446\u0435\u043D\u043A\u0430\
      \u0442\u0430 \u043C\u0438 \u0435 ||| {{ answer_choices[label] }}"
    metadata: !TemplateMetadata
      choices_in_prompt: false
      metrics:
      - Accuracy
      original_task: true
    name: based_on_that
    reference: ''
  29fc6386-90b3-4976-b249-26e49fe7c924: !Template
    answer_choices: "1 \u0437\u0432\u0435\u0437\u0434\u0430 ||| 2 \u0437\u0432\u0435\
      \u0437\u0434\u0438 ||| 3 \u0437\u0432\u0435\u0437\u0434\u0438 ||| 4 \u0437\u0432\
      \u0435\u0437\u0434\u0438 ||| 5 \u0437\u0432\u0435\u0437\u0434\u0438"
    id: 29fc6386-90b3-4976-b249-26e49fe7c924
    jinja: "\u0422\u0435\u043A\u0441\u0442 \u0437\u0430 \u043F\u0440\u0435\u0433\u043B\
      \u0435\u0434:\n{{ text }}\n\n\u0417\u0432\u0435\u0437\u0434\u0438: |||\n{{ answer_choices[label]\
      \ }}"
    metadata: !TemplateMetadata
      choices_in_prompt: false
      metrics:
      - Accuracy
      original_task: true
    name: format_star
    reference: simulating webpage
  2a57af86-e25a-4572-ba9e-aa921842c04b: !Template
    answer_choices: "1 \u0437\u0432\u0435\u0437\u0434\u0430 ||| 2 \u0437\u0432\u0435\
      \u0437\u0434\u0438 ||| 3 \u0437\u0432\u0435\u0437\u0434\u0438 ||| 4 \u0437\u0432\
      \u0435\u0437\u0434\u0438 ||| 5 \u0437\u0432\u0435\u0437\u0434\u0438"
    id: 2a57af86-e25a-4572-ba9e-aa921842c04b
    jinja: "{{ text }} \u041C\u043E\u044F\u0442\u0430 \u043E\u0446\u0435\u043D\u043A\
      \u0430 \u0437\u0430 \u0442\u043E\u0432\u0430 \u043C\u044F\u0441\u0442\u043E\
      \ \u0435 ||| {{ answer_choices[label] }}"
    metadata: !TemplateMetadata
      choices_in_prompt: false
      metrics:
      - Accuracy
      original_task: true
    name: this_place
    reference: ''
  4dd990b3-7201-4cba-bb9a-baa462d68b1a: !Template
    answer_choices: 1 ||| 2 ||| 3 ||| 4 ||| 5
    id: 4dd990b3-7201-4cba-bb9a-baa462d68b1a
    jinja: "\u0422\u0435\u043A\u0441\u0442 \u0437\u0430 \u043F\u0440\u0435\u0433\u043B\
      \u0435\u0434:\n{{ text }}\n\n\u0420\u0435\u0446\u0435\u043D\u0437\u0438\u044F\
      \ \u0437\u0430 \u043F\u0440\u0435\u0433\u043B\u0435\u0434 (\u043C\u0435\u0436\
      \u0434\u0443 1 \u0438 5): |||\n{{ answer_choices[label] }}"
    metadata: !TemplateMetadata
      choices_in_prompt: false
      metrics:
      - Accuracy
      original_task: true
    name: format_score
    reference: Simulating webpage
  6d4bfb59-4260-40a5-9da5-e061720bd430: !Template
    answer_choices: 1 ||| 2 ||| 3 ||| 4 ||| 5
    id: 6d4bfb59-4260-40a5-9da5-e061720bd430
    jinja: "\u041F\u0440\u0435\u0433\u043B\u0435\u0434: {{text}}\n\u0412 \u0441\u043A\
      \u0430\u043B\u0430 \u043E\u0442 1 \u0434\u043E 5, \u0431\u0438\u0445 \u0434\u0430\
      \u043B \u0442\u043E\u0437\u0438 \u043F\u0440\u043E\u0434\u0443\u043A\u0442 |||\
      \ {{ answer_choices[label] }}"
    metadata: !TemplateMetadata
      choices_in_prompt: false
      metrics:
      - Accuracy
      original_task: true
    name: on_a_scale
    reference: ''
  e8091beb-c0fa-490d-9e0c-32eb6907dbc0: !Template
    answer_choices: "1 \u0437\u0432\u0435\u0437\u0434\u0430 ||| 2 \u0437\u0432\u0435\
      \u0437\u0434\u0438 ||| 3 \u0437\u0432\u0435\u0437\u0434\u0438 ||| 4 \u0437\u0432\
      \u0435\u0437\u0434\u0438 ||| 5 \u0437\u0432\u0435\u0437\u0434\u0438"
    id: e8091beb-c0fa-490d-9e0c-32eb6907dbc0
    jinja: "\u0422\u0435\u043A\u0441\u0442 \u0437\u0430 \u043F\u0440\u0435\u0433\u043B\
      \u0435\u0434:\n{{ text }}\n\n\u0420\u0435\u0439\u0442\u0438\u043D\u0433 \u0437\
      \u0430 \u043F\u0440\u0435\u0433\u043B\u0435\u0434: |||\n{{ answer_choices[label]\
      \ }}"
    metadata: !TemplateMetadata
      choices_in_prompt: false
      metrics:
      - Accuracy
      original_task: true
    name: format_rating
    reference: It's simulating the format of a webpage.
