dataset: winogrande
subset: winogrande_debiased_vi
templates:
  1ce2be12-1815-4a07-80a7-ac3c3505b005: !Template
    answer_choices: '{{option1}} ||| {{option2}}'
    id: 1ce2be12-1815-4a07-80a7-ac3c3505b005
    jinja: "{{sentence}}\nThay d\u1EA5u _ trong c\xE2u tr\xEAn b\u1EB1ng ph\u01B0\u01A1\
      ng \xE1n \u0111\xFAng: \n- {{option1}}\n- {{option2}}\n|||\n{% if answer ==\
      \ '1' %} {{option1}} {% else %} {{ option2 }} {% endif %}"
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
      - Accuracy
      original_task: true
    name: Replace
    reference: ''
  1ddbbca4-8917-4a1d-9d83-f42db77f24ba: !Template
    answer_choices: '{{option1}} ||| {{option2}}'
    id: 1ddbbca4-8917-4a1d-9d83-f42db77f24ba
    jinja: "{{sentence}}\nD\u1EA5u _ trong c\xE2u tr\xEAn \xE1m ch\u1EC9 \u0111i\u1EC1\
      u g\xEC? {{option1}} ho\u1EB7c {{option2}}? ||| {% if answer == '1' %} {{option1}}\
      \ {% else %} {{ option2 }} {% endif %}"
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
      - Accuracy
      original_task: true
    name: underscore refer to
    reference: ''
  276eaba6-17e5-403a-98c7-0f8c53c35221: !Template
    answer_choices: '{{ option1 }} ||| {{ option2 }}'
    id: 276eaba6-17e5-403a-98c7-0f8c53c35221
    jinja: "{{ sentence }} Trong c\xE2u tr\u01B0\u1EDBc, _ \xE1m ch\u1EC9 {{option1}}\
      \ hay {{option2}}? ||| {% if answer == '1' %} {{option1}} {% else %} {{ option2\
      \ }} {% endif %}"
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
      - Accuracy
      original_task: true
    name: does underscore refer to
    reference: ''
  9702d456-4261-4a7e-94c5-6a9d2a1c4859: !Template
    answer_choices: '{{option1}} ||| {{option2}}'
    id: 9702d456-4261-4a7e-94c5-6a9d2a1c4859
    jinja: "Trong c\xE2u d\u01B0\u1EDBi \u0111\xE2y, d\u1EA5u _ l\xE0 vi\u1EBFt t\u1EAF\
      t c\u1EE7a {{answer_choices[0]}} hay {{answer_choices[1]}}?\n{{sentence}}|||\n\
      {{answer_choices[answer | int - 1]}}"
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
      - Accuracy
      original_task: true
    name: stand for
    reference: ''
  bb9b91fc-760a-45cd-bacd-dcb05a1cb2f3: !Template
    answer_choices: "\u0110\xDANG V\u1EACY ||| Sai"
    id: bb9b91fc-760a-45cd-bacd-dcb05a1cb2f3
    jinja: "_ Trong c\xE2u d\u01B0\u1EDBi \u0111\xE2y \u0111\u1EC1 c\u1EADp \u0111\
      \u1EBFn {{option1}}. \u0110\xFAng hay sai?\n{{sentence}}|||\n{{answer_choices[answer|int\
      \ - 1]}}"
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
      - Accuracy
      original_task: false
    name: True or False
    reference: ''
  ebabc54d-cff4-46a7-9c22-2412b8ce00c6: !Template
    answer_choices: '{{option1}} ||| {{option2}}'
    id: ebabc54d-cff4-46a7-9c22-2412b8ce00c6
    jinja: "\u0110i\u1EC1n d\u1EA5u _ v\xE0o c\xE2u d\u01B0\u1EDBi \u0111\xE2y:\n\
      {{sentence}}\n\nL\u1EF1a ch\u1ECDn:\n- {{ option1 }}\n- {{ option2 }}\n\nC\xE2\
      u tr\u1EA3 l\u1EDDi: ||| {% if answer == '1' %} {{option1}} {% else %} {{ option2\
      \ }} {% endif %}"
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
      - Accuracy
      original_task: true
    name: fill in the blank
    reference: ''
