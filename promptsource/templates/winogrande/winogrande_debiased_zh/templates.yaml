dataset: winogrande
subset: winogrande_debiased_zh
templates:
  1ce2be12-1815-4a07-80a7-ac3c3505b005: !Template
    answer_choices: '{{option1}} ||| {{option2}}'
    id: 1ce2be12-1815-4a07-80a7-ac3c3505b005
    jinja: "{{sentence}}\n\u5C06\u4E0A\u9762\u53E5\u5B50\u4E2D\u7684 _ \u66FF\u6362\
      \u4E3A\u6B63\u786E\u7684\u9009\u9879\uFF1A \n- {{option1}}\n- {{option2}}\n\
      |||\n{% if answer == '1' %} {{option1}} {% else %} {{ option2 }} {% endif %}"
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
      - Accuracy
      original_task: true
    name: Replace
    reference: ''
  1ddbbca4-8917-4a1d-9d83-f42db77f24ba: !Template
    answer_choices: '{{option1}} ||| {{option2}}'
    id: 1ddbbca4-8917-4a1d-9d83-f42db77f24ba
    jinja: "{{sentence}}\n\u4E0A\u53E5\u4E2D\u7684_\u6307\u7684\u662F\u4EC0\u4E48\uFF1F\
      \ {{option1}} \u8FD8\u662F {{option2}}\uFF1F ||| {% if answer == '1' %} {{option1}}\
      \ {% else %} {{ option2 }} {% endif %}"
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
      - Accuracy
      original_task: true
    name: underscore refer to
    reference: ''
  276eaba6-17e5-403a-98c7-0f8c53c35221: !Template
    answer_choices: '{{ option1 }} ||| {{ option2 }}'
    id: 276eaba6-17e5-403a-98c7-0f8c53c35221
    jinja: "{{ sentence }} \u5728\u4E0A\u4E00\u53E5\u4E2D\uFF0C_ \u662F\u6307 {{option1}}\
      \ \u8FD8\u662F {{option2}}\uFF1F ||| {% if answer == '1' %} {{option1}} {% else\
      \ %} {{ option2 }} {% endif %}"
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
      - Accuracy
      original_task: true
    name: does underscore refer to
    reference: ''
  9702d456-4261-4a7e-94c5-6a9d2a1c4859: !Template
    answer_choices: '{{option1}} ||| {{option2}}'
    id: 9702d456-4261-4a7e-94c5-6a9d2a1c4859
    jinja: "\u5728\u4E0B\u9762\u7684\u53E5\u5B50\u4E2D\uFF0C_ \u4EE3\u8868 {{answer_choices[0]}}\
      \ \u8FD8\u662F {{answer_choices[1]}}\uFF1F\n{{sentence}}|||\n{{answer_choices[answer\
      \ | int - 1]}}"
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
      - Accuracy
      original_task: true
    name: stand for
    reference: ''
  bb9b91fc-760a-45cd-bacd-dcb05a1cb2f3: !Template
    answer_choices: "\u771F\u7684 ||| \u9519\u8BEF\u7684"
    id: bb9b91fc-760a-45cd-bacd-dcb05a1cb2f3
    jinja: "\u4E0B\u9762\u53E5\u5B50\u4E2D\u7684 _ \u6307\u7684\u662F {{option1}}\u3002\
      \ \u5BF9\u6216\u9519\uFF1F\n{{sentence}}|||\n{{answer_choices[answer|int - 1]}}"
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
      - Accuracy
      original_task: false
    name: True or False
    reference: ''
  ebabc54d-cff4-46a7-9c22-2412b8ce00c6: !Template
    answer_choices: '{{option1}} ||| {{option2}}'
    id: ebabc54d-cff4-46a7-9c22-2412b8ce00c6
    jinja: "\u5728\u4E0B\u9762\u7684\u53E5\u5B50\u4E2D\u586B\u5199_\uFF1A\n{{sentence}}\n\
      \n\u9009\u62E9\uFF1A\n- {{ option1 }}\n- {{ option2 }}\n\n\u56DE\u7B54\uFF1A\
      \ ||| {% if answer == '1' %} {{option1}} {% else %} {{ option2 }} {% endif %}"
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
      - Accuracy
      original_task: true
    name: fill in the blank
    reference: ''
