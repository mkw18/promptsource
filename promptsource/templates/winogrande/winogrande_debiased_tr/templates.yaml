dataset: winogrande
subset: winogrande_debiased_tr
templates:
  1ce2be12-1815-4a07-80a7-ac3c3505b005: !Template
    answer_choices: '{{option1}} ||| {{option2}}'
    id: 1ce2be12-1815-4a07-80a7-ac3c3505b005
    jinja: "{{sentence}}\nYukar\u0131daki c\xFCmledeki _'yi do\u011Fru se\xE7enekle\
      \ de\u011Fi\u015Ftirin: \n- {{option1}}\n- {{option2}}\n|||\n{% if answer ==\
      \ '1' %} {{option1}} {% else %} {{ option2 }} {% endif %}"
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
      - Accuracy
      original_task: true
    name: Replace
    reference: ''
  1ddbbca4-8917-4a1d-9d83-f42db77f24ba: !Template
    answer_choices: '{{option1}} ||| {{option2}}'
    id: 1ddbbca4-8917-4a1d-9d83-f42db77f24ba
    jinja: "{{sentence}}\nYukar\u0131daki c\xFCmledeki _ ne anlama gelmektedir? {{option1}}\
      \ veya {{option2}}? ||| {% if answer == '1' %} {{option1}} {% else %} {{ option2 }}\
      \ {% endif %}"
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
      - Accuracy
      original_task: true
    name: underscore refer to
    reference: ''
  276eaba6-17e5-403a-98c7-0f8c53c35221: !Template
    answer_choices: '{{ option1 }} ||| {{ option2 }}'
    id: 276eaba6-17e5-403a-98c7-0f8c53c35221
    jinja: "{{ sentence }} \xD6nceki c\xFCmlede, _ {{option1}} veya {{option2}} anlam\u0131\
      na m\u0131 geliyor? ||| {% if answer == '1' %} {{option1}} {% else %} {{ option2\
      \ }} {% endif %}"
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
      - Accuracy
      original_task: true
    name: does underscore refer to
    reference: ''
  9702d456-4261-4a7e-94c5-6a9d2a1c4859: !Template
    answer_choices: '{{option1}} ||| {{option2}}'
    id: 9702d456-4261-4a7e-94c5-6a9d2a1c4859
    jinja: "A\u015Fa\u011F\u0131daki c\xFCmlede, _ {{answer_choices[0]}} veya {{answer_choices[1]}}\
      \ anlam\u0131na m\u0131 geliyor?\n{{sentence}}|||\n{{answer_choices[answer |\
      \ int - 1]}}"
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
      - Accuracy
      original_task: true
    name: stand for
    reference: ''
  bb9b91fc-760a-45cd-bacd-dcb05a1cb2f3: !Template
    answer_choices: "Do\u011Fru ||| Yanl\u0131\u015F"
    id: bb9b91fc-760a-45cd-bacd-dcb05a1cb2f3
    jinja: "A\u015Fa\u011F\u0131daki c\xFCmledeki _ {{option1}} anlam\u0131na gelir.\
      \ Do\u011Fru ya da yanl\u0131\u015F?\n{{sentence}}|||\n{{answer_choices[answer|int\
      \ - 1]}}"
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
      - Accuracy
      original_task: false
    name: True or False
    reference: ''
  ebabc54d-cff4-46a7-9c22-2412b8ce00c6: !Template
    answer_choices: '{{option1}} ||| {{option2}}'
    id: ebabc54d-cff4-46a7-9c22-2412b8ce00c6
    jinja: "A\u015Fa\u011F\u0131daki c\xFCmledeki _ i\u015Faretini doldurunuz:\n{{sentence}}\n\
      \nSe\xE7enekler:\n- {{ option1 }}\n- {{ option2 }}\n\nCevap: ||| {% if answer\
      \ == '1' %} {{option1}} {% else %} {{ option2 }} {% endif %}"
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
      - Accuracy
      original_task: true
    name: fill in the blank
    reference: ''
