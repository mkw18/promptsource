dataset: winogrande
subset: winogrande_debiased_bg
templates:
  1ce2be12-1815-4a07-80a7-ac3c3505b005: !Template
    answer_choices: '{{option1}} ||| {{option2}}'
    id: 1ce2be12-1815-4a07-80a7-ac3c3505b005
    jinja: "{{sentence}}\n\u0417\u0430\u043C\u0435\u043D\u0435\u0442\u0435 _ \u0432\
      \ \u0433\u043E\u0440\u043D\u043E\u0442\u043E \u0438\u0437\u0440\u0435\u0447\u0435\
      \u043D\u0438\u0435 \u0441 \u043F\u0440\u0430\u0432\u0438\u043B\u043D\u0430\u0442\
      \u0430 \u043E\u043F\u0446\u0438\u044F: \n- {{option1}}\n- {{option2}}\n|||\n\
      {% if answer == '1' %} {{option1}} {% else %} {{ option2 }} {% endif %}"
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
      - Accuracy
      original_task: true
    name: Replace
    reference: ''
  1ddbbca4-8917-4a1d-9d83-f42db77f24ba: !Template
    answer_choices: '{{option1}} ||| {{option2}}'
    id: 1ddbbca4-8917-4a1d-9d83-f42db77f24ba
    jinja: "{{sentence}}\n\u0417\u0430 \u043A\u0430\u043A\u0432\u043E \u0441\u0435\
      \ \u043E\u0442\u043D\u0430\u0441\u044F _ \u0432 \u0433\u043E\u0440\u043D\u043E\
      \u0442\u043E \u0438\u0437\u0440\u0435\u0447\u0435\u043D\u0438\u0435? {{option1}}\
      \ \u0438\u043B\u0438 {{option2}}? ||| {% if answer == '1' %} {{option1}} {%\
      \ else %} {{ option2 }} {% endif %}"
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
      - Accuracy
      original_task: true
    name: underscore refer to
    reference: ''
  276eaba6-17e5-403a-98c7-0f8c53c35221: !Template
    answer_choices: '{{ option1 }} ||| {{ option2 }}'
    id: 276eaba6-17e5-403a-98c7-0f8c53c35221
    jinja: "{{ sentence }} \u0412 \u043F\u0440\u0435\u0434\u0438\u0448\u043D\u043E\
      \u0442\u043E \u0438\u0437\u0440\u0435\u0447\u0435\u043D\u0438\u0435 _ \u0441\
      \u0435 \u043E\u0442\u043D\u0430\u0441\u044F \u0437\u0430 {{option1}} \u0438\u043B\
      \u0438 {{option2}}? ||| {% if answer == '1' %} {{option1}} {% else %} {{ option2\
      \ }} {% endif %}"
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
      - Accuracy
      original_task: true
    name: does underscore refer to
    reference: ''
  9702d456-4261-4a7e-94c5-6a9d2a1c4859: !Template
    answer_choices: '{{option1}} ||| {{option2}}'
    id: 9702d456-4261-4a7e-94c5-6a9d2a1c4859
    jinja: "\u0412 \u0438\u0437\u0440\u0435\u0447\u0435\u043D\u0438\u0435\u0442\u043E\
      \ \u043F\u043E-\u0434\u043E\u043B\u0443 _ \u043E\u0437\u043D\u0430\u0447\u0430\
      \u0432\u0430 \u043B\u0438 {{answer_choices[0]}} \u0438\u043B\u0438 {{answer_choices[1]}}?\n\
      {{sentence}}|||\n{{answer_choices[answer | int - 1]}}"
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
      - Accuracy
      original_task: true
    name: stand for
    reference: ''
  bb9b91fc-760a-45cd-bacd-dcb05a1cb2f3: !Template
    answer_choices: "\u0412\u044F\u0440\u043D\u043E ||| \u041D\u0435\u0432\u044F\u0440\
      \u043D\u043E"
    id: bb9b91fc-760a-45cd-bacd-dcb05a1cb2f3
    jinja: "_ \u0432 \u0438\u0437\u0440\u0435\u0447\u0435\u043D\u0438\u0435\u0442\u043E\
      \ \u043F\u043E-\u0434\u043E\u043B\u0443 \u0441\u0435 \u043E\u0442\u043D\u0430\
      \u0441\u044F \u0434\u043E {{option1}}. \u0418\u0441\u0442\u0438\u043D\u0430\
      \ \u0438\u043B\u0438 \u043B\u044A\u0436\u0430?\n{{sentence}}|||\n{{answer_choices[answer|int\
      \ - 1]}}"
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
      - Accuracy
      original_task: false
    name: True or False
    reference: ''
  ebabc54d-cff4-46a7-9c22-2412b8ce00c6: !Template
    answer_choices: '{{option1}} ||| {{option2}}'
    id: ebabc54d-cff4-46a7-9c22-2412b8ce00c6
    jinja: "\u041F\u043E\u043F\u044A\u043B\u043D\u0435\u0442\u0435 _ \u0432 \u0438\
      \u0437\u0440\u0435\u0447\u0435\u043D\u0438\u0435\u0442\u043E \u043F\u043E-\u0434\
      \u043E\u043B\u0443:\n{{sentence}}\n\n\u0418\u0437\u0431\u043E\u0440:\n- {{ option1\
      \ }}\n- {{ option2 }}\n\n\u041E\u0442\u0433\u043E\u0432\u043E\u0440: ||| {%\
      \ if answer == '1' %} {{option1}} {% else %} {{ option2 }} {% endif %}"
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
      - Accuracy
      original_task: true
    name: fill in the blank
    reference: ''
