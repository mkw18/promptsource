dataset: quoref
subset: zh
templates:
  4120bebc-9c8f-44af-8d1a-a65e443ce010: !Template
    answer_choices: null
    id: 4120bebc-9c8f-44af-8d1a-a65e443ce010
    jinja: "\u95EE\u9898\u7684\u7B54\u6848\uFF1A{{Quartion}}\u5728\u6587\u7AE0\u4E2D\
      \uFF1A{{context}}\uFF0C\u60A8\u80FD\u731C\u51FA\u5417\uFF1F\n\n|||\n{{answers.text\
      \ | choice}}\n"
    metadata: !TemplateMetadata
      choices_in_prompt: false
      metrics:
      - Squad
      original_task: true
    name: Guess Answer
    reference: ''
  6f1d5031-1377-4b8a-9475-987b2275b8da: !Template
    answer_choices: null
    id: 6f1d5031-1377-4b8a-9475-987b2275b8da
    jinja: "\u7ED9\u5B9A\u4EE5\u4E0B\u4E0A\u4E0B\u6587\uFF1A\n\n{{context}}\n\n\u56DE\
      \u7B54\u4EE5\u4E0B\u95EE\u9898\uFF1A\n\n{{question}} |||\n{{answers.text | choice}}"
    metadata: !TemplateMetadata
      choices_in_prompt: false
      metrics:
      - Squad
      original_task: true
    name: Answer Question Given Context
    reference: ''
  9493f80a-daf5-4c30-a9fc-7bc5bc61b5e9: !Template
    answer_choices: null
    id: 9493f80a-daf5-4c30-a9fc-7bc5bc61b5e9
    jinja: "\u4EE5\u4E0B\u6587\u7AE0\u5305\u542B\u4E00\u4E2A\u95EE\u9898\u7684\u7B54\
      \u6848\uFF1A{{Quardion}}\uFF0C\u60A8\u80FD\u627E\u5230\u5B83\u5417\uFF1F \n\n\
      {{context}}|||\n{{answers.text | choice}}"
    metadata: !TemplateMetadata
      choices_in_prompt: false
      metrics:
      - Squad
      original_task: true
    name: Find Answer
    reference: ''
  a3e5e25d-0a87-4cb8-89ab-3539fc4d23cb: !Template
    answer_choices: null
    id: a3e5e25d-0a87-4cb8-89ab-3539fc4d23cb
    jinja: "\u672C\u6587\uFF1A{{context}}\u5305\u542B\u4E00\u4E2A\u95EE\u9898\u7684\
      \u7B54\u6848\uFF1A{{Quartion}}\uFF0C\u8FD9\u662F\u4EC0\u4E48\uFF1F\n|||\n{{answers.text\
      \ | choice}}"
    metadata: !TemplateMetadata
      choices_in_prompt: false
      metrics:
      - Squad
      original_task: true
    name: Context Contains Answer
    reference: ''
  aa26aab2-d2e7-4560-b7eb-0cbcff7c0f31: !Template
    answer_choices: null
    id: aa26aab2-d2e7-4560-b7eb-0cbcff7c0f31
    jinja: "{{question}}\n\n\u6839\u636E\u4EE5\u4E0B\u4E0A\u4E0B\u6587\u56DE\u7B54\
      \u4E0A\u8FF0\u95EE\u9898\uFF1A\n\n{{context}} |||\n{{answers.text | choice}}"
    metadata: !TemplateMetadata
      choices_in_prompt: false
      metrics:
      - Squad
      original_task: true
    name: Given Context Answer Question
    reference: ''
  abdfa570-2de5-406c-9051-caa6a1362796: !Template
    answer_choices: null
    id: abdfa570-2de5-406c-9051-caa6a1362796
    jinja: "\u95EE\u9898\u7684\u7B54\u6848\u662F\u4EC0\u4E48\uFF1A{{Quartion}}\u4ECE\
      \u4E0B\u9762\u7684\u6587\u7AE0\u4E2D\uFF1F\n\n{{context}}|||\n{{answers.text\
      \ | choice}}\n"
    metadata: !TemplateMetadata
      choices_in_prompt: false
      metrics:
      - Squad
      original_task: true
    name: What Is The Answer
    reference: ''
  b3ec0888-dd6f-466a-abd4-b2fbcacfdb8b: !Template
    answer_choices: null
    id: b3ec0888-dd6f-466a-abd4-b2fbcacfdb8b
    jinja: "\u6211\u6709\u4E00\u4E2A\u6D4B\u8BD5\uFF0C\u5728\u4EE5\u4E0B\u6587\u7AE0\
      \u4E2D\u7ED9\u51FA\u4E86\u6211\u7684\u95EE\u9898\uFF0C\u8BE5\u95EE\u9898\u7684\
      \u7B54\u6848\u662F\u4EC0\u4E48\uFF1A{{Quartion}}\uFF1F\n\n{{context}}|||\n{{answers.text\
      \ | choice}}"
    metadata: !TemplateMetadata
      choices_in_prompt: false
      metrics:
      - Squad
      original_task: true
    name: Answer Test
    reference: ''
  bf525757-8cde-4839-81fb-a85be3fd1192: !Template
    answer_choices: null
    id: bf525757-8cde-4839-81fb-a85be3fd1192
    jinja: "\u7ED9\u5B9A\u4EE5\u4E0B\u4E0A\u4E0B\u6587\uFF1A\n\n{{context}}\n\n\u731C\
      \u731C\u6709\u6548\u7684\u6807\u9898\uFF01 |||\n{{title}}"
    metadata: !TemplateMetadata
      choices_in_prompt: false
      metrics:
      - ROUGE
      - BLEU
      original_task: false
    name: Guess Title For Context
    reference: ''
  d055747f-7a32-4e12-aab1-fed35d42a445: !Template
    answer_choices: null
    id: d055747f-7a32-4e12-aab1-fed35d42a445
    jinja: "\u5728\u7EBF\u627E\u5230\u4EE5\u4E0B\u6587\u7AE0\uFF0C\u4F7F\u7528\u5B83\
      \u56DE\u7B54\u4EE5\u4E0B\u95EE\u9898\uFF1A {{question}}\n\n{{context}}|||\n\
      {{answers.text | choice}}\n"
    metadata: !TemplateMetadata
      choices_in_prompt: false
      metrics:
      - Squad
      original_task: true
    name: Found Context Online
    reference: ''
  d1abb8a0-03c4-41ef-865c-aa275278a0e4: !Template
    answer_choices: null
    id: d1abb8a0-03c4-41ef-865c-aa275278a0e4
    jinja: "\u4E00\u4E2A\u670B\u53CB\u8981\u6C42\u6211\u56DE\u7B54\u8FD9\u4E2A\u95EE\
      \u9898\uFF1A{{Quartion}}\uFF0C\u4F7F\u7528\u6587\u7AE0\uFF1A{{context}}\uFF0C\
      \u7B54\u6848\u662F\u4EC0\u4E48\uFF1F\n\n|||\n{{answers.text | choice}}\n"
    metadata: !TemplateMetadata
      choices_in_prompt: false
      metrics:
      - Squad
      original_task: true
    name: Answer Friend Question
    reference: ''
  fcbe0609-06ce-4cbd-91de-adc38966bcac: !Template
    answer_choices: null
    id: fcbe0609-06ce-4cbd-91de-adc38966bcac
    jinja: "\u9605\u8BFB\u4EE5\u4E0B\u6BB5\u843D\uFF0C\u5E76\u63D0\u53D6\u7B54\u6848\
      \u7684\u95EE\u9898\uFF1A {{question}}\n\n{{context}} |||\n{{answers.text | choice}}"
    metadata: !TemplateMetadata
      choices_in_prompt: false
      metrics:
      - Squad
      original_task: true
    name: 'Read And Extract '
    reference: ''
