dataset: quoref
subset: ja
templates:
  4120bebc-9c8f-44af-8d1a-a65e443ce010: !Template
    answer_choices: null
    id: 4120bebc-9c8f-44af-8d1a-a65e443ce010
    jinja: "\u8CEA\u554F\u3078\u306E\u7B54\u3048\uFF1A{{question}}\u306F\u8A18\u4E8B\
      \u306E\u4E2D\u306B\u3042\u308A\u307E\u3059\uFF1A{{context}}\u3001\u3042\u306A\
      \u305F\u306F\u305D\u308C\u3092\u63A8\u6E2C\u3067\u304D\u307E\u3059\u304B\uFF1F\
      \n\n|||\n{{answers.text | choice}}\n"
    metadata: !TemplateMetadata
      choices_in_prompt: false
      metrics:
      - Squad
      original_task: true
    name: Guess Answer
    reference: ''
  6f1d5031-1377-4b8a-9475-987b2275b8da: !Template
    answer_choices: null
    id: 6f1d5031-1377-4b8a-9475-987b2275b8da
    jinja: "\u6B21\u306E\u30B3\u30F3\u30C6\u30AD\u30B9\u30C8\u304C\u4E0E\u3048\u3089\
      \u308C\u307E\u3059\uFF1A\n\n{{context}}\n\n\u6B21\u306E\u554F\u984C\u3092\u7B54\
      \u3048\u3066\uFF1A\n\n{{question}} |||\n{{answers.text | choice}}"
    metadata: !TemplateMetadata
      choices_in_prompt: false
      metrics:
      - Squad
      original_task: true
    name: Answer Question Given Context
    reference: ''
  9493f80a-daf5-4c30-a9fc-7bc5bc61b5e9: !Template
    answer_choices: null
    id: 9493f80a-daf5-4c30-a9fc-7bc5bc61b5e9
    jinja: "\u6B21\u306E\u8A18\u4E8B\u306B\u306F\u3001\u8CEA\u554F\u306B\u5BFE\u3059\
      \u308B\u56DE\u7B54\u304C\u542B\u307E\u308C\u3066\u3044\u307E\u3059\u3002{{question}}\u3001\
      \u898B\u3064\u3051\u3066\u3044\u305F\u3060\u3051\u307E\u3059\u304B\uFF1F \n\n\
      {{context}}|||\n{{answers.text | choice}}"
    metadata: !TemplateMetadata
      choices_in_prompt: false
      metrics:
      - Squad
      original_task: true
    name: Find Answer
    reference: ''
  a3e5e25d-0a87-4cb8-89ab-3539fc4d23cb: !Template
    answer_choices: null
    id: a3e5e25d-0a87-4cb8-89ab-3539fc4d23cb
    jinja: "\u3053\u306E\u8A18\u4E8B\uFF1A{{context}}\u306B\u306F\u3001\u8CEA\u554F\
      \u306B\u5BFE\u3059\u308B\u7B54\u3048\u304C\u542B\u307E\u308C\u3066\u3044\u307E\
      \u3059\u3002{{question}}\u3001\u305D\u308C\u306F\u4F55\u3067\u3059\u304B\uFF1F\
      \n|||\n{{answers.text | choice}}"
    metadata: !TemplateMetadata
      choices_in_prompt: false
      metrics:
      - Squad
      original_task: true
    name: Context Contains Answer
    reference: ''
  aa26aab2-d2e7-4560-b7eb-0cbcff7c0f31: !Template
    answer_choices: null
    id: aa26aab2-d2e7-4560-b7eb-0cbcff7c0f31
    jinja: "{{question}}\n\n\u4EE5\u4E0B\u306E\u30B3\u30F3\u30C6\u30AD\u30B9\u30C8\
      \u306B\u57FA\u3065\u3044\u3066\u4E0A\u8A18\u306E\u8CEA\u554F\u306B\u7B54\u3048\
      \u3066\u304F\u3060\u3055\u3044\u3002\n\n{{context}} |||\n{{answers.text | choice}}"
    metadata: !TemplateMetadata
      choices_in_prompt: false
      metrics:
      - Squad
      original_task: true
    name: Given Context Answer Question
    reference: ''
  abdfa570-2de5-406c-9051-caa6a1362796: !Template
    answer_choices: null
    id: abdfa570-2de5-406c-9051-caa6a1362796
    jinja: "\u8CEA\u554F\u306B\u5BFE\u3059\u308B\u7B54\u3048\u306F\u4F55\u3067\u3059\
      \u304B\uFF1A{{question}}\u6B21\u306E\u8A18\u4E8B\u304B\u3089\uFF1F\n\n{{context}}|||\n\
      {{answers.text | choice}}\n"
    metadata: !TemplateMetadata
      choices_in_prompt: false
      metrics:
      - Squad
      original_task: true
    name: What Is The Answer
    reference: ''
  b3ec0888-dd6f-466a-abd4-b2fbcacfdb8b: !Template
    answer_choices: null
    id: b3ec0888-dd6f-466a-abd4-b2fbcacfdb8b
    jinja: "\u6B21\u306E\u8A18\u4E8B\u304C\u4E0E\u3048\u3089\u308C\u308B\u30C6\u30B9\
      \u30C8\u304C\u3042\u308A\u307E\u3059\u304C\u3001\u8CEA\u554F\u306B\u5BFE\u3059\
      \u308B\u7B54\u3048\u306F\u4F55\u3067\u3059\u304B\uFF1A{{question}}\uFF1F\n\n\
      {{context}}|||\n{{answers.text | choice}}"
    metadata: !TemplateMetadata
      choices_in_prompt: false
      metrics:
      - Squad
      original_task: true
    name: Answer Test
    reference: ''
  bf525757-8cde-4839-81fb-a85be3fd1192: !Template
    answer_choices: null
    id: bf525757-8cde-4839-81fb-a85be3fd1192
    jinja: "\u4EE5\u4E0B\u306E\u30B3\u30F3\u30C6\u30AD\u30B9\u30C8\u304C\u4E0E\u3048\
      \u3089\u308C\u307E\u3059\uFF1A\n\n{{context}}\n\n\u6709\u52B9\u306A\u30BF\u30A4\
      \u30C8\u30EB\u3092\u63A8\u6E2C\u3057\u3066\u304F\u3060\u3055\u3044\uFF01 |||\n\
      {{title}}"
    metadata: !TemplateMetadata
      choices_in_prompt: false
      metrics:
      - ROUGE
      - BLEU
      original_task: false
    name: Guess Title For Context
    reference: ''
  d055747f-7a32-4e12-aab1-fed35d42a445: !Template
    answer_choices: null
    id: d055747f-7a32-4e12-aab1-fed35d42a445
    jinja: "\u6B21\u306E\u8A18\u4E8B\u3092\u30AA\u30F3\u30E9\u30A4\u30F3\u3067\u898B\
      \u3064\u3051\u307E\u3057\u305F\u3002\u305D\u308C\u3092\u4F7F\u7528\u3057\u3066\
      \u8CEA\u554F\u306B\u7B54\u3048\u3066\u304F\u3060\u3055\u3044\u3002 {{question}}\n\
      \n{{context}}|||\n{{answers.text | choice}}\n"
    metadata: !TemplateMetadata
      choices_in_prompt: false
      metrics:
      - Squad
      original_task: true
    name: Found Context Online
    reference: ''
  d1abb8a0-03c4-41ef-865c-aa275278a0e4: !Template
    answer_choices: null
    id: d1abb8a0-03c4-41ef-865c-aa275278a0e4
    jinja: "\u53CB\u4EBA\u304C\u79C1\u306B\u3053\u306E\u8CEA\u554F\u306B\u7B54\u3048\
      \u308B\u3088\u3046\u306B\u983C\u307F\u307E\u3057\u305F\uFF1A{{\u8CEA\u554F}}\u3001\
      \u8A18\u4E8B\u3092\u4F7F\u7528\u3057\u3066\u304F\u3060\u3055\u3044\uFF1A{{context}}\u3001\
      \u7B54\u3048\u306F\u4F55\u3067\u3059\u304B\uFF1F\n\n|||\n{{answers.text | choice}}\n"
    metadata: !TemplateMetadata
      choices_in_prompt: false
      metrics:
      - Squad
      original_task: true
    name: Answer Friend Question
    reference: ''
  fcbe0609-06ce-4cbd-91de-adc38966bcac: !Template
    answer_choices: null
    id: fcbe0609-06ce-4cbd-91de-adc38966bcac
    jinja: "\u6B21\u306E\u6BB5\u843D\u3092\u8AAD\u3093\u3067\u3001\u8CEA\u554F\u306E\
      \u7B54\u3048\u3092\u62BD\u51FA\u3057\u307E\u3059\u3002 {{question}}\n\n{{context}}\
      \ |||\n{{answers.text | choice}}"
    metadata: !TemplateMetadata
      choices_in_prompt: false
      metrics:
      - Squad
      original_task: true
    name: 'Read And Extract '
    reference: ''
