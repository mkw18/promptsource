dataset: quoref
subset: vi
templates:
  4120bebc-9c8f-44af-8d1a-a65e443ce010: !Template
    answer_choices: null
    id: 4120bebc-9c8f-44af-8d1a-a65e443ce010
    jinja: "C\xE2u tr\u1EA3 l\u1EDDi cho c\xE2u h\u1ECFi: {{c\xE2u h\u1ECFi}} n\u1EB1\
      m trong b\xE0i vi\u1EBFt: {{b\u1ED1i c\u1EA3nh}}, b\u1EA1n c\xF3 \u0111o\xE1\
      n \u0111\u01B0\u1EE3c kh\xF4ng?\n\n|||\n{{answers.text | choice}}\n"
    metadata: !TemplateMetadata
      choices_in_prompt: false
      metrics:
      - Squad
      original_task: true
    name: Guess Answer
    reference: ''
  6f1d5031-1377-4b8a-9475-987b2275b8da: !Template
    answer_choices: null
    id: 6f1d5031-1377-4b8a-9475-987b2275b8da
    jinja: "\u0110\u01B0a ra b\u1ED1i c\u1EA3nh sau:\n\n{{context}}\n\nTr\u1EA3 l\u1EDD\
      i c\xE2u h\u1ECFi sau:\n\n{{question}} |||\n{{answers.text | choice}}"
    metadata: !TemplateMetadata
      choices_in_prompt: false
      metrics:
      - Squad
      original_task: true
    name: Answer Question Given Context
    reference: ''
  9493f80a-daf5-4c30-a9fc-7bc5bc61b5e9: !Template
    answer_choices: null
    id: 9493f80a-daf5-4c30-a9fc-7bc5bc61b5e9
    jinja: "B\xE0i vi\u1EBFt sau \u0111\xE2y ch\u1EE9a c\xE2u tr\u1EA3 l\u1EDDi cho\
      \ c\xE2u h\u1ECFi: {{c\xE2u h\u1ECFi}}, b\u1EA1n c\xF3 th\u1EC3 vui l\xF2ng\
      \ t\xECm th\u1EA5y n\xF3 kh\xF4ng? \n\n{{context}}|||\n{{answers.text | choice}}"
    metadata: !TemplateMetadata
      choices_in_prompt: false
      metrics:
      - Squad
      original_task: true
    name: Find Answer
    reference: ''
  a3e5e25d-0a87-4cb8-89ab-3539fc4d23cb: !Template
    answer_choices: null
    id: a3e5e25d-0a87-4cb8-89ab-3539fc4d23cb
    jinja: "B\xE0i vi\u1EBFt n\xE0y: {{b\u1ED1i c\u1EA3nh}} ch\u1EE9a c\xE2u tr\u1EA3\
      \ l\u1EDDi cho c\xE2u h\u1ECFi: {{c\xE2u h\u1ECFi}}, n\xF3 l\xE0 g\xEC?\n|||\n\
      {{answers.text | choice}}"
    metadata: !TemplateMetadata
      choices_in_prompt: false
      metrics:
      - Squad
      original_task: true
    name: Context Contains Answer
    reference: ''
  aa26aab2-d2e7-4560-b7eb-0cbcff7c0f31: !Template
    answer_choices: null
    id: aa26aab2-d2e7-4560-b7eb-0cbcff7c0f31
    jinja: "{{question}}\n\nTr\u1EA3 l\u1EDDi c\xE2u h\u1ECFi tr\xEAn d\u1EF1a tr\xEA\
      n b\u1ED1i c\u1EA3nh d\u01B0\u1EDBi \u0111\xE2y:\n\n{{context}} |||\n{{answers.text\
      \ | choice}}"
    metadata: !TemplateMetadata
      choices_in_prompt: false
      metrics:
      - Squad
      original_task: true
    name: Given Context Answer Question
    reference: ''
  abdfa570-2de5-406c-9051-caa6a1362796: !Template
    answer_choices: null
    id: abdfa570-2de5-406c-9051-caa6a1362796
    jinja: "C\xE2u tr\u1EA3 l\u1EDDi cho c\xE2u h\u1ECFi: {{c\xE2u h\u1ECFi}} t\u1EEB\
      \ b\xE0i vi\u1EBFt sau l\xE0 g\xEC?\n\n{{context}}|||\n{{answers.text | choice}}\n"
    metadata: !TemplateMetadata
      choices_in_prompt: false
      metrics:
      - Squad
      original_task: true
    name: What Is The Answer
    reference: ''
  b3ec0888-dd6f-466a-abd4-b2fbcacfdb8b: !Template
    answer_choices: null
    id: b3ec0888-dd6f-466a-abd4-b2fbcacfdb8b
    jinja: "T\xF4i c\xF3 m\u1ED9t b\xE0i ki\u1EC3m tra trong \u0111\xF3 t\xF4i \u0111\
      \u01B0\u1EE3c \u0111\u01B0a ra b\xE0i vi\u1EBFt sau, c\xE2u tr\u1EA3 l\u1EDD\
      i cho c\xE2u h\u1ECFi: {{c\xE2u h\u1ECFi}} l\xE0 g\xEC?\n\n{{context}}|||\n\
      {{answers.text | choice}}"
    metadata: !TemplateMetadata
      choices_in_prompt: false
      metrics:
      - Squad
      original_task: true
    name: Answer Test
    reference: ''
  bf525757-8cde-4839-81fb-a85be3fd1192: !Template
    answer_choices: null
    id: bf525757-8cde-4839-81fb-a85be3fd1192
    jinja: "\u0110\u01B0a ra b\u1ED1i c\u1EA3nh d\u01B0\u1EDBi \u0111\xE2y:\n\n{{context}}\n\
      \n\u0110o\xE1n m\u1ED9t ti\xEAu \u0111\u1EC1 h\u1EE3p l\u1EC7 cho n\xF3! |||\n\
      {{title}}"
    metadata: !TemplateMetadata
      choices_in_prompt: false
      metrics:
      - ROUGE
      - BLEU
      original_task: false
    name: Guess Title For Context
    reference: ''
  d055747f-7a32-4e12-aab1-fed35d42a445: !Template
    answer_choices: null
    id: d055747f-7a32-4e12-aab1-fed35d42a445
    jinja: "T\xECm th\u1EA5y b\xE0i vi\u1EBFt sau tr\u1EF1c tuy\u1EBFn, s\u1EED d\u1EE5\
      ng n\xF3 \u0111\u1EC3 tr\u1EA3 l\u1EDDi c\xE2u h\u1ECFi: {{question}}\n\n{{context}}|||\n\
      {{answers.text | choice}}\n"
    metadata: !TemplateMetadata
      choices_in_prompt: false
      metrics:
      - Squad
      original_task: true
    name: Found Context Online
    reference: ''
  d1abb8a0-03c4-41ef-865c-aa275278a0e4: !Template
    answer_choices: null
    id: d1abb8a0-03c4-41ef-865c-aa275278a0e4
    jinja: "M\u1ED9t ng\u01B0\u1EDDi b\u1EA1n \u0111\xE3 y\xEAu c\u1EA7u t\xF4i tr\u1EA3\
      \ l\u1EDDi c\xE2u h\u1ECFi n\xE0y: {{c\xE2u h\u1ECFi}}, s\u1EED d\u1EE5ng b\xE0\
      i vi\u1EBFt: {{b\u1ED1i c\u1EA3nh}}, c\xE2u tr\u1EA3 l\u1EDDi s\u1EBD l\xE0\
      \ g\xEC?\n\n|||\n{{answers.text | choice}}\n"
    metadata: !TemplateMetadata
      choices_in_prompt: false
      metrics:
      - Squad
      original_task: true
    name: Answer Friend Question
    reference: ''
  fcbe0609-06ce-4cbd-91de-adc38966bcac: !Template
    answer_choices: null
    id: fcbe0609-06ce-4cbd-91de-adc38966bcac
    jinja: "\u0110\u1ECDc \u0111o\u1EA1n sau v\xE0 tr\xEDch xu\u1EA5t c\xE2u tr\u1EA3\
      \ l\u1EDDi cho c\xE2u h\u1ECFi: {{question}}\n\n{{context}} |||\n{{answers.text\
      \ | choice}}"
    metadata: !TemplateMetadata
      choices_in_prompt: false
      metrics:
      - Squad
      original_task: true
    name: 'Read And Extract '
    reference: ''
