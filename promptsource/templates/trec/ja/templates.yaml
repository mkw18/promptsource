dataset: trec
subset: ja
templates:
  21d04668-c5b3-4418-bbb6-663f1ffdb97c: !Template
    answer_choices: "\u8AAC\u660E ||| \u5B9F\u5728\u7269 ||| \u7565\u8A9E ||| \u4EBA\
      \ ||| \u91CF ||| \u4F4D\u7F6E"
    id: 21d04668-c5b3-4418-bbb6-663f1ffdb97c
    jinja: "\u30AB\u30C6\u30B4\u30EA\u30FC: {{', '.join(answer_choices)}}\n\n\u6700\
      \u3082\u9069\u5207\u306A\u30AB\u30C6\u30B4\u30EA: {{text}} \n\u7B54\u3048\uFF1A\
      \ ||| {{ answer_choices [label_coarse] }}"
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
      - Accuracy
      original_task: true
    name: what_category_best_describe
    reference: ''
  2d4e0add-cfca-4f54-80a2-ddd8e91f9fd6: !Template
    answer_choices: "\u8857 ||| \u56FD ||| \u5C71 ||| \u5DDE ||| \u4ED6\u306E\u5834\
      \u6240"
    id: 2d4e0add-cfca-4f54-80a2-ddd8e91f9fd6
    jinja: "{% set label_mapping = {21:0, 18:1, 24:2, 11:3, 14:4} %}\n{% if label_coarse\
      \ == 5 %}\n\u3053\u306E\u8CEA\u554F\u306F{{', '.join(answer_choices)}}\u3092\
      \u6C42\u3081\u3066\u3044\u307E\u3059\u304B?\n{{text}}\n|||\n{{ answer_choices\
      \ [label_mapping[label_fine]] }}\n{% endif %}"
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
      - Accuracy
      original_task: false
    name: fine_grained_LOC
    reference: Fine grained labels with coarse-label `LOC`, context after question
  309bf243-2185-4090-ac66-a24f44d89966: !Template
    answer_choices: "\u30B3\u30FC\u30C9 ||| \u30AB\u30A6\u30F3\u30C8 ||| \u65E5\u306B\
      \u3061 ||| \u8DDD\u96E2 ||| \u4FA1\u683C ||| \u6CE8\u6587 ||| \u671F\u9593 |||\
      \ \u30D1\u30FC\u30BB\u30F3\u30C6\u30FC\u30B8 ||| \u901F\u5EA6 ||| \u6E29\u5EA6\
      \ ||| \u30B5\u30A4\u30BA ||| \u91CD\u3055 ||| \u305D\u306E\u4ED6\u306E\u756A\
      \u53F7"
    id: 309bf243-2185-4090-ac66-a24f44d89966
    jinja: "{% set label_mapping = {39:0, 13:1, 8:2, 40:3, 25:4, 43:5, 27:6, 38:7,\
      \ 35:8, 41:9, 32:10, 45:11, 14:12} %}\n{% if label_coarse == 4 %}\n{{text}}\n\
      \n\u3053\u306E\u8CEA\u554F\u306F{{', '.join(answer_choices)}}\u3092\u6C42\u3081\
      \u3066\u3044\u307E\u3059\u304B?\n|||\n{{ answer_choices [label_mapping[label_fine]]\
      \ }}\n{% endif %}"
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
      - Accuracy
      original_task: false
    name: fine_grained_NUM_context_first
    reference: Fine grained labels with coarse-label `NUM`, context provided first
  3aff84f3-e478-4598-abe8-40aa24cec1fa: !Template
    answer_choices: "\u52D5\u7269 ||| \u4F53\u306E\u81D3\u5668 ||| \u8272 ||| \u30AF\
      \u30EA\u30A8\u30A4\u30C6\u30A3\u30D6\u30D4\u30FC\u30B9 ||| \u901A\u8CA8 |||\
      \ \u75C5\u6C17\u3084\u85AC ||| \u30A4\u30D9\u30F3\u30C8 ||| \u98DF\u7269 |||\
      \ \u697D\u5668 ||| \u8A00\u8A9E ||| \u624B\u7D19 ||| \u5DE5\u5834 ||| \u88FD\
      \u54C1 ||| \u5B97\u6559 ||| \u30B9\u30DD\u30FC\u30C4 ||| \u7269\u8CEA ||| \u30B7\
      \u30F3\u30DC\u30EB ||| \u6280\u8853 ||| \u5B66\u671F ||| \u8ECA\u4E21 ||| \u8A9E\
      \ ||| \u4ED6\u306E\u30A8\u30F3\u30C6\u30A3\u30C6\u30A3"
    id: 3aff84f3-e478-4598-abe8-40aa24cec1fa
    jinja: "{% set label_mapping = {2:0, 22:1, 19:2, 1:3, 46:3, 23:4, 10:5, 17:6,\
      \ 33:7, 37:8, 15:9, 30:10, 26:11, 16:12, 28:13, 42:14, 31:15, 20:16, 44:17,\
      \ 36:18, 14:19} %}\n{% if label_coarse == 1 %}\n\u3053\u306E\u8CEA\u554F\u306F\
      {{', '.join(answer_choices)}}\u3092\u6C42\u3081\u3066\u3044\u307E\u3059\u304B\
      ?\n{{text}}\n|||\n{{ answer_choices [label_mapping[label_fine]] }}\n{% endif\
      \ %}"
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
      - Accuracy
      original_task: false
    name: fine_grained_ENTY
    reference: Fine grained labels with coarse-label `ENTY`, context after question
  43a188a2-b6dd-46a7-af2e-81a64b90b92a: !Template
    answer_choices: "\u30B3\u30FC\u30C9 ||| \u30AB\u30A6\u30F3\u30C8 ||| \u65E5\u306B\
      \u3061 ||| \u8DDD\u96E2 ||| \u4FA1\u683C ||| \u6CE8\u6587 ||| \u671F\u9593 |||\
      \ \u30D1\u30FC\u30BB\u30F3\u30C6\u30FC\u30B8 ||| \u901F\u5EA6 ||| \u6E29\u5EA6\
      \ ||| \u30B5\u30A4\u30BA ||| \u91CD\u3055 ||| \u305D\u306E\u4ED6\u306E\u756A\
      \u53F7"
    id: 43a188a2-b6dd-46a7-af2e-81a64b90b92a
    jinja: "{% set label_mapping = {39:0, 13:1, 8:2, 40:3, 25:4, 43:5, 27:6, 38:7,\
      \ 35:8, 41:9, 32:10, 45:11, 14:12} %}\n{% if label_coarse == 4 %}\n\u3053\u306E\
      \u8CEA\u554F\u306F{{', '.join(answer_choices)}}\u3092\u6C42\u3081\u3066\u3044\
      \u307E\u3059\u304B?\n{{text}}\n|||\n{{ answer_choices [label_mapping[label_fine]]\
      \ }}\n{% endif %}"
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
      - Accuracy
      original_task: false
    name: fine_grained_NUM
    reference: Fine grained labels with coarse-label `NUM`
  6c391f4f-027b-4425-88de-1dbb6aa706ee: !Template
    answer_choices: "\u8AAC\u660E ||| \u5B9F\u5728\u7269 ||| \u7565\u8A9E ||| \u4EBA\
      \ ||| \u91CF ||| \u4F4D\u7F6E"
    id: 6c391f4f-027b-4425-88de-1dbb6aa706ee
    jinja: "\u8CEA\u554F\uFF1A {{text}}\n\n\u8A18\u8FF0\u5B50: {{', '.join(answer_choices)}}\n\
      \n\u6700\u9AD8\u306E\u8A18\u8FF0\u5B50?\n|||\n{{answer_choices[label_coarse]}}"
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
      - Accuracy
      original_task: true
    name: pick_the_best_descriptor
    reference: ''
  71090d59-dd02-4cbd-8032-ad86179b9bd4: !Template
    answer_choices: "\u30DE\u30CA\u30FC ||| \u30AF\u30EA\u30A8\u30A4\u30C6\u30A3\u30D6\
      \u30D4\u30FC\u30B9 ||| \u52D5\u7269 ||| \u7701\u7565\u5F0F ||| \u500B\u4EBA\
      \ ||| \u30B0\u30EB\u30FC\u30D7 ||| \u984C\u540D ||| \u610F\u5473 ||| \u65E5\u306B\
      \u3061 ||| \u7406\u7531 ||| \u30A4\u30D9\u30F3\u30C8 ||| \u5DDE ||| \u8AAC\u660E\
      \ ||| \u30AB\u30A6\u30F3\u30C8 ||| \u4ED6\u306E ||| \u624B\u7D19 ||| \u5B97\u6559\
      \ ||| \u98DF\u3079\u7269 ||| \u30AB\u30A6\u30F3\u30C8ry ||| \u8272 ||| \u5B66\
      \u671F ||| \u8857 ||| \u4F53\u306E\u81D3\u5668 ||| \u75C5\u6C17\u3084\u85AC\
      \ ||| \u5C71 ||| \u4FA1\u683C ||| \u88FD\u54C1 ||| \u9650\u76EE ||| \u7269\u8CEA\
      \ ||| \u30B9\u30DD\u30FC\u30C4 ||| \u5DE5\u5834 ||| \u6280\u8853 ||| \u30B5\u30A4\
      \u30BA ||| \u697D\u5668 ||| \u7565\u8A9E ||| \u30B9\u30D4\u30FC\u30C9 ||| \u8A9E\
      \ ||| \u8A00\u8A9E ||| \u30D1\u30FC\u30BB\u30F3\u30C6\u30FC\u30B8 ||| \u30B3\
      \u30FC\u30C9 ||| \u8DDD\u96E2 ||| \u6E29\u5EA6 ||| \u30B7\u30F3\u30DC\u30EB\
      \ ||| \u6CE8\u6587 ||| \u8ECA\u4E21 ||| \u91CD\u3055 ||| \u901A\u8CA8"
    id: 71090d59-dd02-4cbd-8032-ad86179b9bd4
    jinja: "{{text}}\n\n\u3053\u306E\u8CEA\u554F\u306F\u4F55\u3092\u6C42\u3081\u3066\
      \u3044\u308B\u306E\u3067\u3059\u304B\uFF1F\n|||\n{{answer_choices[label_fine]\
      \ }}"
    metadata: !TemplateMetadata
      choices_in_prompt: false
      metrics:
      - Accuracy
      original_task: true
    name: fine_grained_open_context_first
    reference: Fine grained classes without providing choices, context first.
  736b2629-ed57-48ce-a458-4cbc435c499b: !Template
    answer_choices: "\u8857 ||| \u56FD ||| \u5C71 ||| \u5DDE ||| \u4ED6\u306E\u5834\
      \u6240"
    id: 736b2629-ed57-48ce-a458-4cbc435c499b
    jinja: "{% set label_mapping = {21:0, 18:1, 24:2, 11:3, 14:4} %}\n{% if label_coarse\
      \ == 5 %}\n{{text}}\n\n\u3053\u306E\u8CEA\u554F\u306F{{', '.join(answer_choices)}}\u3092\
      \u6C42\u3081\u3066\u3044\u307E\u3059\u304B?\n|||\n{{ answer_choices [label_mapping[label_fine]]\
      \ }}\n{% endif %}"
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
      - Accuracy
      original_task: false
    name: fine_grained_LOC_context_first
    reference: Fine grained labels with coarse-label `LOC`, context provided first
  7a3ed4dd-af89-493c-8efb-c67622f63034: !Template
    answer_choices: "\u8AAC\u660E ||| \u5B9F\u5728\u7269 ||| \u7565\u8A9E ||| \u4EBA\
      \ ||| \u91CF ||| \u4F4D\u7F6E"
    id: 7a3ed4dd-af89-493c-8efb-c67622f63034
    jinja: "\u6B21\u306E\u8CEA\u554F\u306B\u6700\u3082\u3088\u304F\u5F53\u3066\u306F\
      \u307E\u308B\u30AB\u30C6\u30B4\u30EA\u306F\u3069\u308C\u3067\u3059\u304B\u3002\
      \ {{text}} \n\n\u6B21\u306E\u30EA\u30B9\u30C8\u304B\u3089\u9078\u629E\u3057\u307E\
      \u3059\u3002 \n{{', '.join(answer_choices)}}\n ||| {{ answer_choices [label_coarse]\
      \ }}"
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
      - Accuracy
      original_task: true
    name: which_category_best_describes
    reference: ''
  7a9e6f3c-1dee-45b0-a315-1badaf59a7b8: !Template
    answer_choices: "\u610F\u5473 ||| \u8AAC\u660E ||| \u884C\u52D5\u306E\u4ED5\u65B9\
      \ ||| \u7406\u7531"
    id: 7a9e6f3c-1dee-45b0-a315-1badaf59a7b8
    jinja: "{% set label_mapping={0:2, 7:1,  12:0, 9:3} %}\n{% if label_coarse ==\
      \ 0 %}\n\u3053\u306E\u8CEA\u554F\u306F{{', '.join(answer_choices)}}\u3092\u6C42\
      \u3081\u3066\u3044\u307E\u3059\u304B?\n{{text}}\n|||\n{{ answer_choices[label_mapping[label_fine]]\
      \ }}\n{% endif %}"
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
      - Accuracy
      original_task: false
    name: fine_grained_DESC
    reference: Fine grained labels with coarse-label `DESC`, context after question
  861d1a48-1113-4f35-b777-2b2f12ab9d5d: !Template
    answer_choices: "\u8AAC\u660E ||| \u5B9F\u5728\u7269 ||| \u7565\u8A9E ||| \u4EBA\
      \ ||| \u91CF ||| \u4F4D\u7F6E"
    id: 861d1a48-1113-4f35-b777-2b2f12ab9d5d
    jinja: '{{text}}


      Is this asking about {{('', '').join(answer_choices)}}?

      |||

      {{ answer_choices [label_coarse] }}'
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
      - Accuracy
      original_task: true
    name: trec1
    reference: Context then prompt
  93a06e72-2c15-4f8a-a46c-6a10919c4ea4: !Template
    answer_choices: "\u7565\u8A9E ||| \u7701\u7565\u8868\u73FE"
    id: 93a06e72-2c15-4f8a-a46c-6a10919c4ea4
    jinja: "{% set label_mapping={34:0, 3:1} %} \n{% if label_coarse == 2 %}\n\u3053\
      \u306E\u8CEA\u554F\u306F{{', '.join(answer_choices)}}\u3092\u6C42\u3081\u3066\
      \u3044\u307E\u3059\u304B?\n{{text}}\n|||\n{{answer_choices[label_mapping[label_fine]]\
      \ }}\n{% endif %}"
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
      - Accuracy
      original_task: false
    name: fine_grained_ABBR
    reference: Fine grained labels with coarse-label `ABBR`, context after question
  a0096044-3b4c-4c80-b139-25eac8fe692a: !Template
    answer_choices: "\u7565\u8A9E ||| \u7701\u7565\u8868\u73FE"
    id: a0096044-3b4c-4c80-b139-25eac8fe692a
    jinja: "{% set label_mapping = {34:0, 3:1} %} \n{% if label_coarse == 2 %}\n{{text}}\n\
      \n\u3053\u306E\u8CEA\u554F\u306F{{', '.join(answer_choices)}}\u3092\u6C42\u3081\
      \u3066\u3044\u307E\u3059\u304B?\n|||\n{{ answer_choices [label_mapping[label_fine]]\
      \ }}\n{% endif %}"
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
      - Accuracy
      original_task: false
    name: fine_grained_ABBR_context_first
    reference: Fine grained labels with coarse-label `ABBR`, context provided first
  aad2def1-b694-40ee-9c26-3d1cf5c577da: !Template
    answer_choices: "\u8AAC\u660E ||| \u5B9F\u5728\u7269 ||| \u7565\u8A9E ||| \u4EBA\
      \ ||| \u91CF ||| \u4F4D\u7F6E"
    id: aad2def1-b694-40ee-9c26-3d1cf5c577da
    jinja: "\u6B21\u306E\u8CEA\u554F\u306F {{', '.join(answer_choices)}} \u306B\u95A2\
      \u3059\u308B\u8CEA\u554F\u3067\u3059\u304B?\n\n{{text}}\n|||\n{{ answer_choices\
      \ [label_coarse] }}"
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
      - Accuracy
      original_task: true
    name: trec2
    reference: Prompt then context
  bc58ba18-24a5-4553-be0a-2dba60efdad6: !Template
    answer_choices: "\u30B0\u30EB\u30FC\u30D7 ||| \u500B\u4EBA ||| \u984C\u540D |||\
      \ \u8AAC\u660E"
    id: bc58ba18-24a5-4553-be0a-2dba60efdad6
    jinja: "{% set label_mapping = {5:0, 4:1, 6:2, 12:3} %}\n{% if label_coarse ==\
      \ 3 %}\n\u3053\u306E\u8CEA\u554F\u306F{{', '.join(answer_choices)}}\u3092\u6C42\
      \u3081\u3066\u3044\u307E\u3059\u304B?\n{{text}}\n|||\n{{ answer_choices[label_mapping[label_fine]]\
      \ }}\n{% endif %}"
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
      - Accuracy
      original_task: false
    name: fine_grained_HUM
    reference: Fine grained labels with coarse-label `HUM`, context after question
  cfa8fde0-8320-4050-8d6e-7619ab14adea: !Template
    answer_choices: "\u30DE\u30CA\u30FC ||| \u30AF\u30EA\u30A8\u30A4\u30C6\u30A3\u30D6\
      \u30D4\u30FC\u30B9 ||| \u52D5\u7269 ||| \u7701\u7565\u5F0F ||| \u500B\u4EBA\
      \ ||| \u30B0\u30EB\u30FC\u30D7 ||| \u984C\u540D ||| \u610F\u5473 ||| \u65E5\u306B\
      \u3061 ||| \u7406\u7531 ||| \u30A4\u30D9\u30F3\u30C8 ||| \u5DDE ||| \u8AAC\u660E\
      \ ||| \u30AB\u30A6\u30F3\u30C8 ||| \u4ED6\u306E ||| \u624B\u7D19 ||| \u5B97\u6559\
      \ ||| \u98DF\u3079\u7269 ||| \u30AB\u30A6\u30F3\u30C8ry ||| \u8272 ||| \u5B66\
      \u671F ||| \u8857 ||| \u4F53\u306E\u81D3\u5668 ||| \u75C5\u6C17\u3084\u85AC\
      \ ||| \u5C71 ||| \u4FA1\u683C ||| \u88FD\u54C1 ||| \u9650\u76EE ||| \u7269\u8CEA\
      \ ||| \u30B9\u30DD\u30FC\u30C4 ||| \u5DE5\u5834 ||| \u6280\u8853 ||| \u30B5\u30A4\
      \u30BA ||| \u697D\u5668 ||| \u7565\u8A9E ||| \u30B9\u30D4\u30FC\u30C9 ||| \u8A9E\
      \ ||| \u8A00\u8A9E ||| \u30D1\u30FC\u30BB\u30F3\u30C6\u30FC\u30B8 ||| \u30B3\
      \u30FC\u30C9 ||| \u8DDD\u96E2 ||| \u6E29\u5EA6 ||| \u30B7\u30F3\u30DC\u30EB\
      \ ||| \u6CE8\u6587 ||| \u8ECA\u4E21 ||| \u91CD\u3055 ||| \u901A\u8CA8"
    id: cfa8fde0-8320-4050-8d6e-7619ab14adea
    jinja: "\u3053\u306E\u8CEA\u554F\u306F\u4F55\u3092\u6C42\u3081\u3066\u3044\u308B\
      \u306E\u3067\u3059\u304B\uFF1F\n\n{{text}}\n|||\n{{ answer_choices[label_fine]\
      \ }}"
    metadata: !TemplateMetadata
      choices_in_prompt: false
      metrics:
      - Accuracy
      original_task: true
    name: fine_grained_open
    reference: Fine grained classes without providing choices.
  e98b9294-76b4-4172-a78c-9c6e5fdfe73b: !Template
    answer_choices: "\u30B0\u30EB\u30FC\u30D7 ||| \u500B\u4EBA ||| \u984C\u540D |||\
      \ \u8AAC\u660E"
    id: e98b9294-76b4-4172-a78c-9c6e5fdfe73b
    jinja: "{% set label_mapping = {5:0, 4:1, 6:2, 12:3} %}\n{% if label_coarse ==\
      \ 3 %}\n{{text}}\n\n\u3053\u306E\u8CEA\u554F\u306F{{', '.join(answer_choices)}}\u3092\
      \u6C42\u3081\u3066\u3044\u307E\u3059\u304B?\n|||\n{{ answer_choices [label_mapping[label_fine]]\
      \ }}{% endif %}"
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
      - Accuracy
      original_task: false
    name: fine_grained_HUM_context_first
    reference: Fine grained labels with coarse-label `HUM`, context provided first
  fa588c55-5c69-4fd0-a0b1-edbfa092f710: !Template
    answer_choices: "\u610F\u5473 ||| \u8AAC\u660E ||| \u884C\u52D5\u306E\u4ED5\u65B9\
      \ ||| \u7406\u7531"
    id: fa588c55-5c69-4fd0-a0b1-edbfa092f710
    jinja: "{% set label_mapping={0:2, 7:1,  12:0, 9:3} %}\n{% if label_coarse ==\
      \ 0 %}\n{{text}}\n\n\u3053\u306E\u8CEA\u554F\u306F{{', '.join(answer_choices)}}\u3092\
      \u6C42\u3081\u3066\u3044\u307E\u3059\u304B?\n|||\n{{ answer_choices [label_mapping[label_fine]]\
      \ }}\n{% endif %}"
    metadata: !TemplateMetadata
      choices_in_prompt: false
      metrics:
      - Accuracy
      original_task: false
    name: fine_grained_DESC_context_first
    reference: Fine grained labels with coarse-label `DESC`, context provided first
