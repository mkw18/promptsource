dataset: xsum
subset: ko
templates:
  13c02904-e4e2-4b4f-b115-44b437d22041: !Template
    answer_choices: null
    id: 13c02904-e4e2-4b4f-b115-44b437d22041
    jinja: "{{document}}\n\n===\n\n\uC704\uC758 \uD14D\uC2A4\uD2B8 \uC694\uC57D\uC744\
      \ \uC791\uC131\uD558\uC2ED\uC2DC\uC624. ||| {{summary}}"
    metadata: !TemplateMetadata
      choices_in_prompt: false
      metrics:
      - ROUGE
      - BLEU
      original_task: true
    name: DOC_write_summary_of_above
    reference: ''
  30292806-8e58-463c-8d92-ba525411c6fa: !Template
    answer_choices: null
    id: 30292806-8e58-463c-8d92-ba525411c6fa
    jinja: "\uAE30\uC0AC: {{document}}\n\n\uC694\uC57D: ||| {{summary}}"
    metadata: !TemplateMetadata
      choices_in_prompt: false
      metrics:
      - ROUGE
      - BLEU
      original_task: true
    name: article_DOC_summary
    reference: Prefix-Tuning
  3d388a1e-3361-407b-baa7-61397cc58382: !Template
    answer_choices: null
    id: 3d388a1e-3361-407b-baa7-61397cc58382
    jinja: "{{document}}\n\uBA87 \uB9C8\uB514\uB85C \uC5B4\uB5BB\uAC8C \uB2E4\uC2DC\
      \ \uD45C\uD604 \uD558\uC2DC\uACA0\uC2B5\uB2C8\uAE4C? ||| {{summary}}"
    metadata: !TemplateMetadata
      choices_in_prompt: false
      metrics:
      - ROUGE
      - BLEU
      original_task: true
    name: DOC_how_would_you_rephrase_few_words
    reference: http://gptprompts.wikidot.com/prompt:summarization
  4cfe4126-b9f5-44eb-8a98-973987c5f32e: !Template
    answer_choices: null
    id: 4cfe4126-b9f5-44eb-8a98-973987c5f32e
    jinja: "\uB0B4 \uB300\uD559 \uB8F8\uBA54\uC774\uD2B8\uB294\uC774 \uAE30\uC0AC\uAC00\
      \ \uBB34\uC5C7\uC744 \uC758\uBBF8\uD558\uB294\uC9C0 \uBB3C\uC5C8\uC2B5\uB2C8\
      \uB2E4.\n\n{{document}}\n\n\uADF8\uB798\uC11C \uB098\uB294 \uD3C9\uC2E0\uB3C4\
      \uC758 \uC6A9\uC5B4\uB85C \uADF8\uAC83\uC744 \uC694\uC57D\uD588\uC2B5\uB2C8\uB2E4\
      . ||| {{summary}}"
    metadata: !TemplateMetadata
      choices_in_prompt: false
      metrics:
      - ROUGE
      - BLEU
      original_task: true
    name: college_roommate_asked_DOC_so_I_recap
    reference: http://gptprompts.wikidot.com/prompt:summarization
  57a7a3f1-91f8-4f4b-b72d-745d7cb7b1e3: !Template
    answer_choices: null
    id: 57a7a3f1-91f8-4f4b-b72d-745d7cb7b1e3
    jinja: "{{document}}\n\uC774\uAC83\uC740 \uB2E8\uC21C\uD55C \uC0DD\uAC01\uC73C\
      \uB85C \uADC0\uACB0\uB429\uB2C8\uB2E4 ||| {{summary}}"
    metadata: !TemplateMetadata
      choices_in_prompt: false
      metrics:
      - ROUGE
      - BLEU
      original_task: true
    name: DOC_boils_down_to_simple_idea_that
    reference: http://gptprompts.wikidot.com/prompt:summarization
  65a3c419-57e9-48c2-b090-0c5d7adb23c6: !Template
    answer_choices: null
    id: 65a3c419-57e9-48c2-b090-0c5d7adb23c6
    jinja: "\uC694\uC57D\uD558\uB2E4: {{document}}|||\n{{summary}}"
    metadata: !TemplateMetadata
      choices_in_prompt: false
      metrics:
      - ROUGE
      - BLEU
      original_task: true
    name: summarize_DOC
    reference: ''
  752fda48-e64c-47a7-8342-17c2c113f600: !Template
    answer_choices: null
    id: 752fda48-e64c-47a7-8342-17c2c113f600
    jinja: "\uC774 \uBB38\uC11C\uB97C \uC694\uC57D\uD558\uC2ED\uC2DC\uC624. {{document}}\n\
      \uC694\uC57D: ||| {{summary}}"
    metadata: !TemplateMetadata
      choices_in_prompt: false
      metrics:
      - ROUGE
      - BLEU
      original_task: true
    name: summarize_this_DOC_summary
    reference: ''
  826ffcd4-c0e6-4f4c-bd9a-fcf8ee169ede: !Template
    answer_choices: null
    id: 826ffcd4-c0e6-4f4c-bd9a-fcf8ee169ede
    jinja: "{{document}}\n\n===\n\n\uC704\uC758 \uBB38\uC11C\uAC00 \uC8FC\uC5B4\uC9C0\
      \uBA74 \uD55C \uBB38\uC7A5\uC744 \uC791\uC131\uD558\uC5EC \uC694\uC57D\uD569\
      \uB2C8\uB2E4. ||| {{summary}}"
    metadata: !TemplateMetadata
      choices_in_prompt: false
      metrics:
      - ROUGE
      - BLEU
      original_task: true
    name: DOC_given_above_write_one_sentence
    reference: ''
  9a3f617f-628f-4fa5-9b74-47d0b166a487: !Template
    answer_choices: null
    id: 9a3f617f-628f-4fa5-9b74-47d0b166a487
    jinja: "\uBA3C\uC800 \uC544\uB798 \uAE30\uC0AC\uB97C \uC77D\uC73C\uC2ED\uC2DC\uC624\
      .\n\n{{document}}\n\n\uC790, \uB2F9\uC2E0\uC740 \uC800\uC5D0\uAC8C \uB9E4\uC6B0\
      \ \uC9E7\uC740 \uCD08\uB85D\uC744 \uC4F8 \uC218 \uC788\uC2B5\uB2C8\uAE4C?  |||\
      \ {{summary}}"
    metadata: !TemplateMetadata
      choices_in_prompt: false
      metrics:
      - ROUGE
      - BLEU
      original_task: true
    name: read_below_DOC_write_abstract
    reference: ''
  d878b768-9da2-4d9d-9517-1edcca3b1b26: !Template
    answer_choices: null
    id: d878b768-9da2-4d9d-9517-1edcca3b1b26
    jinja: "{{document}}\n\n\uB108\uBB34 \uC624\uB798;\uC77D\uC9C0 \uC54A\uC558\uB2E4\
      \ : ||| {{summary}}"
    metadata: !TemplateMetadata
      choices_in_prompt: false
      metrics:
      - ROUGE
      - BLEU
      original_task: true
    name: DOC_tldr
    reference: GPT-2 TLDR
