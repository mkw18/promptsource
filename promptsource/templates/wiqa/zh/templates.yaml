dataset: wiqa
subset: zh
templates:
  1bc8d95b-0a50-49f4-a46b-bd752929926d: !Template
    answer_choices: null
    id: 1bc8d95b-0a50-49f4-a46b-bd752929926d
    jinja: "-  {{ question_para_step[1:] | join(\"\\n- \") }}\n\n\u8BE5\u8FC7\u7A0B\
      \u7684\u7B2C\u4E00\u6B65\u53EF\u80FD\u662F\u4EC0\u4E48\uFF1F\n\n|||\n\n{{ question_para_step\
      \ | first }}\n"
    metadata: !TemplateMetadata
      choices_in_prompt: false
      metrics:
      - BLEU
      - ROUGE
      original_task: false
    name: what_might_be_the_first_step_of_the_process
    reference: ''
  360cd99a-2f83-469a-a505-d80808159dd2: !Template
    answer_choices: null
    id: 360cd99a-2f83-469a-a505-d80808159dd2
    jinja: "\n{% set process_list = question_para_step[:-1] if question_para_step[-1]\
      \ == \"\" else question_para_step %}\n-  {{ process_list[:-1] | join(\"\\n-\
      \ \") }}\n\n\u8BE5\u8FC7\u7A0B\u7684\u6700\u540E\u4E00\u6B65\u53EF\u80FD\u662F\
      \u4EC0\u4E48\uFF1F\n\n|||\n\n{{ process_list | last }}\n"
    metadata: !TemplateMetadata
      choices_in_prompt: false
      metrics:
      - BLEU
      - ROUGE
      original_task: false
    name: what_might_be_the_last_step_of_the_process
    reference: ''
  4191b162-9220-46e5-a2f0-0a763eef55a0: !Template
    answer_choices: null
    id: 4191b162-9220-46e5-a2f0-0a763eef55a0
    jinja: "\u4EE5\u4E0B\u8FC7\u7A0B\u4E2D\u7F3A\u5C11\u7684\u7B2C\u4E00\u6B65\u662F\
      \u4EC0\u4E48\uFF1A\n\n-  {{ question_para_step[1:] | join(\"\\n- \") }}\n\n\
      |||\n\n{{ question_para_step | first }}"
    metadata: !TemplateMetadata
      choices_in_prompt: false
      metrics:
      - BLEU
      - ROUGE
      original_task: false
    name: what_is_the_missing_first_step
    reference: ''
  52d69c02-5ff3-4fe7-bcaf-a6b995a15020: !Template
    answer_choices: null
    id: 52d69c02-5ff3-4fe7-bcaf-a6b995a15020
    jinja: " {% set process_list = question_para_step[:-1] if question_para_step[-1]\
      \ == \"\" else question_para_step %}\n\u4EE5\u4E0B\u8FC7\u7A0B\u7684\u6700\u540E\
      \u4E00\u6B65\u662F\u4EC0\u4E48\uFF1A\n-  {{ process_list[:-1] | join(\"\\n-\
      \ \") }}\n\n|||\n\n{{ process_list | last }}\n"
    metadata: !TemplateMetadata
      choices_in_prompt: false
      metrics:
      - BLEU
      - ROUGE
      original_task: false
    name: what_is_the_final_step_of_the_following_process
    reference: ''
  5dfee2c2-9742-4003-8ab6-dfe0ce5a745b: !Template
    answer_choices: '{{choices.text | join("|||")}}'
    id: 5dfee2c2-9742-4003-8ab6-dfe0ce5a745b
    jinja: "\u8FC7\u7A0B\uFF1A\n- {{ question_para_step | join(\"\\n- \")}}\n\n\u95EE\
      \u9898\uFF1A\n{{question_stem}}\n\n\u5047\u5B9A\u7684\u6270\u52A8\u5982\u4F55\
      \u5F71\u54CD\u63D0\u5230\u7684\u7B2C\u4E8C\u6548\u679C\u3002\u56DE\u7B54 {{\"\
      more, less or no effect\"}}\n\n|||\n\n{{answer_label|replace(\"_\", \" \")}}"
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
      - Accuracy
      original_task: true
    name: effect_with_string_answer
    reference: ''
  667c291f-6a36-4334-aa49-804c9e72500b: !Template
    answer_choices: "\u95F4\u63A5\u5F71\u54CD\u6D41\u7A0B\u7684\u4E00\u6B65 ||| \u4E0D\
      \u5F71\u54CD\u8BE5\u8FC7\u7A0B\u7684\u4EFB\u4F55\u6B65\u9AA4"
    id: 667c291f-6a36-4334-aa49-804c9e72500b
    jinja: "\u8FC7\u7A0B\uFF1A\n\n- {{ question_para_step | join(\"\\n- \") }}\n\n\
      {{question_stem}}\n\n\u4EE5\u4E0B\u54EA\u9879\u662F\u6240\u8C13\u7684\u6270\u52A8\
      \uFF1F\n\n- {{\"\u76F4\u63A5\u5F71\u54CD\u6D41\u7A0B\u7684\u4E00\u6B65\"}}\n\
      - {{\"\u95F4\u63A5\u5F71\u54CD\u6D41\u7A0B\u7684\u4E00\u6B65\"}}\n- {{\"\u4E0D\
      \u5F71\u54CD\u8BE5\u8FC7\u7A0B\u7684\u4EFB\u4F55\u6B65\u9AA4\"}}\n\n\n|||\n\n\
      {{{\"EXOGENOUS_EFFECT\": \"\u95F4\u63A5\u5F71\u54CD\u6D41\u7A0B\u7684\u4E00\u6B65\
      \", \"OUTOFPARA_DISTRACTOR\": \"\u4E0D\u5F71\u54CD\u8BE5\u8FC7\u7A0B\u7684\u4EFB\
      \u4F55\u6B65\u9AA4\", \"INPARA_EFFECT\": \"\u76F4\u63A5\u5F71\u54CD\u6D41\u7A0B\
      \u7684\u4E00\u6B65\"}[metadata_question_type]}}"
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
      - Accuracy
      original_task: false
    name: which_of_the_following_is_the_supposed_perturbation
    reference: ''
  6cf2b300-6790-4120-9592-9db63bec221b: !Template
    answer_choices: A ||| B ||| C
    id: 6cf2b300-6790-4120-9592-9db63bec221b
    jinja: "\u8FC7\u7A0B\uFF1A\n- {{ question_para_step | join(\"\\n- \")}}\n\n\u95EE\
      \u9898\uFF1A\n{{question_stem}}\n\n- {{\"A: more\"}}\n- {{\"B: less\"}}\n- {{\"\
      C: no effect\"}}\n\n|||\n\n{{answer_label_as_choice}}"
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
      - Accuracy
      original_task: true
    name: effect_with_label_answer
    reference: ''
  a17313bd-94bb-47ab-82bf-538df1b1ad5f: !Template
    answer_choices: "\u662F\u7684 ||| \u4E0D"
    id: a17313bd-94bb-47ab-82bf-538df1b1ad5f
    jinja: "\u8FC7\u7A0B\uFF1A\n\n- {{ question_para_step | join(\"\\n- \") }}\n\n\
      \u6270\u52A8\u5047\u8BBE\uFF1A\n{{question_stem}}\n\n\u5047\u5B9A\u7684\u6270\
      \u52A8\u662F\u5426\u5BF9\u8BE5\u8FC7\u7A0B\u4EA7\u751F\u5F71\u54CD\uFF08\u76F4\
      \u63A5\u6216\u95F4\u63A5\uFF09\uFF1F\n\n|||\n\n{{{\"EXOGENOUS_EFFECT\": \"\u662F\
      \u7684\", \"OUTOFPARA_DISTRACTOR\": \"\u4E0D\", \"INPARA_EFFECT\": \"\u662F\u7684\
      \"}[metadata_question_type]}}"
    metadata: !TemplateMetadata
      choices_in_prompt: false
      metrics:
      - Accuracy
      original_task: false
    name: does_the_supposed_perturbation_have_an_effect
    reference: ''
