dataset: super_glue
subset: copa_ur
templates:
  0edd8660-f299-4819-a5ac-633c11177228: !Template
    answer_choices: '{{choice1}} ||| {{choice2}}'
    id: 0edd8660-f299-4819-a5ac-633c11177228
    jinja: "\u0648\u0631\u0632\u0634: \u0627\u0646\u062A\u06C1\u0627\u0626\u06CC \u0642\
      \u0627\u0628\u0644 \u0627\u062D\u062A\u0631\u0627\u0645 \u0645\u062A\u0628\u0627\
      \u062F\u0644 \u06A9\u0627 \u0627\u0646\u062A\u062E\u0627\u0628 \u06A9\u0631\u06CC\
      \u06BA\u06D4\n\n{{ premise }} {% if question == \"cause\" %} \u06A9\u06CC\u0648\
      \u0646\u06A9\u06C1... {% else %} \u062A\u0648... {% endif %}\n- {{choice1}}\n\
      - {{choice2}} ||| {% if label != -1 %}{{ answer_choices[label] }}{%endif%}"
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
      - Accuracy
      original_task: true
    name: exercise
    reference: ''
  150789fe-e309-47a1-82c9-0a4dc2c6b12b: !Template
    answer_choices: '{{choice1}} ||| {{choice2}}'
    id: 150789fe-e309-47a1-82c9-0a4dc2c6b12b
    jinja: "{% if question == \"effect\" %} \n{{ premise }} \u0622\u06AF\u06D2 \u06A9\
      \u06CC\u0627 \u06C1\u0648\u0633\u06A9\u062A\u0627 \u06C1\u06D2 \u060C \"{{ answer_choices[0]\
      \ }}\" \u06CC\u0627 \"{{ answer_choices[1] }}\"\u061F ||| {% if label != -1\
      \ %}{{ answer_choices[label] }}{%endif%}\n{% endif %}"
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
      - Accuracy
      original_task: true
    name: "\u2026What could happen next, C1 or C2?"
    reference: ''
  4d879cbe-2fd7-424a-9d78-3f5200313fba: !Template
    answer_choices: '{{choice1}} ||| {{choice2}}'
    id: 4d879cbe-2fd7-424a-9d78-3f5200313fba
    jinja: "{{ premise }} \n\n\u0645\u06CC\u06BA \u062F\u0648 \u0627\u062E\u062A\u06CC\
      \u0627\u0631\u0627\u062A \u06A9\u06D2 \u0645\u0627\u0628\u06CC\u0646 \u06C1\u0686\
      \u06A9\u0686\u0627\u06C1\u0679 \u0645\u062D\u0633\u0648\u0633 \u06A9\u0631 \u0631\
      \u06C1\u0627 \u06C1\u0648\u06BA\u06D4 \u0632\u06CC\u0627\u062F\u06C1 \u0627\u0645\
      \u06A9\u0627\u0646 \u06A9\u0627 \u0627\u0646\u062A\u062E\u0627\u0628 \u06A9\u0631\
      \u0646\u06D2 \u0645\u06CC\u06BA \u0645\u06CC\u0631\u06CC \u0645\u062F\u062F\
      \ \u06A9\u0631\u06CC\u06BA {% if question == \"cause\" %} \u0648\u062C\u06C1\
      : {% else %} \u0627\u062B\u0631: {% endif %}\n- {{choice1}}\n- {{choice2}} |||\
      \ {% if label != -1 %}{{ answer_choices[label] }}{%endif%}"
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
      - Accuracy
      original_task: true
    name: i_am_hesitating
    reference: ''
  66ea075e-4d03-4a78-b1fa-9a5228cf0c9d: !Template
    answer_choices: '{{choice1}} ||| {{choice2}}'
    id: 66ea075e-4d03-4a78-b1fa-9a5228cf0c9d
    jinja: "{{ premise }} {% if question == \"cause\" %} \u06CC\u06C1 \u0627\u0633\
      \ \u0644\u0626\u06D2 \u06C1\u0648\u0627 \u06A9\u06C1... {% else %} \u0646\u062A\
      \u06CC\u062C\u06C1 \u06A9\u06D2 \u0637\u0648\u0631 \u067E\u0631... {% endif\
      \ %}\n\u0645\u0632\u06CC\u062F \u0642\u0627\u0628\u0644 \u0639\u0645\u0644 \u0622\
      \u067E\u0634\u0646 \u06A9\u0648 \u0645\u0646\u062A\u062E\u0628 \u06A9\u0631\u0646\
      \u06D2 \u0645\u06CC\u06BA \u0645\u06CC\u0631\u06CC \u0645\u062F\u062F \u06A9\
      \u0631\u06CC\u06BA:\n- {{choice1}}\n- {{choice2}} ||| {% if label != -1 %}{{\
      \ answer_choices[label] }}{%endif%}"
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
      - Accuracy
      original_task: true
    name: plausible_alternatives
    reference: ''
  744047dc-1298-45a2-8d68-d67e3f834ded: !Template
    answer_choices: '{{choice1 }} ||| {{choice2}}'
    id: 744047dc-1298-45a2-8d68-d67e3f834ded
    jinja: "\"{{ answer_choices[0] }}\" \u06CC\u0627 \"{{ answer_choices[1] }}\"\u061F\
      \ {{ premise }} {% if question == \"cause\" %} \u06A9\u06CC\u0648\u0646\u06A9\
      \u06C1 {% else %} \u062A\u0648 {% endif %} ||| {% if label != -1 %}{{ answer_choices[label]\
      \ }}{% endif %}"
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
      - Accuracy
      original_task: true
    name: "C1 or C2? premise, so/because\u2026"
    reference: "Adapted from Perez et al. 2021 and Schick & Sch\xFCtz 2021."
  84da62c2-9440-4cfc-bdd4-d70c65e33a82: !Template
    answer_choices: '{{choice1}} ||| {{choice2}}'
    id: 84da62c2-9440-4cfc-bdd4-d70c65e33a82
    jinja: "{% if question == \"effect\" %} \n{{ premise }} \u0646\u062A\u06CC\u062C\
      \u06D2 \u06A9\u06D2 \u0637\u0648\u0631 \u067E\u0631 \u060C \"{{ answer_choices[0]\
      \ }}\" \u06CC\u0627 \"{{ answer_choices[1] }}\"\u061F ||| {% if label != -1\
      \ %}{{ answer_choices[label] }}{%endif%}\n{% endif %}"
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
      - Accuracy
      original_task: true
    name: "\u2026As a result, C1 or C2?"
    reference: ''
  8ce80f8a-239e-4393-892c-f63dbb0d9929: !Template
    answer_choices: '{{choice1}} ||| {{choice2}}'
    id: 8ce80f8a-239e-4393-892c-f63dbb0d9929
    jinja: "{{ premise }} \n\n\u0628\u06C1\u062A\u0631\u06CC\u0646 \u0622\u067E\u0634\
      \u0646 \u06A9\u06CC\u0627 \u06C1\u06D2\u061F\n- {{choice1}}\n- {{choice2}}\n\
      \n\u06C1\u0645 \u062A\u0644\u0627\u0634 \u0645\u06CC\u06BA \u06C1\u06CC\u06BA\
      \ {% if question == \"cause\" %} \u0627\u06CC\u06A9 \u0648\u062C\u06C1 {% else\
      \ %} \u0627\u06CC\u06A9 \u0627\u062B\u0631 {% endif %}\n||| {% if label != -1\
      \ %}{{answer_choices[label]}}{%endif%}"
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
      - Accuracy
      original_task: true
    name: best_option
    reference: ''
  8cf2ba73-aee5-4651-b5d4-b1b88afe4abb: !Template
    answer_choices: '{{choice1}} ||| {{choice2}}'
    id: 8cf2ba73-aee5-4651-b5d4-b1b88afe4abb
    jinja: "{% if question == \"cause\" %} \n{{ premise }} \u062C\u0633 \u06A9\u06CC\
      \ \u0648\u062C\u06C1 \"{{ answer_choices[0] }}\" \u06CC\u0627 \"{{ answer_choices[1]\
      \ }}\" \u06A9\u06CC \u0648\u062C\u06C1 \u0633\u06D2 \u06C1\u0648\u0633\u06A9\
      \u062A\u0627 \u06C1\u06D2\u061F ||| {% if label != -1 %}{{ answer_choices[label]\
      \ }}{%endif%}\n{% endif %}"
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
      - Accuracy
      original_task: true
    name: "\u2026which may be caused by"
    reference: ''
  a1f9951e-2b6b-4530-9636-9cdf4c1658c5: !Template
    answer_choices: '{{choice1}} ||| {{choice2}}'
    id: a1f9951e-2b6b-4530-9636-9cdf4c1658c5
    jinja: "\u0645\u0646\u062F\u0631\u062C\u06C1 \u0630\u06CC\u0644 \u062C\u0645\u0644\
      \u06D2 \u0645\u06CC\u06BA \u0632\u06CC\u0627\u062F\u06C1 \u0633\u06D2 \u0632\
      \u06CC\u0627\u062F\u06C1 \u062A\u0633\u0644\u0633\u0644 \u06A9\u0627 \u0627\u0646\
      \u062A\u062E\u0627\u0628 \u06A9\u0631\u06CC\u06BA:\n{{ premise }} {% if question\
      \ == \"cause\" %} \u0627\u0633 \u06A9\u06D2 \u0646\u062A\u06CC\u062C\u06D2 \u0645\
      \u06CC\u06BA: {% else %} \u0646\u062A\u06CC\u062C\u06C1 \u06A9\u06D2 \u0637\u0648\
      \u0631 \u067E\u0631: {% endif %}\n- {{choice1}}\n- {{choice2}} ||| {% if label\
      \ != -1 %}{{ answer_choices[label] }}{%endif%}"
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
      - Accuracy
      original_task: true
    name: more likely
    reference: ''
  a61d8c21-da25-47bf-b5fe-14a8edd650af: !Template
    answer_choices: '{{choice1}} ||| {{choice2}}'
    id: a61d8c21-da25-47bf-b5fe-14a8edd650af
    jinja: "{{ premise }}\n\n\u0627\u0646\u062A\u06C1\u0627\u0626\u06CC \u0642\u0627\
      \u0628\u0644 \u0641\u06C1\u0645 \u0645\u0646\u062A\u062E\u0628 \u06A9\u0631\u06CC\
      \u06BA {% if question == \"cause\" %} \u0648\u062C\u06C1: {% else %} \u0627\u062B\
      \u0631: {% endif %}\n- {{choice1}}\n- {{choice2}} ||| {% if label != -1 %}{{\
      \ answer_choices[label] }}{%endif%}"
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
      - Accuracy
      original_task: true
    name: cause_effect
    reference: ''
  a8bf11c3-bea2-45ba-a533-957d8bee5e2e: !Template
    answer_choices: '{{choice1}} ||| {{choice2}}'
    id: a8bf11c3-bea2-45ba-a533-957d8bee5e2e
    jinja: "{% if question == \"cause\" %} \n{{ premise }} \u06A9\u06CC\u0648\u06BA\
      \u061F \"{{ answer_choices[0] }}\" \u06CC\u0627 \"{{ answer_choices[1] }}\"\u061F\
      \ ||| {% if label != -1 %}{{ answer_choices[label] }}{%endif%}\n{% endif %}"
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
      - Accuracy
      original_task: true
    name: "\u2026why? C1 or C2"
    reference: ''
  f32348cd-d3cb-4619-87b9-e24f99c78567: !Template
    answer_choices: '{{choice1}} ||| {{choice2}}'
    id: f32348cd-d3cb-4619-87b9-e24f99c78567
    jinja: "{{ premise }} {% if question == \"cause\" %} \u06A9\u06CC\u0648\u0646\u06A9\
      \u06C1... {% else %} \u062A\u0648... {% endif %}\n\u06A9\u06D2 \u062F\u0631\u0645\
      \u06CC\u0627\u0646 \u0627\u0646\u062A\u062E\u0627\u0628 \u06A9\u0631\u06CC\u06BA\
      :\n- {{choice1}}\n- {{choice2}} ||| {% if label != -1 %}{{ answer_choices[label]\
      \ }}{%endif%}"
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
      - Accuracy
      original_task: true
    name: choose
    reference: ''
