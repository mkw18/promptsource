dataset: super_glue
subset: multirc_hi
templates:
  2d95962b-a545-41ae-8d76-07ee6704ef65: !Template
    answer_choices: "\u0928\u0939\u0940\u0902 ||| \u0939\u093E\u0901"
    id: 2d95962b-a545-41ae-8d76-07ee6704ef65
    jinja: "{{paragraph}}\n\n\u092A\u094D\u0930\u0936\u094D\u0928: {{question}}\n\u092E\
      \u0941\u091D\u0947 \u092F\u0939 \u0909\u0924\u094D\u0924\u0930 \"{{answer}}\"\
      \ \u092E\u093F\u0932\u093E\u0964 \u0915\u094D\u092F\u093E \u0935\u094B \u0938\
      \u0939\u0940 \u0939\u0948? \u0939\u093E\u0902 \u092F\u093E \u0928\u0939\u0940\
      \u0902?\n|||\n{% if label != -1 %}{{answer_choices[label]}}{% endif %}"
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
      - Accuracy
      original_task: true
    name: found_this_answer
    reference: ''
  42d47df9-09de-4691-8e49-7cfadd636cdd: !Template
    answer_choices: "\u0928\u0939\u0940\u0902 ||| \u0939\u093E\u0901"
    id: 42d47df9-09de-4691-8e49-7cfadd636cdd
    jinja: "{{ paragraph }}\n\u092A\u093F\u091B\u0932\u0947 \u092E\u093E\u0930\u094D\
      \u0917 \u0915\u0947 \u0906\u0927\u093E\u0930 \u092A\u0930, {{ question }} \n\
      \u0915\u094D\u092F\u093E \"{{answer}}\" \u090F\u0915 \u0938\u0939\u0940 \u0909\
      \u0924\u094D\u0924\u0930 \u0939\u0948? ||| {% if label != -1 %}{{ answer_choices[label]\
      \ }}{% endif %}"
    metadata: !TemplateMetadata
      choices_in_prompt: false
      metrics:
      - Accuracy
      original_task: true
    name: "is\u2026 a correct answer?"
    reference: "Adapted from Perez et al. 2021 and Schick & Sch\xFCtz 2021."
  431a5c97-af33-4053-83c8-afb0dfc04448: !Template
    answer_choices: "\u0928\u0939\u0940\u0902 ||| \u0939\u093E\u0901"
    id: 431a5c97-af33-4053-83c8-afb0dfc04448
    jinja: "{{paragraph}}\n\u092A\u094D\u0930\u0936\u094D\u0928: {{question}}\n\n\u092E\
      \u0948\u0902 \u0905\u092A\u0928\u0947 \u091B\u093E\u0924\u094D\u0930\u094B\u0902\
      \ \u0915\u0947 \u0905\u092D\u094D\u092F\u093E\u0938\u094B\u0902 \u0915\u094B\
      \ \u0917\u094D\u0930\u0947\u0921 \u0915\u0930 \u0930\u0939\u093E \u0939\u0942\
      \u0902\u0964 \u0915\u094D\u092F\u093E \u0909\u0924\u094D\u0924\u0930 \"{{answer}}\"\
      \ \u0938\u0939\u0940 \u0939\u0948?\n|||\n{% if label != -1 %}{{answer_choices[label]}}{%\
      \ endif %}"
    metadata: !TemplateMetadata
      choices_in_prompt: false
      metrics:
      - Accuracy
      original_task: true
    name: grading
    reference: ''
  4fc9e1ea-7451-4dba-a2cb-ce870e35ef8b: !Template
    answer_choices: "\u0928\u0939\u0940\u0902 ||| \u0939\u093E\u0901"
    id: 4fc9e1ea-7451-4dba-a2cb-ce870e35ef8b
    jinja: "{{ paragraph }}\n{{ question }} \n\u0915\u094D\u092F\u093E \"{{answer}}\"\
      \ \u0915\u093E \u091C\u0935\u093E\u092C \u0926\u0947\u0928\u093E \u0905\u091A\
      \u094D\u091B\u093E \u0939\u094B\u0917\u093E? ||| {% if label != -1 %}{{ answer_choices[label]\
      \ }}{% endif %}"
    metadata: !TemplateMetadata
      choices_in_prompt: false
      metrics:
      - Accuracy
      original_task: true
    name: "Would it be good to answer\u2026"
    reference: ''
  59a2d847-27f3-4002-a125-cf9a291b3098: !Template
    answer_choices: "\u0928\u0939\u0940\u0902 ||| \u0939\u093E\u0901"
    id: 59a2d847-27f3-4002-a125-cf9a291b3098
    jinja: "{{ paragraph }}\n\u092A\u094D\u0930\u0936\u094D\u0928: {{ question }}\
      \ \n\u0915\u094D\u092F\u093E \u092F\u0939}}? ||| {% if label != -1 %}{{ answer_choices[label]\
      \ }}{% endif %}"
    metadata: !TemplateMetadata
      choices_in_prompt: false
      metrics:
      - Accuracy
      original_task: true
    name: "paragraph\u2026 question\u2026 is it\u2026 ?"
    reference: "Adapted from Perez et al. 2021 and Schick & Sch\xFCtz 2021."
  7bf537ea-ff8d-44c7-8fc9-305b35e3be66: !Template
    answer_choices: "\u0928\u0939\u0940\u0902 ||| \u0939\u093E\u0901"
    id: 7bf537ea-ff8d-44c7-8fc9-305b35e3be66
    jinja: "{{paragraph}}\n\n\u0924\u092F \u0915\u0930\u0947\u0902 \u0915\u093F \u0915\
      \u094D\u092F\u093E \"{{answer}}\" \u0928\u093F\u092E\u094D\u0928\u0932\u093F\
      \u0916\u093F\u0924 \u092A\u094D\u0930\u0936\u094D\u0928 \u0915\u093E \u090F\u0915\
      \ \u092E\u093E\u0928\u094D\u092F \u0909\u0924\u094D\u0924\u0930 \u0939\u0948\
      : {{question}}\n\u0939\u093E\u0902 \u092F\u093E \u0928\u093E \u092E\u0947\u0902\
      \ \u0909\u0924\u094D\u0924\u0930 \u0926\u0947\u0902\u0964\n|||\n{% if label\
      \ != -1 %}{{answer_choices[label]}}{% endif %}"
    metadata: !TemplateMetadata
      choices_in_prompt: false
      metrics:
      - Accuracy
      original_task: true
    name: decide_valid
    reference: ''
  7d878b89-2774-429a-82fb-ac801379e3ae: !Template
    answer_choices: "\u0928\u0939\u0940\u0902 ||| \u0939\u093E\u0901"
    id: 7d878b89-2774-429a-82fb-ac801379e3ae
    jinja: "{{ paragraph }}\n\u092A\u094D\u0930\u0936\u094D\u0928: {{ question }}\
      \ \n\u0915\u094D\u092F\u093E \u0938\u0939\u0940 \u0909\u0924\u094D\u0924\u0930\
      \ {{answer}} \u0939\u0948? ||| {% if label != -1 %}{{ answer_choices[label]\
      \ }}{% endif %}"
    metadata: !TemplateMetadata
      choices_in_prompt: false
      metrics:
      - Accuracy
      original_task: true
    name: "is the correct answer\u2026"
    reference: "Adapted from Perez et al. 2021 and Schick & Sch\xFCtz 2021."
  ae9b2b0b-1731-4370-adcc-36c4a959490d: !Template
    answer_choices: "\u0928\u0939\u0940\u0902 ||| \u0939\u093E\u0901"
    id: ae9b2b0b-1731-4370-adcc-36c4a959490d
    jinja: "\u0915\u094D\u092F\u093E \"{{answer}}\" \u0928\u093F\u092E\u094D\u0928\
      \u0932\u093F\u0916\u093F\u0924 \u092A\u094D\u0930\u0936\u094D\u0928 \u0915\u093E\
      \ \u090F\u0915 \u0938\u0939\u0940 \u0909\u0924\u094D\u0924\u0930 \u0939\u0948\
      ?\n\u092A\u094D\u0930\u0936\u094D\u0928: {{question}}\n\n\u0928\u093F\u092E\u094D\
      \u0928\u0932\u093F\u0916\u093F\u0924 \u092A\u093E\u0920 \u092A\u0930 \u092D\u0930\
      \u094B\u0938\u093E \u0915\u0930\u0947\u0902: {{paragraph}}\n|||\n{% if label\
      \ != -1 %}{{answer_choices[label]}}{% endif %}"
    metadata: !TemplateMetadata
      choices_in_prompt: false
      metrics:
      - Accuracy
      original_task: true
    name: correct
    reference: ''
  b63fd1c3-b4a6-43c3-8429-6a389235b2a4: !Template
    answer_choices: "\u0928\u0939\u0940\u0902 ||| \u0939\u093E\u0901"
    id: b63fd1c3-b4a6-43c3-8429-6a389235b2a4
    jinja: "{{paragraph}}\n\n\u092A\u094D\u0930\u0936\u094D\u0928: {{question}}\n\u092E\
      \u0941\u091D\u0947 \u0932\u0917\u0924\u093E \u0939\u0948 \u0915\u093F \"{{answer}}\"\
      \ \u090F\u0915 \u0935\u0948\u0927 \u0909\u0924\u094D\u0924\u0930 \u0939\u0948\
      \u0964 \u0915\u094D\u092F\u093E \u0906\u092A \u0907\u0938 \u092C\u093E\u0924\
      \ \u0915\u0940 \u092A\u0941\u0937\u094D\u091F\u093F \u0915\u0930 \u0938\u0915\
      \u0924\u0947 \u0939\u0948? \u0939\u093E\u0902 \u092F\u093E \u0928\u0939\u0940\
      \u0902?\n|||\n{% if label != -1 %}{{answer_choices[label]}}{% endif %}"
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
      - Accuracy
      original_task: true
    name: confirm
    reference: ''
  d2d78b88-8845-45b5-935a-6451da00b285: !Template
    answer_choices: "\u0928\u0939\u0940\u0902 ||| \u0939\u093E\u0901"
    id: d2d78b88-8845-45b5-935a-6451da00b285
    jinja: "{{ paragraph }}\n{{ question }} \n\u092E\u0948\u0902 \"{{answer}}\" \u0915\
      \u0939\u0928\u0947 \u091C\u093E \u0930\u0939\u093E \u0925\u093E\u0964 \u0915\
      \u094D\u092F\u093E \u0935\u0939 \u0927\u094D\u0935\u0928\u093F \u0938\u0939\u0940\
      \ \u0939\u0948? ||| {% if label != -1 %}{{ answer_choices[label] }}{% endif\
      \ %}"
    metadata: !TemplateMetadata
      choices_in_prompt: false
      metrics:
      - Accuracy
      original_task: true
    name: "I was going to say\u2026"
    reference: ''
