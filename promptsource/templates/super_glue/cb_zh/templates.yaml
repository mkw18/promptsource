dataset: super_glue
subset: cb_zh
templates:
  2e76cd0f-68ca-4f03-83ed-11cf15b25a84: !Template
    answer_choices: "\u662F\u7684 ||| \u4E0D ||| \u4E5F\u8BB8"
    id: 2e76cd0f-68ca-4f03-83ed-11cf15b25a84
    jinja: "\u8BA4\u4E3A {{premise}} \u6211\u4EEC\u53EF\u4EE5\u63A8\u65AD\u201C {{hypothesis}}\u201D\
      \u5417\uFF1F \u662F\u7684\uFF0C\u4E0D\u662F\uFF0C\u6216\u8005\u4E5F\u8BB8\uFF1F\
      \ ||| {% if label !=-1 %}{{ answer_choices[label] }}{% endif %} "
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
      - Accuracy
      original_task: true
    name: can we infer
    reference: Webson & Pavlick 2021
  358860fd-61ad-45fd-92a6-a72ca9107ebc: !Template
    answer_choices: "\u662F\u7684 ||| \u4E0D ||| \u4E5F\u8BB8"
    id: 358860fd-61ad-45fd-92a6-a72ca9107ebc
    jinja: "{{premise}} \u57FA\u4E8E\u4EE5\u524D\u7684\u6BB5\u843D\uFF0C\u201C {{hypothesis}}\u201D\
      \u662F\u771F\u7684\u5417\uFF1F \u662F\u7684\uFF0C\u4E0D\u662F\uFF0C\u6216\u8005\
      \u4E5F\u8BB8\uFF1F ||| {% if label !=-1 %}{{ answer_choices[label] }}{% endif\
      \ %}"
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
      - Accuracy
      original_task: true
    name: based on the previous passage
    reference: "Adapted from the BoolQ prompts in Schick & Sch\xFCtze 2021."
  3f43a599-ffdb-490e-8952-c0ce41dd4621: !Template
    answer_choices: "\u771F\u7684 ||| \u9519\u8BEF\u7684 ||| \u5C1A\u65E0\u5B9A\u8BBA"
    id: 3f43a599-ffdb-490e-8952-c0ce41dd4621
    jinja: "{{premise}} \u57FA\u4E8E\u8BE5\u4FE1\u606F\uFF0C\u662F\u8BF4\u660E\uFF1A\
      \u201C {{hypothesis}}\u201D {{{\u201C \u771F\u7684\u201D}}\uFF0C{{{\u201C \u9519\
      \u8BEF\u7684\u201D}}}\u6216{{\u201C Incconclusive\u201D}}\uFF1F ||| {% if label\
      \ !=-1 %}{{ answer_choices[label] }}{% endif %}"
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
      - Accuracy
      original_task: true
    name: claim true/false/inconclusive
    reference: Sanh et al. 2021
  404eed25-558a-4d39-9515-7de46d60d4e0: !Template
    answer_choices: "\u662F\u7684 ||| \u4E0D ||| \u4E5F\u8BB8"
    id: 404eed25-558a-4d39-9515-7de46d60d4e0
    jinja: "\u9274\u4E8E {{premise}} \u662F\u5426\u53EF\u4EE5\u8DDF\u968F{{hypothesis}}\
      \ \u662F\u7684\uFF0C\u4E0D\u662F\uFF0C\u6216\u8005\u4E5F\u8BB8\uFF1F ||| {%\
      \ if label !=-1 %}{{ answer_choices[label] }}{% endif %}"
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
      - Accuracy
      original_task: true
    name: does it follow that
    reference: Sanh et al. 2021
  5c9b1fa9-93f0-4f82-b9e3-e0967e4d7260: !Template
    answer_choices: "\u662F\u7684 ||| \u4E0D ||| \u4E5F\u8BB8"
    id: 5c9b1fa9-93f0-4f82-b9e3-e0967e4d7260
    jinja: "{{premise}} \u6211\u4EEC\u8BF4\u201C {{hypothesis}}\u201D\u662F\u6709\u9053\
      \u7406\u7684\u5417\uFF1F \u662F\u7684\uFF0C\u4E0D\u662F\uFF0C\u6216\u8005\u4E5F\
      \u8BB8\uFF1F ||| {% if label !=-1 %}{{ answer_choices[label] }}{% endif %}"
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
      - Accuracy
      original_task: true
    name: justified in saying
    reference: Webson & Pavlick 2021
  6b0c6191-183d-4731-8050-ab17c909335c: !Template
    answer_choices: "\u603B\u662F ||| \u7EDD\u4E0D ||| \u6709\u65F6"
    id: 6b0c6191-183d-4731-8050-ab17c909335c
    jinja: "\u5047\u8BBE\u662F\u7684 {{premise}} \u90A3\u4E48\uFF0C\u662F\u201C {{hypothesis}}\u201D\
      \ {{{\u201C\u59CB\u7EC8\u201D}}\uFF0C{{{\u201C\u6709\u65F6\u201D}}}}}\u6216\
      {{{{{{{{{\u201C nover\u201D}}} true\u5417\uFF1F ||| {% if label !=-1 %}{{ answer_choices[label]\
      \ }}{% endif %}"
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
      - Accuracy
      original_task: true
    name: always/sometimes/never
    reference: Sanh et al. 2021
  75db2bc2-3caa-4956-9653-13c7dd6255df: !Template
    answer_choices: "\u771F\u7684 ||| \u9519\u8BEF\u7684 ||| \u4E24\u8005\u90FD\u4E0D"
    id: 75db2bc2-3caa-4956-9653-13c7dd6255df
    jinja: "{{premise}}\n\u95EE\u9898\uFF1A {{hypothesis}} \u662F\u7684\uFF0C\u9519\
      \u8BEF\uFF0C\u8FD8\u662F\u4EC0\u4E48\uFF1F ||| {% if label !=-1 %}{{ answer_choices[label]\
      \ }}{% endif %}"
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
      - Accuracy
      original_task: true
    name: GPT-3 style
    reference: 'Same as reported in Figure G7 of the GPT-3 paper, except that there
      is no task identifying tokens like "anli R1: ".'
  87237a07-7cce-470a-80ac-3e5e3a5283ba: !Template
    answer_choices: "\u603B\u662F ||| \u7EDD\u4E0D ||| \u6709\u65F6"
    id: 87237a07-7cce-470a-80ac-3e5e3a5283ba
    jinja: "{{premise}} \n\n\u7262\u8BB0\u4E0A\u8FF0\u6587\u672C\uFF0C\u8BF7\u8003\
      \u8651\uFF1A {{hypothesis}} \u8FD9\u662F{{{\u201C\u59CB\u7EC8\u201D}}\uFF0C\
      {{\u201C\u6709\u65F6\u201D}}\uFF0C\u8FD8\u662F{{{\u201C nover\u201D}}\u6B63\u786E\
      \u5417\uFF1F ||| {% if label !=-1 %}{{ answer_choices[label] }}{% endif %}"
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
      - Accuracy
      original_task: true
    name: consider always/sometimes/never
    reference: Sanh et al. 2021
  8798b8a4-1f59-4c72-9c1b-3e3044a7462a: !Template
    answer_choices: "\u662F\u7684 ||| \u4E0D ||| \u4E5F\u8BB8"
    id: 8798b8a4-1f59-4c72-9c1b-3e3044a7462a
    jinja: "\u7ED9\u51FA {{premise}} \u662F\u5426\u53EF\u4EE5\u4FDD\u8BC1\u201C {{hypothesis}}\u201D\
      \u5417\uFF1F \u662F\u7684\uFF0C\u4E0D\u662F\uFF0C\u6216\u8005\u4E5F\u8BB8\uFF1F\
      \ ||| {% if label !=-1 %}{{ answer_choices[label] }}{% endif %}"
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
      - Accuracy
      original_task: true
    name: guaranteed true
    reference: Webson & Pavlick 2021
  8e3b8d3d-1362-47dc-922a-82c03f965989: !Template
    answer_choices: "\u662F\u7684 ||| \u4E0D ||| \u4E5F\u8BB8"
    id: 8e3b8d3d-1362-47dc-922a-82c03f965989
    jinja: "\u9274\u4E8E {{premise}} \u56E0\u6B64\uFF0C\u201C {{hypothesis}}\u201D\
      \u4E00\u5B9A\u662F\u771F\u7684\u5417\uFF1F \u662F\u7684\uFF0C\u4E0D\u662F\uFF0C\
      \u6216\u8005\u4E5F\u8BB8\uFF1F ||| {% if label !=-1 %}{{ answer_choices[label]\
      \ }}{% endif %}"
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
      - Accuracy
      original_task: true
    name: must be true
    reference: Sanh et al. 2021
  90ab1002-093c-4e54-b48f-626655e36b65: !Template
    answer_choices: "\u4FDD\u8BC1 ||| \u4E0D\u53EF\u80FD\u7684 ||| \u53EF\u80FD\u7684"
    id: 90ab1002-093c-4e54-b48f-626655e36b65
    jinja: "\u5047\u8BBE\u662F\u771F\u7684 {{premise}} \n\n\u56E0\u6B64\uFF0C\u201C\
      \ {{hypothesis}}\u201D\u662F{{{\u201C\u4FDD\u8BC1\u201D}}\uFF0C{{\u201C\u53EF\
      \u80FD\u201D}}}}\u6216{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{''\
      \ ||| {% if label !=-1 %}{{ answer_choices[label] }}{% endif %}"
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
      - Accuracy
      original_task: true
    name: guaranteed/possible/impossible
    reference: Sanh et al. 2021
  a485d120-6eef-4ff6-8684-42df1639b101: !Template
    answer_choices: "\u662F\u7684 ||| \u4E0D ||| \u4E5F\u8BB8"
    id: a485d120-6eef-4ff6-8684-42df1639b101
    jinja: "{{premise}} \n\n\u95EE\u9898\uFF1A \u8FD9\u662F\u5426\u610F\u5473\u7740\
      \u201C {{hypothesis}}\u201D\uFF1F \u662F\u7684\uFF0C\u4E0D\u662F\uFF0C\u6216\
      \u8005\u4E5F\u8BB8\uFF1F ||| {% if label !=-1 %}{{answer_choices[label]}}{%\
      \ endif %}"
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
      - Accuracy
      original_task: true
    name: does this imply
    reference: Sanh et al. 2021
  bee62bfa-5307-4e1c-97b2-2ad2f7bcb179: !Template
    answer_choices: "\u6B63\u786E\u7684 ||| \u4E0D\u6B63\u786E ||| \u5C1A\u65E0\u5B9A\
      \u8BBA"
    id: bee62bfa-5307-4e1c-97b2-2ad2f7bcb179
    jinja: "{{premise}} \u4EC5\u4F7F\u7528\u4E0A\u8FF0\u63CF\u8FF0\u4EE5\u53CA\u60A8\
      \u5BF9\u4E16\u754C\u7684\u4E86\u89E3\uFF0C\u201C {{hypothesis}}\u201D\u7EDD\u5BF9\
      \u662F\u6B63\u786E\u7684\uFF0C\u9519\u8BEF\u6216\u4E0D\u786E\u5B9A\u7684\uFF1F\
      \ ||| {% if label !=-1 %}{{ answer_choices[label] }}{% endif %}"
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
      - Accuracy
      original_task: true
    name: MNLI crowdsource
    reference: Adapted from Williams et al. 2018's instructions to crowdsourcing workers.
  e503b148-8e6c-43b5-9ed6-312794c54d9b: !Template
    answer_choices: "\u662F\u7684 ||| \u4E0D ||| \u4E5F\u8BB8"
    id: e503b148-8e6c-43b5-9ed6-312794c54d9b
    jinja: "\u7ED9\u51FA {{premise}} \u6211\u4EEC\u5E94\u8BE5\u5047\u8BBE\u201C {{hypothesis}}\u201D\
      \u662F\u771F\u7684\u5417\uFF1F \u662F\u7684\uFF0C\u4E0D\u662F\uFF0C\u6216\u8005\
      \u4E5F\u8BB8\uFF1F ||| {% if label !=-1 %}{{ answer_choices[label] }}{% endif\
      \ %}"
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
      - Accuracy
      original_task: true
    name: should assume
    reference: Webson & Pavlick 2021
  ea56b7f3-6e07-45bc-b619-c527eac4a41b: !Template
    answer_choices: "\u771F\u7684 ||| \u9519\u8BEF\u7684 ||| \u5C1A\u65E0\u5B9A\u8BBA"
    id: ea56b7f3-6e07-45bc-b619-c527eac4a41b
    jinja: "\u4EE5\u4EE5\u4E0B\u65B9\u5F0F\u4E3A\u771F\u7406\uFF1A {{premise}}\n\u7136\
      \u540E\u4EE5\u4E0B\u8BED\u53E5\uFF1A \u201C {{hypothesis}}\u201D\u662F{{{\u201C\
      \ \u771F\u7684\u201D}}\uFF0C{{\u201C \u9519\u8BEF\u7684\u201D}}}\u6216{{\u201C\
      \ noccclusive\u201D}}\uFF1F ||| {% if label !=-1 %}{{ answer_choices[label]\
      \ }}{% endif %}"
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
      - Accuracy
      original_task: true
    name: take the following as truth
    reference: Sanh et al. 2021
