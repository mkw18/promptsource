dataset: super_glue
subset: boolq_ja
templates:
  3e386463-1715-4578-9cba-07d11a0d3b61: !Template
    answer_choices: "\u9593\u9055\u3044 ||| \u771F\u5B9F"
    id: 3e386463-1715-4578-9cba-07d11a0d3b61
    jinja: "\u901A\u8DEF\uFF1A {{passage}}\n\n\u3053\u306E\u4E00\u7BC0\u3092\u8AAD\
      \u3093\u3060\u5F8C\u3001\u79C1\u306F\u8CEA\u554F\u304C\u3042\u308A\u307E\u3059\
      \uFF1A {{question}}\uFF1F \u6B63\u3057\u3044\u304B\u9593\u9055\u3063\u3066\u3044\
      \u308B\u304B\uFF1F |||\n{% if label != -1 %}\n{{answer_choices[label]}}\n{%\
      \ endif %}"
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
      - Accuracy
      original_task: true
    name: after_reading
    reference: ''
  492f0f88-4370-46cd-839b-1de37a55aeda: !Template
    answer_choices: "\u3044\u3044\u3048 ||| \u306F\u3044"
    id: 492f0f88-4370-46cd-839b-1de37a55aeda
    jinja: "{{ passage }} \n\u8CEA\u554F\uFF1A {{ question }}\n\u7B54\u3048\uFF1A\
      \ ||| \n{% if label != -1 %}\n{{ answer_choices[label] }}\n{% endif %}"
    metadata: !TemplateMetadata
      choices_in_prompt: false
      metrics:
      - Accuracy
      original_task: true
    name: GPT-3 Style
    reference: Same as Figure G29, p. 58 of the GPT-3 paper
  6cb6a026-c070-470a-b75d-bb8fdf424e35: !Template
    answer_choices: "\u3044\u3044\u3048 ||| \u306F\u3044"
    id: 6cb6a026-c070-470a-b75d-bb8fdf424e35
    jinja: "{{ passage }} \n\n\u305D\u308C\u3092\u8AAD\u3093\u3067\u3001{{ question\
      \ }}\uFF1F |||\n{% if label != -1 %}\n{{ answer_choices[label] }} \n{% endif\
      \ %}"
    metadata: !TemplateMetadata
      choices_in_prompt: false
      metrics:
      - Accuracy
      original_task: true
    name: "I wonder\u2026"
    reference: ''
  7cf7acdf-e3a2-459f-a3e8-2e2d27dd6aa5: !Template
    answer_choices: "\u3044\u3044\u3048 ||| \u306F\u3044"
    id: 7cf7acdf-e3a2-459f-a3e8-2e2d27dd6aa5
    jinja: "\u6587\u7AE0\uFF1A {{passage}}\n\n\u6B21\u306E\u306F\u3044/\u3044\u3044\
      \u3048\u306E\u8CEA\u554F\u306B\u7B54\u3048\u3066\u304F\u3060\u3055\u3044\u3002\
      \ {{question}}\uFF1F \u306F\u3044\u3001\u3082\u3057\u304F\u306F\u3001\u3044\u3044\
      \u3048\uFF1F |||\n{% if label != -1 %}\n{{answer_choices[label]}}\n{% endif\
      \ %}"
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
      - Accuracy
      original_task: true
    name: yes_no_question
    reference: ''
  7d21d974-0624-4d4f-9e8c-644e2d009cb5: !Template
    answer_choices: "\u3044\u3044\u3048 ||| \u306F\u3044"
    id: 7d21d974-0624-4d4f-9e8c-644e2d009cb5
    jinja: "{{ passage }} \n\n\u305D\u308C\u3092\u8AAD\u3093\u3067\u3001{{ question\
      \ }}\u6559\u3048\u3066\u304F\u308C\u307E\u305B\u3093\u304B\uFF1F ||| {% if label\
      \ != -1 %}{{ answer_choices[label] }}\n{% endif %}"
    metadata: !TemplateMetadata
      choices_in_prompt: false
      metrics:
      - Accuracy
      original_task: true
    name: "could you tell me\u2026"
    reference: ''
  922d3e87-ac58-4731-84d1-f0a40e47afb5: !Template
    answer_choices: "\u3044\u3044\u3048 ||| \u306F\u3044"
    id: 922d3e87-ac58-4731-84d1-f0a40e47afb5
    jinja: "\u30C6\u30B9\u30C8\n1. \u306F\u3044\u307E\u305F\u306F\u3044\u3044\u3048\
      \u3067\u7B54\u3048\u307E\u3059\u3002\n\n\u66F8\u985E\uFF1A {{passage}}\n\u8CEA\
      \u554F\uFF1A {{question}}? ||| \n{% if label != -1 %}\n{{answer_choices[label]}}\n\
      {% endif %}"
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
      - Accuracy
      original_task: true
    name: exam
    reference: ''
  9a1bf459-8047-437c-9def-f21e960429cc: !Template
    answer_choices: "\u3044\u3044\u3048 ||| \u306F\u3044"
    id: 9a1bf459-8047-437c-9def-f21e960429cc
    jinja: "\u6B21\u306E\u6587\u7AE0\u306B\u57FA\u3065\u3044\u3066\u3001{{ question\
      \ }}? {{ passage }}\n\n|||\n{% if label != -1 %}\n{{ answer_choices[label] }}\n\
      {% endif %}"
    metadata: !TemplateMetadata
      choices_in_prompt: false
      metrics:
      - Accuracy
      original_task: true
    name: based on the following passage
    reference: "Adapted from Perez et al. 2021 and Schick & Sch\xFCtz 2021."
  9f4c6b0a-437b-40c0-b467-db4b7218d38d: !Template
    answer_choices: "\u9593\u9055\u3044 ||| \u771F\u5B9F"
    id: 9f4c6b0a-437b-40c0-b467-db4b7218d38d
    jinja: "\u30A8\u30AF\u30B5\u30B5\u30A4\u30BA\uFF1A \u30C6\u30AD\u30B9\u30C8\u3092\
      \u8AAD\u3093\u3067\u3001\u8CEA\u554F\u306B\u6B63\u8AA4\u3067\u7B54\u3048\u3066\
      \u304F\u3060\u3055\u3044\u3002\n\n\u6587\u7AE0\uFF1A {{passage}}\n\u8CEA\u554F\
      \uFF1A {{question}}? |||\n{% if label != -1 %}\n{{answer_choices[label]}}\n\
      {% endif %}"
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
      - Accuracy
      original_task: true
    name: exercise
    reference: ''
  b2b3cb60-d6e3-491c-a09a-8201e13e417e: !Template
    answer_choices: "\u3044\u3044\u3048 ||| \u306F\u3044"
    id: b2b3cb60-d6e3-491c-a09a-8201e13e417e
    jinja: "{{ passage }}\n\u524D\u306E\u6587\u7AE0\u306B\u57FA\u3065\u3044\u3066\u3001\
      {{ question }}? ||| {% if label != -1 %}{{ answer_choices[label] }}\n{% endif\
      \ %}"
    metadata: !TemplateMetadata
      choices_in_prompt: false
      metrics:
      - Accuracy
      original_task: true
    name: based on the previous passage
    reference: "Adapted from Perez et al. 2021 and Schick & Sch\xFCtz 2021."
  eb78772c-e81e-4b8a-a77b-b75efd1c212a: !Template
    answer_choices: "\u9593\u9055\u3044 ||| \u771F\u5B9F"
    id: eb78772c-e81e-4b8a-a77b-b75efd1c212a
    jinja: "{{passage}}\n\n\u8CEA\u554F\uFF1A {{question}}\uFF1F \u6B63\u3057\u3044\
      \u304B\u9593\u9055\u3063\u3066\u3044\u308B\u304B\uFF1F |||\n{% if label != -1\
      \ %}\n{{answer_choices[label]}}\n{% endif %}"
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
      - Accuracy
      original_task: true
    name: valid_binary
    reference: ''
