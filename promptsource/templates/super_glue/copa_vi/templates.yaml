dataset: super_glue
subset: copa_vi
templates:
  0edd8660-f299-4819-a5ac-633c11177228: !Template
    answer_choices: '{{choice1}} ||| {{choice2}}'
    id: 0edd8660-f299-4819-a5ac-633c11177228
    jinja: "T\u1EADp th\u1EC3 d\u1EE5c: Ch\u1ECDn gi\u1EA3i ph\xE1p thay th\u1EBF\
      \ h\u1EE3p l\xFD nh\u1EA5t.\n\n{{ premise }} {% if question == \"cause\" %}\
      \ t\u1EA1i v\xEC... {% else %} v\xEC th\u1EBF... {% endif %}\n- {{choice1}}\n\
      - {{choice2}} ||| {% if label != -1 %}{{ answer_choices[label] }}{%endif%}"
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
      - Accuracy
      original_task: true
    name: exercise
    reference: ''
  150789fe-e309-47a1-82c9-0a4dc2c6b12b: !Template
    answer_choices: '{{choice1}} ||| {{choice2}}'
    id: 150789fe-e309-47a1-82c9-0a4dc2c6b12b
    jinja: "{% if question == \"effect\" %} \n{{ premise }} \u0110i\u1EC1u g\xEC c\xF3\
      \ th\u1EC3 x\u1EA3y ra ti\u1EBFp theo, \"{{ answer_choices[0] }}\" ho\u1EB7\
      c \"{{ answer_choices[1] }}\"? ||| {% if label != -1 %}{{ answer_choices[label]\
      \ }}{%endif%}\n{% endif %}"
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
      - Accuracy
      original_task: true
    name: "\u2026What could happen next, C1 or C2?"
    reference: ''
  4d879cbe-2fd7-424a-9d78-3f5200313fba: !Template
    answer_choices: '{{choice1}} ||| {{choice2}}'
    id: 4d879cbe-2fd7-424a-9d78-3f5200313fba
    jinja: "{{ premise }} \n\nT\xF4i \u0111ang do d\u1EF1 gi\u1EEFa hai l\u1EF1a ch\u1ECD\
      n. Gi\xFAp t\xF4i ch\u1ECDn nhi\u1EC1u kh\u1EA3 n\u0103ng {% if question ==\
      \ \"cause\" %} g\xE2y ra: {% else %} hi\u1EC7u \u1EE9ng: {% endif %}\n- {{choice1}}\n\
      - {{choice2}} ||| {% if label != -1 %}{{ answer_choices[label] }}{%endif%}"
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
      - Accuracy
      original_task: true
    name: i_am_hesitating
    reference: ''
  66ea075e-4d03-4a78-b1fa-9a5228cf0c9d: !Template
    answer_choices: '{{choice1}} ||| {{choice2}}'
    id: 66ea075e-4d03-4a78-b1fa-9a5228cf0c9d
    jinja: "{{ premise }} {% if question == \"cause\" %} \u0110i\u1EC1u n\xE0y \u0111\
      \xE3 x\u1EA3y ra b\u1EDFi v\xEC... {% else %} H\u1EADu qu\u1EA3 l\xE0... {%\
      \ endif %}\nGi\xFAp t\xF4i ch\u1ECDn t\xF9y ch\u1ECDn h\u1EE3p l\xFD h\u01A1\
      n:\n- {{choice1}}\n- {{choice2}} ||| {% if label != -1 %}{{ answer_choices[label]\
      \ }}{%endif%}"
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
      - Accuracy
      original_task: true
    name: plausible_alternatives
    reference: ''
  744047dc-1298-45a2-8d68-d67e3f834ded: !Template
    answer_choices: '{{choice1 }} ||| {{choice2}}'
    id: 744047dc-1298-45a2-8d68-d67e3f834ded
    jinja: "\"{{ answer_choices[0] }}\" ho\u1EB7c \"{{ answer_choices[1] }}\"? {{\
      \ premise }} {% if question == \"cause\" %} t\u1EA1i v\xEC {% else %} v\xEC\
      \ th\u1EBF {% endif %} ||| {% if label != -1 %}{{ answer_choices[label] }}{%\
      \ endif %}"
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
      - Accuracy
      original_task: true
    name: "C1 or C2? premise, so/because\u2026"
    reference: "Adapted from Perez et al. 2021 and Schick & Sch\xFCtz 2021."
  84da62c2-9440-4cfc-bdd4-d70c65e33a82: !Template
    answer_choices: '{{choice1}} ||| {{choice2}}'
    id: 84da62c2-9440-4cfc-bdd4-d70c65e33a82
    jinja: "{% if question == \"effect\" %} \n{{ premise }} K\u1EBFt qu\u1EA3 l\xE0\
      , \"{{ answer_choices[0] }}\" ho\u1EB7c \"{{ answer_choices[1] }}\"? ||| {%\
      \ if label != -1 %}{{ answer_choices[label] }}{%endif%}\n{% endif %}"
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
      - Accuracy
      original_task: true
    name: "\u2026As a result, C1 or C2?"
    reference: ''
  8ce80f8a-239e-4393-892c-f63dbb0d9929: !Template
    answer_choices: '{{choice1}} ||| {{choice2}}'
    id: 8ce80f8a-239e-4393-892c-f63dbb0d9929
    jinja: "{{ premise }} \n\nL\u1EF1a ch\u1ECDn t\u1ED1t nh\u1EA5t l\xE0 g\xEC?\n\
      - {{choice1}}\n- {{choice2}}\n\nCh\xFAng t\xF4i \u0111ang t\xECm ki\u1EBFm {%\
      \ if question == \"cause\" %} m\u1ED9t nguy\xEAn nh\xE2n {% else %} m\u1ED9\
      t hi\u1EC7u \u1EE9ng {% endif %}\n||| {% if label != -1 %}{{answer_choices[label]}}{%endif%}"
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
      - Accuracy
      original_task: true
    name: best_option
    reference: ''
  8cf2ba73-aee5-4651-b5d4-b1b88afe4abb: !Template
    answer_choices: '{{choice1}} ||| {{choice2}}'
    id: 8cf2ba73-aee5-4651-b5d4-b1b88afe4abb
    jinja: "{% if question == \"cause\" %} \n{{ premise }} C\xF3 th\u1EC3 \u0111\u01B0\
      \u1EE3c g\xE2y ra b\u1EDFi \"{{ answer_choices[0] }}\" ho\u1EB7c \"{{ answer_choices[1]\
      \ }}\"? ||| {% if label != -1 %}{{ answer_choices[label] }}{%endif%}\n{% endif\
      \ %}"
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
      - Accuracy
      original_task: true
    name: "\u2026which may be caused by"
    reference: ''
  a1f9951e-2b6b-4530-9636-9cdf4c1658c5: !Template
    answer_choices: '{{choice1}} ||| {{choice2}}'
    id: a1f9951e-2b6b-4530-9636-9cdf4c1658c5
    jinja: "Ch\u1ECDn nhi\u1EC1u kh\u1EA3 n\u0103ng ti\u1EBFp t\u1EE5c cho c\xE2u\
      \ sau:\n{{ premise }} {% if question == \"cause\" %} b\u1EDFi v\xEC: {% else\
      \ %} K\u1EBFt qu\u1EA3 l\xE0: {% endif %}\n- {{choice1}}\n- {{choice2}} |||\
      \ {% if label != -1 %}{{ answer_choices[label] }}{%endif%}"
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
      - Accuracy
      original_task: true
    name: more likely
    reference: ''
  a61d8c21-da25-47bf-b5fe-14a8edd650af: !Template
    answer_choices: '{{choice1}} ||| {{choice2}}'
    id: a61d8c21-da25-47bf-b5fe-14a8edd650af
    jinja: "{{ premise }}\n\nCh\u1ECDn h\u1EE3p l\xFD nh\u1EA5t {% if question ==\
      \ \"cause\" %} g\xE2y ra: {% else %} hi\u1EC7u \u1EE9ng: {% endif %}\n- {{choice1}}\n\
      - {{choice2}} ||| {% if label != -1 %}{{ answer_choices[label] }}{%endif%}"
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
      - Accuracy
      original_task: true
    name: cause_effect
    reference: ''
  a8bf11c3-bea2-45ba-a533-957d8bee5e2e: !Template
    answer_choices: '{{choice1}} ||| {{choice2}}'
    id: a8bf11c3-bea2-45ba-a533-957d8bee5e2e
    jinja: "{% if question == \"cause\" %} \n{{ premise }} T\u1EA1i sao? \"{{ answer_choices[0]\
      \ }}\" ho\u1EB7c \"{{ answer_choices[1] }}\"? ||| {% if label != -1 %}{{ answer_choices[label]\
      \ }}{%endif%}\n{% endif %}"
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
      - Accuracy
      original_task: true
    name: "\u2026why? C1 or C2"
    reference: ''
  f32348cd-d3cb-4619-87b9-e24f99c78567: !Template
    answer_choices: '{{choice1}} ||| {{choice2}}'
    id: f32348cd-d3cb-4619-87b9-e24f99c78567
    jinja: "{{ premise }} {% if question == \"cause\" %} t\u1EA1i v\xEC... {% else\
      \ %} v\xEC th\u1EBF... {% endif %}\nCh\u1ECDn gi\u1EEFa:\n- {{choice1}}\n- {{choice2}}\
      \ ||| {% if label != -1 %}{{ answer_choices[label] }}{%endif%}"
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
      - Accuracy
      original_task: true
    name: choose
    reference: ''
