dataset: super_glue
subset: copa_hi
templates:
  0edd8660-f299-4819-a5ac-633c11177228: !Template
    answer_choices: '{{choice1}} ||| {{choice2}}'
    id: 0edd8660-f299-4819-a5ac-633c11177228
    jinja: "\u0935\u094D\u092F\u093E\u092F\u093E\u092E: \u0938\u092C\u0938\u0947 \u092A\
      \u094D\u0930\u0936\u0902\u0938\u0928\u0940\u092F \u0935\u093F\u0915\u0932\u094D\
      \u092A \u091A\u0941\u0928\u0947\u0902\u0964\n\n{{ premise }} {% if question\
      \ == \"cause\" %} \u0907\u0938\u0932\u093F\u092F\u0947... {% else %} \u0907\u0938\
      \u0932\u093F\u090F... {% endif %}\n- {{choice1}}\n- {{choice2}} ||| {% if label\
      \ != -1 %}{{ answer_choices[label] }}{%endif%}"
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
      - Accuracy
      original_task: true
    name: exercise
    reference: ''
  150789fe-e309-47a1-82c9-0a4dc2c6b12b: !Template
    answer_choices: '{{choice1}} ||| {{choice2}}'
    id: 150789fe-e309-47a1-82c9-0a4dc2c6b12b
    jinja: "{% if question == \"effect\" %} \n{{ premise }} \u0906\u0917\u0947 \u0915\
      \u094D\u092F\u093E \u0939\u094B \u0938\u0915\u0924\u093E \u0939\u0948, \"{{\
      \ answer_choices[0] }}\" \u092F\u093E \"{{ answer_choices[1] }}\"? ||| {% if\
      \ label != -1 %}{{ answer_choices[label] }}{%endif%}\n{% endif %}"
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
      - Accuracy
      original_task: true
    name: "\u2026What could happen next, C1 or C2?"
    reference: ''
  4d879cbe-2fd7-424a-9d78-3f5200313fba: !Template
    answer_choices: '{{choice1}} ||| {{choice2}}'
    id: 4d879cbe-2fd7-424a-9d78-3f5200313fba
    jinja: "{{ premise }} \n\n\u092E\u0948\u0902 \u0926\u094B \u0935\u093F\u0915\u0932\
      \u094D\u092A\u094B\u0902 \u0915\u0947 \u092C\u0940\u091A \u0938\u0902\u0915\u094B\
      \u091A \u0915\u0930 \u0930\u0939\u093E \u0939\u0942\u0902\u0964 \u092E\u0941\
      \u091D\u0947 \u0905\u0927\u093F\u0915 \u0938\u0902\u092D\u093E\u0935\u0928\u093E\
      \ \u091A\u0941\u0928\u0928\u0947 \u092E\u0947\u0902 \u092E\u0926\u0926 \u0915\
      \u0930\u0947\u0902 {% if question == \"cause\" %} \u0915\u093E\u0930\u0923:\
      \ {% else %} \u092A\u094D\u0930\u092D\u093E\u0935: {% endif %}\n- {{choice1}}\n\
      - {{choice2}} ||| {% if label != -1 %}{{ answer_choices[label] }}{%endif%}"
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
      - Accuracy
      original_task: true
    name: i_am_hesitating
    reference: ''
  66ea075e-4d03-4a78-b1fa-9a5228cf0c9d: !Template
    answer_choices: '{{choice1}} ||| {{choice2}}'
    id: 66ea075e-4d03-4a78-b1fa-9a5228cf0c9d
    jinja: "{{ premise }} {% if question == \"cause\" %} \u0910\u0938\u093E \u0907\
      \u0938\u0932\u093F\u090F \u0939\u0941\u0906 \u0915\u094D\u092F\u094B\u0902\u0915\
      \u093F... {% else %} \u090F\u0915 \u092A\u0930\u093F\u0923\u093E\u092E \u0915\
      \u0947 \u0930\u0942\u092A \u092E\u0947\u0902... {% endif %}\n\u092E\u0941\u091D\
      \u0947 \u0914\u0930 \u0905\u0927\u093F\u0915 \u092A\u094D\u0930\u0936\u0902\u0938\
      \u0928\u0940\u092F \u0935\u093F\u0915\u0932\u094D\u092A \u091A\u0941\u0928\u0928\
      \u0947 \u092E\u0947\u0902 \u092E\u0926\u0926 \u0915\u0930\u0947\u0902:\n- {{choice1}}\n\
      - {{choice2}} ||| {% if label != -1 %}{{ answer_choices[label] }}{%endif%}"
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
      - Accuracy
      original_task: true
    name: plausible_alternatives
    reference: ''
  744047dc-1298-45a2-8d68-d67e3f834ded: !Template
    answer_choices: '{{choice1 }} ||| {{choice2}}'
    id: 744047dc-1298-45a2-8d68-d67e3f834ded
    jinja: "\"{{ answer_choices[0] }}\" \u092F\u093E \"{{ answer_choices[1] }}\"?\
      \ {{ premise }} {% if question == \"cause\" %} \u0907\u0938\u0932\u093F\u092F\
      \u0947 {% else %} \u0907\u0938\u0932\u093F\u090F {% endif %} ||| {% if label\
      \ != -1 %}{{ answer_choices[label] }}{% endif %}"
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
      - Accuracy
      original_task: true
    name: "C1 or C2? premise, so/because\u2026"
    reference: "Adapted from Perez et al. 2021 and Schick & Sch\xFCtz 2021."
  84da62c2-9440-4cfc-bdd4-d70c65e33a82: !Template
    answer_choices: '{{choice1}} ||| {{choice2}}'
    id: 84da62c2-9440-4cfc-bdd4-d70c65e33a82
    jinja: "{% if question == \"effect\" %} \n{{ premise }} \u0928\u0924\u0940\u091C\
      \u0924\u0928, \"{{ answer_choices[0] }}\" \u092F\u093E \"{{ answer_choices[1]\
      \ }}\"? ||| {% if label != -1 %}{{ answer_choices[label] }}{%endif%}\n{% endif\
      \ %}"
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
      - Accuracy
      original_task: true
    name: "\u2026As a result, C1 or C2?"
    reference: ''
  8ce80f8a-239e-4393-892c-f63dbb0d9929: !Template
    answer_choices: '{{choice1}} ||| {{choice2}}'
    id: 8ce80f8a-239e-4393-892c-f63dbb0d9929
    jinja: "{{ premise }} \n\n\u0938\u092C\u0938\u0947 \u0905\u091A\u094D\u091B\u093E\
      \ \u0935\u093F\u0915\u0932\u094D\u092A \u0915\u094D\u092F\u093E \u0939\u0948\
      ?\n- {{choice1}}\n- {{choice2}}\n\n\u0915\u094B \u0939\u092E \u0922\u0942\u0902\
      \u0922 \u0930\u0939\u0947 \u0939\u0948\u0902 {% if question == \"cause\" %}\
      \ \u090F\u0915 \u0915\u093E\u0930\u0923 {% else %} \u090F\u0915 \u092A\u094D\
      \u0930\u092D\u093E\u0935 {% endif %}\n||| {% if label != -1 %}{{answer_choices[label]}}{%endif%}"
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
      - Accuracy
      original_task: true
    name: best_option
    reference: ''
  8cf2ba73-aee5-4651-b5d4-b1b88afe4abb: !Template
    answer_choices: '{{choice1}} ||| {{choice2}}'
    id: 8cf2ba73-aee5-4651-b5d4-b1b88afe4abb
    jinja: "{% if question == \"cause\" %} \n{{ premise }} \u091C\u094B \"{{ answer_choices[0]\
      \ }}\" \u092F\u093E \"{{ answer_choices[1] }}\" \u0915\u0947 \u0915\u093E\u0930\
      \u0923 \u0939\u094B \u0938\u0915\u0924\u093E \u0939\u0948? ||| {% if label !=\
      \ -1 %}{{ answer_choices[label] }}{%endif%}\n{% endif %}"
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
      - Accuracy
      original_task: true
    name: "\u2026which may be caused by"
    reference: ''
  a1f9951e-2b6b-4530-9636-9cdf4c1658c5: !Template
    answer_choices: '{{choice1}} ||| {{choice2}}'
    id: a1f9951e-2b6b-4530-9636-9cdf4c1658c5
    jinja: "\u0928\u093F\u092E\u094D\u0928\u0932\u093F\u0916\u093F\u0924 \u0935\u093E\
      \u0915\u094D\u092F \u0915\u0947 \u0932\u093F\u090F \u0905\u0927\u093F\u0915\
      \ \u0938\u0902\u092D\u093E\u0935\u0928\u093E \u0928\u093F\u0930\u0902\u0924\u0930\
      \u0924\u093E \u091A\u0941\u0928\u0947\u0902:\n{{ premise }} {% if question ==\
      \ \"cause\" %} \u0915\u0947 \u092A\u0930\u093F\u0923\u093E\u092E \u0938\u094D\
      \u0935\u0930\u0942\u092A: {% else %} \u090F\u0915 \u092A\u0930\u093F\u0923\u093E\
      \u092E \u0915\u0947 \u0930\u0942\u092A \u092E\u0947\u0902: {% endif %}\n- {{choice1}}\n\
      - {{choice2}} ||| {% if label != -1 %}{{ answer_choices[label] }}{%endif%}"
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
      - Accuracy
      original_task: true
    name: more likely
    reference: ''
  a61d8c21-da25-47bf-b5fe-14a8edd650af: !Template
    answer_choices: '{{choice1}} ||| {{choice2}}'
    id: a61d8c21-da25-47bf-b5fe-14a8edd650af
    jinja: "{{ premise }}\n\n\u0938\u092C\u0938\u0947 \u092A\u094D\u0930\u0936\u0902\
      \u0938\u0928\u0940\u092F \u0915\u093E \u091A\u092F\u0928 \u0915\u0930\u0947\u0902\
      \ {% if question == \"cause\" %} \u0915\u093E\u0930\u0923: {% else %} \u092A\
      \u094D\u0930\u092D\u093E\u0935: {% endif %}\n- {{choice1}}\n- {{choice2}} |||\
      \ {% if label != -1 %}{{ answer_choices[label] }}{%endif%}"
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
      - Accuracy
      original_task: true
    name: cause_effect
    reference: ''
  a8bf11c3-bea2-45ba-a533-957d8bee5e2e: !Template
    answer_choices: '{{choice1}} ||| {{choice2}}'
    id: a8bf11c3-bea2-45ba-a533-957d8bee5e2e
    jinja: "{% if question == \"cause\" %} \n{{ premise }} \u0915\u094D\u092F\u094B\
      \u0902? \"{{ answer_choices[0] }}\" \u092F\u093E \"{{ answer_choices[1] }}\"\
      ? ||| {% if label != -1 %}{{ answer_choices[label] }}{%endif%}\n{% endif %}"
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
      - Accuracy
      original_task: true
    name: "\u2026why? C1 or C2"
    reference: ''
  f32348cd-d3cb-4619-87b9-e24f99c78567: !Template
    answer_choices: '{{choice1}} ||| {{choice2}}'
    id: f32348cd-d3cb-4619-87b9-e24f99c78567
    jinja: "{{ premise }} {% if question == \"cause\" %} \u0907\u0938\u0932\u093F\u092F\
      \u0947... {% else %} \u0907\u0938\u0932\u093F\u090F... {% endif %}\n\u092C\u0940\
      \u091A \u091A\u092F\u0928:\n- {{choice1}}\n- {{choice2}} ||| {% if label !=\
      \ -1 %}{{ answer_choices[label] }}{%endif%}"
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
      - Accuracy
      original_task: true
    name: choose
    reference: ''
