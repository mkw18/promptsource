dataset: quail
subset: vi
templates:
  01870e5a-39d0-4485-a453-893d46c82736: !Template
    answer_choices: A ||| B ||| C ||| D
    id: 01870e5a-39d0-4485-a453-893d46c82736
    jinja: "{{ context }}\nC\xE2u h\u1ECFi: {{ question }}\nT\xF9y ch\u1ECDn:\n{%\
      \ for k in range(answers | length) %}\n{{'. '.join([answer_choices[k], answers[k]])}}\n\
      {% endfor %}\n===\n\u0110\xE1p \xE1n \u0111\xFAng l\xE0\n|||\n{{ answer_choices[correct_answer_id]\
      \ }}"
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
      - Accuracy
      original_task: true
    name: context_question_answer_description_id
    reference: ''
  1225d6c7-4d4c-46ab-9a65-a8fa87826906: !Template
    answer_choices: '{{answers | join("|||")}}'
    id: 1225d6c7-4d4c-46ab-9a65-a8fa87826906
    jinja: "{{ context }}\nC\xE2u h\u1ECFi: {{ question }}\nT\xF9y ch\u1ECDn:\n- {{\
      \ answer_choices | join(\" \\n - \") }}\n===\n\u0110\xE1p \xE1n \u0111\xFAng\
      \ l\xE0\n|||\n{{ answer_choices[correct_answer_id] }}"
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
      - Accuracy
      original_task: true
    name: context_question_answer_description_text
    reference: ''
  38caa4e6-28b9-4476-8609-b66c83679fcc: !Template
    answer_choices: A ||| B ||| C ||| D
    id: 38caa4e6-28b9-4476-8609-b66c83679fcc
    jinja: "\u0110\u1ECDc b\u1ED1i c\u1EA3nh sau v\xE0 ch\u1ECDn t\xF9y ch\u1ECDn\
      \ ch\xEDnh x\xE1c \u0111\u1EC3 tr\u1EA3 l\u1EDDi c\xE2u h\u1ECFi.\n\u0110\u1ECB\
      nh ngh\u0129a b\xE0i v\u0103n: {{ context }}\nC\xE2u h\u1ECFi: {{ question }}\n\
      T\xF9y ch\u1ECDn:\n{% for k in range(answers | length) %}\n{{'. '.join([answer_choices[k],\
      \ answers[k]])}}\n{% endfor %}\n|||\n{{ answer_choices[correct_answer_id] }}"
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
      - Accuracy
      original_task: true
    name: description_context_question_answer_id
    reference: ''
  7186e352-adfa-4c16-8eda-d9fcccb6293e: !Template
    answer_choices: '{{answers | join("|||")}}'
    id: 7186e352-adfa-4c16-8eda-d9fcccb6293e
    jinja: "{{ context }}\n{{ question }}\nCh\u1ECDn c\xE2u tr\u1EA3 l\u1EDDi \u0111\
      \xFAng t\u1EEB c\xE1c t\xF9y ch\u1ECDn sau:\n- {{ answer_choices | join(\"\\\
      n- \") }}\n|||\n{{ answer_choices[correct_answer_id] }}"
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
      - Accuracy
      original_task: true
    name: context_question_description_answer_text
    reference: ''
  773d1dad-ccc7-4f5d-936b-c43b2d3eedf7: !Template
    answer_choices: '{{answers | join("|||")}}'
    id: 773d1dad-ccc7-4f5d-936b-c43b2d3eedf7
    jinja: "{{ context }}\nC\xE2u h\u1ECFi: {{ question }}\n===\nC\xE2u tr\u1EA3 l\u1EDD\
      i cho c\xE2u h\u1ECFi tr\xEAn l\xE0\n|||\n{{ answer_choices[correct_answer_id]\
      \ }}"
    metadata: !TemplateMetadata
      choices_in_prompt: false
      metrics:
      - Accuracy
      original_task: false
    name: context_question_description_text
    reference: ''
  7b0ce9fa-6aa0-4210-ab6c-1edd4b2f43df: !Template
    answer_choices: '{{answers | join("|||")}}'
    id: 7b0ce9fa-6aa0-4210-ab6c-1edd4b2f43df
    jinja: "{{ context }}\nTheo b\u1ED1i c\u1EA3nh tr\xEAn, tr\u1EA3 l\u1EDDi c\xE2\
      u h\u1ECFi sau.\n{{ question }}\n|||\n{{ answer_choices[correct_answer_id] }}"
    metadata: !TemplateMetadata
      choices_in_prompt: false
      metrics:
      - Accuracy
      original_task: false
    name: context_description_question_text
    reference: ''
  7c9c7cec-12c1-4005-a9a1-a027e472d949: !Template
    answer_choices: A ||| B ||| C ||| D
    id: 7c9c7cec-12c1-4005-a9a1-a027e472d949
    jinja: "{{ context }}\n{{ question }}\nCh\u1ECDn c\xE2u tr\u1EA3 l\u1EDDi \u0111\
      \xFAng t\u1EEB c\xE1c t\xF9y ch\u1ECDn sau:\n{% for k in range(answers | length)\
      \ %}\n{{'. '.join([answer_choices[k], answers[k]])}}\n{% endfor %}\n|||\n{{\
      \ answer_choices[correct_answer_id] }}"
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
      - Accuracy
      original_task: true
    name: context_question_description_answer_id
    reference: ''
  80fe7668-d088-4432-98bd-9df022a62b5b: !Template
    answer_choices: A ||| B ||| C ||| D
    id: 80fe7668-d088-4432-98bd-9df022a62b5b
    jinja: '{{ context }}

      {{ question }}

      {% for k in range(answers | length) %}

      {{''. ''.join([answer_choices[k], answers[k]])}}

      {% endfor %}

      |||

      {{ answer_choices[correct_answer_id] }}'
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
      - Accuracy
      original_task: true
    name: no_prompt_id
    reference: ''
  88d0056d-e736-405f-85aa-155474fde51a: !Template
    answer_choices: A ||| B ||| C ||| D
    id: 88d0056d-e736-405f-85aa-155474fde51a
    jinja: "{{ context }}\nTheo b\u1ED1i c\u1EA3nh tr\xEAn, ch\u1ECDn t\xF9y ch\u1ECD\
      n ch\xEDnh x\xE1c \u0111\u1EC3 tr\u1EA3 l\u1EDDi c\xE2u h\u1ECFi sau.\nC\xE2\
      u h\u1ECFi: {{ question }}\nT\xF9y ch\u1ECDn:\n{% for k in range(answers | length)\
      \ %}\n{{'. '.join([answer_choices[k], answers[k]])}}\n{% endfor %}\n|||\n{{\
      \ answer_choices[correct_answer_id] }}"
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
      - Accuracy
      original_task: true
    name: context_description_question_answer_id
    reference: ''
  a071e73e-5fda-45b5-8a6a-b56e477a6aee: !Template
    answer_choices: '{{answers | join("|||")}}'
    id: a071e73e-5fda-45b5-8a6a-b56e477a6aee
    jinja: "Read the following context and answer the question.\n\u0110\u1ECBnh ngh\u0129\
      a b\xE0i v\u0103n: {{ context }}\nC\xE2u h\u1ECFi: {{ question }}\nC\xE2u tr\u1EA3\
      \ l\u1EDDi:\n|||\n{{ answer_choices[correct_answer_id] }}"
    metadata: !TemplateMetadata
      choices_in_prompt: false
      metrics:
      - Accuracy
      original_task: false
    name: description_context_question_text
    reference: ''
  cb57451d-2a1c-4db1-a352-9f50d835b327: !Template
    answer_choices: '{{answers | join("|||")}}'
    id: cb57451d-2a1c-4db1-a352-9f50d835b327
    jinja: '{{ context }}

      {{ question }}

      - {{ answer_choices | join("\n- ") }}

      |||

      {{ answer_choices[correct_answer_id] }}'
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
      - Accuracy
      original_task: true
    name: no_prompt_text
    reference: ''
  ea0ba07f-bb89-42dc-b1e8-4fe6008297b2: !Template
    answer_choices: '{{answers | join("|||")}}'
    id: ea0ba07f-bb89-42dc-b1e8-4fe6008297b2
    jinja: "{{ context }}\nTheo b\u1ED1i c\u1EA3nh tr\xEAn, ch\u1ECDn t\xF9y ch\u1ECD\
      n ch\xEDnh x\xE1c \u0111\u1EC3 tr\u1EA3 l\u1EDDi c\xE2u h\u1ECFi sau.\nC\xE2\
      u h\u1ECFi: {{ question }}\nT\xF9y ch\u1ECDn:\n- {{ answer_choices | join(\"\
      \\n- \") }}\n|||\n{{ answer_choices[correct_answer_id] }}"
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
      - Accuracy
      original_task: true
    name: context_description_question_answer_text
    reference: ''
  f374c2ca-952a-47ab-8420-cb5fb2c693d9: !Template
    answer_choices: '{{answers | join("|||")}}'
    id: f374c2ca-952a-47ab-8420-cb5fb2c693d9
    jinja: "\u0110\u1ECDc b\u1ED1i c\u1EA3nh sau v\xE0 ch\u1ECDn t\xF9y ch\u1ECDn\
      \ ch\xEDnh x\xE1c \u0111\u1EC3 tr\u1EA3 l\u1EDDi c\xE2u h\u1ECFi.\n\u0110\u1ECB\
      nh ngh\u0129a b\xE0i v\u0103n: {{ context }}\nC\xE2u h\u1ECFi: {{ question }}\n\
      T\xF9y ch\u1ECDn:\n- {{ answer_choices | join(\"\\n- \") }}\n|||\n{{ answer_choices[correct_answer_id]\
      \ }}"
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
      - Accuracy
      original_task: true
    name: description_context_question_answer_text
    reference: ''
