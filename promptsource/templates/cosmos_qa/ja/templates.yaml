dataset: cosmos_qa
subset: ja
templates:
  015f333d-2a15-4552-9fe3-a20bd781001e: !Template
    answer_choices: null
    id: 015f333d-2a15-4552-9fe3-a20bd781001e
    jinja: "\u30B3\u30F3\u30C6\u30AD\u30B9\u30C8\u3068\u7B54\u3048\u306B\u57FA\u3065\
      \u3044\u3066\u3001\u8CEA\u554F\u3092\u751F\u6210\u3057\u307E\u3059\u3002 \n\n\
      \u74B0\u5883\uFF1A {{context}}\n\n\u7B54\u3048\uFF1A\n{% if label == 0 %}\n\
      {{answer0}}\n{% elif label == 1 %}\n{{answer1}}\n{% elif label == 2 %}\n{{answer2}}\n\
      {% elif label == 3 %}\n{{answer3}}\n{% endif %}\n|||\n{{question}}"
    metadata: !TemplateMetadata
      choices_in_prompt: false
      metrics:
      - BLEU
      - ROUGE
      original_task: false
    name: context_answer_to_question
    reference: 'Template asks the model to generate questions '
  08e20b79-d1c0-4717-b538-f1a313c2b7d2: !Template
    answer_choices: '{{answer0}} ||| {{answer1}} ||| {{answer2}} ||| {{answer3}}'
    id: 08e20b79-d1c0-4717-b538-f1a313c2b7d2
    jinja: "\u6B21\u306E\u30B3\u30F3\u30C6\u30AD\u30B9\u30C8\u3092\u8AAD\u3093\u3067\
      \u3001\u8CEA\u554F\u306B\u7B54\u3048\u308B\u6700\u9069\u306A\u30AA\u30D7\u30B7\
      \u30E7\u30F3\u3092\u9078\u629E\u3057\u3066\u304F\u3060\u3055\u3044\u3002\n\u74B0\
      \u5883\uFF1A {{ context }}\n\u8CEA\u554F\uFF1A {{ question }}\n\u30AA\u30D7\u30B7\
      \u30E7\u30F3\uFF1A \n- {{ answer_choices | join(\"\\n - \") }}\n|||\n{{ answer_choices[label]\
      \ }}"
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
      - Accuracy
      original_task: true
    name: description_context_question_answer_text
    reference: 'Template generates the answer. Answer cues are included. '
  67d6ba13-4958-4e5e-842c-ada92aead6cc: !Template
    answer_choices: '{{answer0}} ||| {{answer1}} ||| {{answer2}} ||| {{answer3}}'
    id: 67d6ba13-4958-4e5e-842c-ada92aead6cc
    jinja: "\u6B21\u306E\u30B3\u30F3\u30C6\u30AD\u30B9\u30C8\u3092\u8AAD\u3093\u3067\
      \u3001\u8CEA\u554F\u306B\u7B54\u3048\u3066\u304F\u3060\u3055\u3044\u3002\n\u74B0\
      \u5883\uFF1A {{ context }}\n\u8CEA\u554F\uFF1A {{ question }}\n\u7B54\u3048\uFF1A\
      \n|||\n{{ answer_choices[label] }}"
    metadata: !TemplateMetadata
      choices_in_prompt: false
      metrics:
      - Accuracy
      original_task: true
    name: description_context_question_text
    reference: Template generates the answer
  693c47c6-f17c-417a-af70-bc20e71b4ed4: !Template
    answer_choices: A ||| B ||| C ||| D
    id: 693c47c6-f17c-417a-af70-bc20e71b4ed4
    jinja: "\u6B21\u306E\u30B3\u30F3\u30C6\u30AD\u30B9\u30C8\u3092\u8AAD\u3093\u3067\
      \u3001\u8CEA\u554F\u306B\u7B54\u3048\u308B\u6700\u9069\u306A\u30AA\u30D7\u30B7\
      \u30E7\u30F3\u3092\u9078\u629E\u3057\u3066\u304F\u3060\u3055\u3044\u3002\n\u74B0\
      \u5883\uFF1A {{ context }}\n\u8CEA\u554F\uFF1A {{ question }}\n\u30AA\u30D7\u30B7\
      \u30E7\u30F3\uFF1A \nA. {{ answer0 }}\nB. {{ answer1 }}\nC. {{ answer2 }}\n\
      D. {{ answer3 }}\n|||\n{{ answer_choices[label] }}"
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
      - Accuracy
      original_task: true
    name: description_context_question_answer_id
    reference: Template asks the model to pick the correct answer
  6b9a24cc-054e-40d6-8abf-261443122f3a: !Template
    answer_choices: '{{answer0}} ||| {{answer1}} ||| {{answer2}} ||| {{answer3}}'
    id: 6b9a24cc-054e-40d6-8abf-261443122f3a
    jinja: "{{ context }}\n\u4E0A\u8A18\u306E\u30B3\u30F3\u30C6\u30AD\u30B9\u30C8\u306B\
      \u5F93\u3063\u3066\u3001\u6B21\u306E\u8CEA\u554F\u306B\u7B54\u3048\u308B\u305F\
      \u3081\u306E\u6700\u826F\u306E\u30AA\u30D7\u30B7\u30E7\u30F3\u3092\u9078\u629E\
      \u3057\u3066\u304F\u3060\u3055\u3044\u3002\n\u8CEA\u554F\uFF1A {{ question }}\n\
      \u30AA\u30D7\u30B7\u30E7\u30F3\uFF1A\n- {{answer_choices | join(\"\\n - \")}}\n\
      |||\n{{answer_choices[label]}}"
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
      - Accuracy
      original_task: true
    name: context_description_question_answer_text
    reference: The template asks the model to generate the answer
  71325300-1f16-4a68-97c7-a03457f00cc7: !Template
    answer_choices: A ||| B ||| C ||| D
    id: 71325300-1f16-4a68-97c7-a03457f00cc7
    jinja: '{{ context }}

      {{ question }}

      A. {{ answer0 }}

      B. {{ answer1 }}

      C. {{ answer2 }}

      D. {{ answer3 }}

      |||

      {{ answer_choices[label] }}'
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
      - Accuracy
      original_task: true
    name: no_prompt_id
    reference: 'No prompt with context and question. '
  7c30b1a1-14da-4458-95e8-c35f8de23110: !Template
    answer_choices: '{{answer0}} ||| {{answer1}} ||| {{answer2}} ||| {{answer3}}'
    id: 7c30b1a1-14da-4458-95e8-c35f8de23110
    jinja: "{{ context }}\n\u8CEA\u554F\uFF1A {{ question }}\n\u4E0A\u8A18\u306E\u8CEA\
      \u554F\u3078\u306E\u7B54\u3048\uFF1A\n|||\n{{ answer_choices[label] }}"
    metadata: !TemplateMetadata
      choices_in_prompt: false
      metrics:
      - Accuracy
      original_task: false
    name: context_question_description_text
    reference: Context, question, task description, and generate the answer
  85e9ae2c-fbb7-47ed-980c-56da5299e9af: !Template
    answer_choices: '{{answer0}} ||| {{answer1}} ||| {{answer2}} ||| {{answer3}}'
    id: 85e9ae2c-fbb7-47ed-980c-56da5299e9af
    jinja: '{{ context }}

      {{ question }}

      - {{ answer_choices | join("\n - ") }}

      |||

      {{ answer_choices[label] }}'
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
      - Accuracy
      original_task: true
    name: no_prompt_text
    reference: 'No prompt with answer choices. The template asks the model to generate
      the answer. '
  8a60255c-d44d-4f20-a631-ae1c0c9a7d68: !Template
    answer_choices: A ||| B ||| C ||| D
    id: 8a60255c-d44d-4f20-a631-ae1c0c9a7d68
    jinja: "{{ context }}\n\u4E0A\u8A18\u306E\u30B3\u30F3\u30C6\u30AD\u30B9\u30C8\u306B\
      \u5F93\u3063\u3066\u3001\u6B21\u306E\u8CEA\u554F\u306B\u7B54\u3048\u308B\u305F\
      \u3081\u306E\u6700\u826F\u306E\u30AA\u30D7\u30B7\u30E7\u30F3\u3092\u9078\u629E\
      \u3057\u3066\u304F\u3060\u3055\u3044\u3002\n\u8CEA\u554F\uFF1A {{ question }}\n\
      \u30AA\u30D7\u30B7\u30E7\u30F3\uFF1A\nA. {{ answer0 }}\nB. {{ answer1 }}\nC.\
      \ {{ answer2 }}\nD. {{ answer3 }}\n|||\n{{ answer_choices[label] }}"
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
      - Accuracy
      original_task: true
    name: context_description_question_answer_id
    reference: Original task with context, question and the answer choices.
  9dc80101-516d-448e-8e05-a62b4acead3b: !Template
    answer_choices: A ||| B ||| C ||| D
    id: 9dc80101-516d-448e-8e05-a62b4acead3b
    jinja: "{{ context }}\n{{ question }}\n\u6B21\u306E\u30AA\u30D7\u30B7\u30E7\u30F3\
      \u304B\u3089\u30D9\u30B9\u30C8\u30A2\u30F3\u30B5\u30FC\u3092\u9078\u629E\u3057\
      \u3066\u304F\u3060\u3055\u3044\u3002\nA. {{ answer0 }}\nB. {{ answer1 }}\nC.\
      \ {{ answer2 }}\nD. {{ answer3 }}\n|||\n{{ answer_choices[label] }}"
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
      - Accuracy
      original_task: true
    name: context_question_description_answer_id
    reference: Template asks the model to pick the correct answer
  c07c459e-f1f7-409e-9da7-fe5c993a4933: !Template
    answer_choices: '{{answer0}} ||| {{answer1}} ||| {{answer2}} ||| {{answer3}}'
    id: c07c459e-f1f7-409e-9da7-fe5c993a4933
    jinja: "{{ context }}\n\u4E0A\u8A18\u306E\u30B3\u30F3\u30C6\u30AD\u30B9\u30C8\u306B\
      \u3088\u308B\u3068\u3001\u6B21\u306E\u8CEA\u554F\u306B\u7B54\u3048\u3066\u304F\
      \u3060\u3055\u3044\u3002\n{{ question }}\n|||\n{{answer_choices[label]}}"
    metadata: !TemplateMetadata
      choices_in_prompt: false
      metrics:
      - Accuracy
      original_task: true
    name: context_description_question_text
    reference: The template asks the model to generate the answer without any answer
      cues
  d5499348-5cb3-467b-a543-206b5dd9806e: !Template
    answer_choices: '{{answer0}} ||| {{answer1}} ||| {{answer2}} ||| {{answer3}}'
    id: d5499348-5cb3-467b-a543-206b5dd9806e
    jinja: "{{ context }}\n{{ question }}\n\u6B21\u306E\u30AA\u30D7\u30B7\u30E7\u30F3\
      \u304B\u3089\u30D9\u30B9\u30C8\u30A2\u30F3\u30B5\u30FC\u3092\u9078\u629E\u3057\
      \u3066\u304F\u3060\u3055\u3044\u3002\n- {{ answer_choices | join(\"\\n - \"\
      ) }}\n|||\n{{ answer_choices[label] }}"
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
      - Accuracy
      original_task: true
    name: context_question_description_answer_text
    reference: 'Context, question,  task description, and answer choices '
  e640e365-091c-491e-a87e-f529514607e5: !Template
    answer_choices: '{{answer0}} ||| {{answer1}} ||| {{answer2}} ||| {{answer3}}'
    id: e640e365-091c-491e-a87e-f529514607e5
    jinja: "{{question}} \n|||\n{{ answer_choices[label] }}"
    metadata: !TemplateMetadata
      choices_in_prompt: false
      metrics:
      - Accuracy
      original_task: false
    name: only_question_answer
    reference: Template with only question and generates the answer
