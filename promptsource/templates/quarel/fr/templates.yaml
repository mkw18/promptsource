dataset: quarel
subset: fr
templates:
  5904fd73-b1ee-4f89-b7bc-b0fe8cc07c66: !Template
    answer_choices: '{{world_literals.world1[0]}} ||| {{world_literals.world2[0]}}'
    id: 5904fd73-b1ee-4f89-b7bc-b0fe8cc07c66
    jinja: "Question: {{question}}\n\nN'utilisez pas {{\"A\"}} et {{\"B\"}} pour r\xE9\
      pondre \xE0 la question, mais choisissez plut\xF4t entre \"{{answer_choices[0]}}\"\
      \ et \"{{answer_choices[1]}}\".\n|||\n{{answer_choices[answer_index]}}"
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
      - Accuracy
      original_task: false
    name: do_not_use
    reference: ''
  5b5f9d29-0ad5-4bb9-831a-11fcb115c10d: !Template
    answer_choices: '{{world_literals.world1[0]}} ||| {{world_literals.world2[0]}}'
    id: 5b5f9d29-0ad5-4bb9-831a-11fcb115c10d
    jinja: "Voici un test logique\_: {{question}}\n\nChoisissez la r\xE9ponse entre\
      \ \"{{answer_choices[0]}}\" et \"{{answer_choices[1]}}\".\n|||\n{{answer_choices[answer_index]}}"
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
      - Accuracy
      original_task: false
    name: logic_test
    reference: ''
  63c58389-605a-42b9-85a6-a2586a954a92: !Template
    answer_choices: '{{world_literals.world1[0]}} ||| {{world_literals.world2[0]}}'
    id: 63c58389-605a-42b9-85a6-a2586a954a92
    jinja: "Voici une courte histoire\_: {{question}}.\n\nQuelle est la r\xE9ponse\
      \ la plus sens\xE9e entre \"{{answer_choices[0]}}\" et \"{{answer_choices[1]}}\"\
      \_?\n|||\n{{answer_choices[answer_index]}}"
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
      - Accuracy
      original_task: false
    name: heres_a_story
    reference: ''
  73a7adbb-41b1-4b4d-b378-d7e17d030a6f: !Template
    answer_choices: '{{world_literals.world1[0]}} ||| {{world_literals.world2[0]}}'
    id: 73a7adbb-41b1-4b4d-b378-d7e17d030a6f
    jinja: 'Choisissez entre "{{answer_choices[0]}}" et "{{answer_choices[1]}}".

      Question: {{question}}

      |||

      {{answer_choices[answer_index]}}'
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
      - Accuracy
      original_task: false
    name: choose_between
    reference: ''
  92013fab-5387-44d4-bf0f-e29a31bcafb6: !Template
    answer_choices: '{{world_literals.world1[0]}} ||| {{world_literals.world2[0]}}'
    id: 92013fab-5387-44d4-bf0f-e29a31bcafb6
    jinja: "Je teste la logique de mes \xE9l\xE8ves.\nQuelle est la r\xE9ponse qu'ils\
      \ doivent choisir entre \"{{answer_choices[0]}}\" et \"{{answer_choices[1]}}\"\
      \_?\nEssai logique\_: {{question}}\n|||\n{{answer_choices[answer_index]}}"
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
      - Accuracy
      original_task: false
    name: testing_students
    reference: ''
