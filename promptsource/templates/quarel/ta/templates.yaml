dataset: quarel
subset: ta
templates:
  5904fd73-b1ee-4f89-b7bc-b0fe8cc07c66: !Template
    answer_choices: '{{world_literals.world1[0]}} ||| {{world_literals.world2[0]}}'
    id: 5904fd73-b1ee-4f89-b7bc-b0fe8cc07c66
    jinja: "\u0B95\u0BC7\u0BB3\u0BCD\u0BB5\u0BBF: {{question}}\n\n\u0B95\u0BC7\u0BB3\
      \u0BCD\u0BB5\u0BBF\u0B95\u0BCD\u0B95\u0BC1 \u0BAA\u0BA4\u0BBF\u0BB2\u0BB3\u0BBF\
      \u0B95\u0BCD\u0B95 {{\"A\"}} \u0BAE\u0BB1\u0BCD\u0BB1\u0BC1\u0BAE\u0BCD {{\"\
      B\"}} be \u0B90\u0BAA\u0BCD \u0BAA\u0BAF\u0BA9\u0BCD\u0BAA\u0B9F\u0BC1\u0BA4\u0BCD\
      \u0BA4 \u0BB5\u0BC7\u0BA3\u0BCD\u0B9F\u0BBE\u0BAE\u0BCD, \u0BAE\u0BBE\u0BB1\u0BBE\
      \u0B95, \"{{answer_choices[0]}}\" \u0BAE\u0BB1\u0BCD\u0BB1\u0BC1\u0BAE\u0BCD\
      \ \"{{answer_choices[1]}}\" between \u0B95\u0BCD\u0B95\u0BC1 \u0B87\u0B9F\u0BC8\u0BAF\u0BBF\u0BB2\
      \u0BCD \u0BA4\u0BC7\u0BB0\u0BCD\u0BB5\u0BC1 \u0B9A\u0BC6\u0BAF\u0BCD\u0BAF\u0BB5\
      \u0BC1\u0BAE\u0BCD.\n|||\n{{answer_choices[answer_index]}}"
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
      - Accuracy
      original_task: false
    name: do_not_use
    reference: ''
  5b5f9d29-0ad5-4bb9-831a-11fcb115c10d: !Template
    answer_choices: '{{world_literals.world1[0]}} ||| {{world_literals.world2[0]}}'
    id: 5b5f9d29-0ad5-4bb9-831a-11fcb115c10d
    jinja: "\u0B87\u0B99\u0BCD\u0B95\u0BC7 \u0B92\u0BB0\u0BC1 \u0BA4\u0BB0\u0BCD\u0B95\
      \u0BCD\u0B95 \u0B9A\u0BCB\u0BA4\u0BA9\u0BC8: {{question}}\n\n\"{{answer_choices[0]}}\"\
      \ \u0BAE\u0BB1\u0BCD\u0BB1\u0BC1\u0BAE\u0BCD \"{{answer_choices[1]}}\" between \u0B95\u0BCD\u0B95\
      \u0BC1 \u0B87\u0B9F\u0BC8\u0BAF\u0BBF\u0BB2\u0BBE\u0BA9 \u0BAA\u0BA4\u0BBF\u0BB2\
      \u0BC8\u0BA4\u0BCD \u0BA4\u0BC7\u0BB0\u0BCD\u0BB5\u0BC1\u0B9A\u0BC6\u0BAF\u0BCD\
      \u0B95.\n|||\n{{answer_choices[answer_index]}}"
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
      - Accuracy
      original_task: false
    name: logic_test
    reference: ''
  63c58389-605a-42b9-85a6-a2586a954a92: !Template
    answer_choices: '{{world_literals.world1[0]}} ||| {{world_literals.world2[0]}}'
    id: 63c58389-605a-42b9-85a6-a2586a954a92
    jinja: "\u0B87\u0B99\u0BCD\u0B95\u0BC7 \u0B92\u0BB0\u0BC1 \u0B9A\u0BBF\u0BB1\u0BC1\
      \u0B95\u0BA4\u0BC8: {{question}}.\n\n\"{{answer_choices[0]}}\" \u0BAE\u0BB1\u0BCD\
      \u0BB1\u0BC1\u0BAE\u0BCD \"{{answer_choices[1]}}\" between \u0B95\u0BCD\u0B95\u0BC1 \u0B87\u0B9F\u0BC8\
      \u0BAF\u0BBF\u0BB2\u0BCD \u0BAE\u0BBF\u0B95\u0BB5\u0BC1\u0BAE\u0BCD \u0B89\u0BA3\
      \u0BB0\u0BCD\u0BA4\u0BBF\u0BB1\u0BA9\u0BCD \u0BAA\u0BA4\u0BBF\u0BB2\u0BCD \u0B8E\
      \u0BA9\u0BCD\u0BA9?\n|||\n{{answer_choices[answer_index]}}"
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
      - Accuracy
      original_task: false
    name: heres_a_story
    reference: ''
  73a7adbb-41b1-4b4d-b378-d7e17d030a6f: !Template
    answer_choices: '{{world_literals.world1[0]}} ||| {{world_literals.world2[0]}}'
    id: 73a7adbb-41b1-4b4d-b378-d7e17d030a6f
    jinja: "\"{{answer_choices[0]}}\" \u0BAE\u0BB1\u0BCD\u0BB1\u0BC1\u0BAE\u0BCD \"{{answer_choices[1]}}\"\
      \ between \u0B87\u0B9F\u0BC8\u0BAF\u0BC7 \u0BA4\u0BC7\u0BB0\u0BCD\u0BB5\u0BC1\
      \ \u0B9A\u0BC6\u0BAF\u0BCD\u0BAF\u0BB5\u0BC1\u0BAE\u0BCD.\n\u0B95\u0BC7\u0BB3\
      \u0BCD\u0BB5\u0BBF: {{question}}\n|||\n{{answer_choices[answer_index]}}"
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
      - Accuracy
      original_task: false
    name: choose_between
    reference: ''
  92013fab-5387-44d4-bf0f-e29a31bcafb6: !Template
    answer_choices: '{{world_literals.world1[0]}} ||| {{world_literals.world2[0]}}'
    id: 92013fab-5387-44d4-bf0f-e29a31bcafb6
    jinja: "\u0B8E\u0BA9\u0BA4\u0BC1 \u0BAE\u0BBE\u0BA3\u0BB5\u0BB0\u0BCD\u0B95\u0BB3\
      \u0BBF\u0BA9\u0BCD \u0BA4\u0BB0\u0BCD\u0B95\u0BCD\u0B95\u0BA4\u0BCD\u0BA4\u0BC8\
      \ \u0BA8\u0BBE\u0BA9\u0BCD \u0B9A\u0BCB\u0BA4\u0BBF\u0B95\u0BCD\u0B95\u0BBF\u0BB1\
      \u0BC7\u0BA9\u0BCD.\n\"{{answer_choices[0]}}\" \u0BAE\u0BB1\u0BCD\u0BB1\u0BC1\
      \u0BAE\u0BCD \"{{answer_choices[1]}}\" bower \u0B95\u0BCD\u0B95\u0BC1 \u0B87\u0B9F\u0BC8\u0BAF\u0BBF\
      \u0BB2\u0BCD \u0B85\u0BB5\u0BB0\u0BCD\u0B95\u0BB3\u0BCD \u0BA4\u0BC7\u0BB0\u0BCD\
      \u0BB5\u0BC1 \u0B9A\u0BC6\u0BAF\u0BCD\u0BAF \u0BB5\u0BC7\u0BA3\u0BCD\u0B9F\u0BBF\
      \u0BAF \u0BAA\u0BA4\u0BBF\u0BB2\u0BCD \u0B8E\u0BA9\u0BCD\u0BA9?\n\u0BA4\u0BB0\
      \u0BCD\u0B95\u0BCD\u0B95 \u0B9A\u0BCB\u0BA4\u0BA9\u0BC8: {{question}}\n|||\n\
      {{answer_choices[answer_index]}}"
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
      - Accuracy
      original_task: false
    name: testing_students
    reference: ''
