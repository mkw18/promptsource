dataset: piqa
subset: es
templates:
  16e97a16-c958-4956-bfba-279f88dafd5b: !Template
    answer_choices: '{{sol1}} ||| {{sol2}}'
    id: 16e97a16-c958-4956-bfba-279f88dafd5b
    jinja: "Meta: {{goal}}\n\n\xBFCu\xE1l es el final correcto?\n- {{sol1}}\n- {{sol2}}\n\
      \nResponder:\n|||\n{{answer_choices[label]}}"
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
      - Accuracy
      original_task: true
    name: what_is_the_correct_ending
    reference: ''
  3f336295-c1f7-410a-8fc6-d2ed79487aa4: !Template
    answer_choices: '{{sol1}} ||| {{sol2}}'
    id: 3f336295-c1f7-410a-8fc6-d2ed79487aa4
    jinja: "{{\"Soluci\xF3n 1\"}}: {{sol1}}\n{{\"Soluci\xF3n 2\"}}: {{sol2}}\n\nMeta:\
      \ {{goal}}\n\nDado el objetivo, \xBFcu\xE1l es la soluci\xF3n correcta?\n\n\
      Respuesta copiando la soluci\xF3n correcta\n|||\n{{answer_choices[label]}}"
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
      - Accuracy
      original_task: true
    name: pick_correct_choice_with_choice_given_before_goal
    reference: ''
  44778818-7b73-4262-a294-c00fc32b6c2c: !Template
    answer_choices: 1 ||| 2
    id: 44778818-7b73-4262-a294-c00fc32b6c2c
    jinja: "Frase: {{goal}}\n\nElecci\xF3n {{answer_choices[0]}}: {{sol1}}\n\nElecci\xF3\
      n {{answer_choices[1]}}: {{sol2}}\n\n\xBFCu\xE1l es el \xEDndice de la elecci\xF3\
      n correcta para terminar para la oraci\xF3n?\n\nResponder:\n\n|||\n{{answer_choices[label]}}"
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
      - Accuracy
      original_task: true
    name: pick_correct_choice_index
    reference: ''
  5f4b4645-9438-4375-9062-083130e6d04e: !Template
    answer_choices: null
    id: 5f4b4645-9438-4375-9062-083130e6d04e
    jinja: "Dado un objetivo y una soluci\xF3n incorrecta, reescribirlo para dar una\
      \ soluci\xF3n correcta.\nMeta: {{goal}} \nSoluci\xF3n: {{[sol1, sol2][1 - label]}}\n\
      Soluci\xF3n corregida:\n|||\n{{[sol1, sol2][label]}}\n"
    metadata: !TemplateMetadata
      choices_in_prompt: false
      metrics:
      - BLEU
      - ROUGE
      original_task: false
    name: Correct the solution
    reference: ''
  94c39589-7bfb-4c09-9337-672369459545: !Template
    answer_choices: '{{sol1}} ||| {{sol2}}'
    id: 94c39589-7bfb-4c09-9337-672369459545
    jinja: "Termine la siguiente oraci\xF3n con la mejor opci\xF3n: {{goal}}\n\nOpciones:\n\
      - {{sol1}}\n- {{sol2}}\n\nResponder:\n\n|||\n{{answer_choices[label]}}"
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
      - Accuracy
      original_task: true
    name: finish_sentence_with_correct_choice
    reference: ''
  99565244-4eaf-4004-a28b-4362ba5bcac3: !Template
    answer_choices: "No ||| S\xED"
    id: 99565244-4eaf-4004-a28b-4362ba5bcac3
    jinja: "{{goal}} {{sol2}}\n\xBFEsta frase tiene sentido?\n|||\n{{answer_choices[label]}}"
    metadata: !TemplateMetadata
      choices_in_prompt: false
      metrics:
      - Accuracy
      original_task: false
    name: Does this solution make sense? sol2
    reference: ''
  adfef248-f856-44fa-affd-e3223718854e: !Template
    answer_choices: "Soluci\xF3n 1 ||| Soluci\xF3n 2"
    id: adfef248-f856-44fa-affd-e3223718854e
    jinja: "Dado un objetivo y 2 soluciones, elija la soluci\xF3n m\xE1s apropiada.\n\
      Meta: {{goal}}\n- {{\"Soluci\xF3n 1\"}}: {{sol1}}\n- {{\"Soluci\xF3n 2\"}}:\
      \ {{sol2}}\n\nRespuesta devolviendo tampoco {{\"Soluci\xF3n 1\"}} o {{\"Soluci\xF3\
      n 2\"}}\n|||\n{{answer_choices[label]}}"
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
      - Accuracy
      original_task: true
    name: choose the most appropriate solution
    reference: ''
  b5c69473-eedb-4c4f-a5fa-d4e266e43535: !Template
    answer_choices: null
    id: b5c69473-eedb-4c4f-a5fa-d4e266e43535
    jinja: "Given a sentence, correct it if it doesn't make sense. If it makes sense,\
      \ just return it as the answer.\nAporte: {{goal}} {{sol2[0].lower() + sol2[1:]}}\n\
      Producci\xF3n:\n|||\n{{goal}} {{[sol1[0].lower() + sol1[1:], sol2[0].lower()\
      \ + sol2[1:]][label]}}\n"
    metadata: !TemplateMetadata
      choices_in_prompt: false
      metrics:
      - BLEU
      - ROUGE
      original_task: false
    name: 'Correct the solution if false: from sol 2'
    reference: ''
  c8c45ef1-2ffc-43d7-8710-b98c2fc4f699: !Template
    answer_choices: null
    id: c8c45ef1-2ffc-43d7-8710-b98c2fc4f699
    jinja: '{{goal}}

      |||

      {{[sol1[0].lower() + sol1[1:], sol2[0].lower() + sol2[1:]][label]}}'
    metadata: !TemplateMetadata
      choices_in_prompt: false
      metrics:
      - BLEU
      - ROUGE
      original_task: false
    name: no prompt needed
    reference: ''
  f044def7-01c2-42de-b6ad-4e8c63ab2bf1: !Template
    answer_choices: "S\xED ||| No"
    id: f044def7-01c2-42de-b6ad-4e8c63ab2bf1
    jinja: "\xBFEsta frase tiene sentido?\n{{goal}} {{sol1[0].lower() + sol1[1:]}}\n\
      Responder con {{answer_choices[0]}} o {{answer_choices[1]}}\n|||\n{{answer_choices[label]}}"
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
      - Accuracy
      original_task: false
    name: Does this solution make sense? sol1
    reference: ''
  f42cd457-a14b-465a-a139-d7d2407a3bac: !Template
    answer_choices: null
    id: f42cd457-a14b-465a-a139-d7d2407a3bac
    jinja: "Frase: {{goal}} {{sol1[0].lower() + sol1[1:]}}\nSi la oraci\xF3n no tiene\
      \ sentido, corr\xEDgela para que tenga sentido. De lo contrario, simplemente\
      \ c\xF3pielo.\nResponder:\n|||\n{{goal}} {{[sol1[0].lower() + sol1[1:], sol2[0].lower()\
      \ + sol2[1:]][label]}}\n"
    metadata: !TemplateMetadata
      choices_in_prompt: false
      metrics:
      - BLEU
      - ROUGE
      original_task: false
    name: 'Correct the solution if false: from sol 1'
    reference: ''
